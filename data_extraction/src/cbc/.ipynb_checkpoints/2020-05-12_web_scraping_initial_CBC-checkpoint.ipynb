{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CBC SCRAPING CODE\n",
    "### Authors: JONATHAN CHAN and PANDRAMISHI NAGA SIRISHA\n",
    "### This script contains code to extract the articles from CBC news site\n",
    "###MOST RECENT UPDATE:  \n",
    "##2020 MAY 15, 11:52AM\n",
    "#wrote separate functions for each JSON element to be collected\n",
    "#extract_json_items() will run for all articles, and will return null if not in proper format\n",
    "\n",
    "##2020 June 10 by Pandramishi Naga Sirisha, to write test cases, convert to .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json \n",
    "from bs4 import BeautifulSoup\n",
    "#from datetime import date\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import pytz\n",
    "import dateutil.parser\n",
    "import os\n",
    "from dateutil.parser import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.cbc.ca/search_api/v1/search?q=mortgage%20rate&sortOrder=relevance&page=100&fields=feed\n",
    "def get_initial_url(search_term):\n",
    "    \"\"\"This function returns the URL of the first page API call of the CBC news website given a search string\n",
    "    Input:\n",
    "    ------ \n",
    "    search_term - string : The search string for retrieving articles\n",
    "    \n",
    "    Output:\n",
    "    ------ \n",
    "    string - API call string \n",
    "    \n",
    "    Example: first_url = get_initial_url(\"interest rates\")\n",
    "    \"\"\"\n",
    "    \n",
    "    words = search_term.split()\n",
    "    url_prefix = \"https://www.cbc.ca/search_api/v1/search?\"\n",
    "    query = \"q=\" + \"%20\".join(words)\n",
    "    url_suffix = \"&sortOrder=relevance&page=1&fields=feed\"\n",
    "    first_url = url_prefix + query + url_suffix\n",
    "    print(\"FIRST URL API CALL: \", first_url)\n",
    "    return first_url\n",
    "    \n",
    "# get_initial_url(\"interest rate index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_urls(url, start_date, end_date):\n",
    "    \"\"\"This function takes in the first query url and scrapes all other articles from past 1 year and returns \n",
    "    the urls of such articles\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    url - string : The url of the first page\n",
    "    start_date - date (format:''%Y-%m-%d %H:%M:%S') : The start date from which you want to retrieve articles from\n",
    "    end_date - date (format:''%Y-%m-%d %H:%M:%S') : The start date from which you want to retrieve articles till\n",
    "    \n",
    "    Note: The default time zone will be taken as UTC \n",
    "    \n",
    "    Example:\n",
    "    # all_urls = scrape_urls(first_url, \"2019-01-01 00:00:00\", \"2020-05-01 00:00:00\")\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    url_list = []\n",
    "    main_url = url\n",
    "    r = requests.get(url)\n",
    "    info = r.json()\n",
    "    last_retrieved_items_count= len(info)\n",
    "    \n",
    "    timezone = pytz.timezone('UTC')\n",
    "    start_date_string = parse(start_date)\n",
    "    end_date_string = parse(end_date)\n",
    "    start_tz_obj =  timezone.localize(start_date_string)\n",
    "    end_tz_obj = timezone.localize(end_date_string)\n",
    "    \n",
    "    if start_tz_obj > end_tz_obj:\n",
    "        print(\"The start date is more recent than end date, exiting... \")\n",
    "        return None\n",
    "    \n",
    "    for i in info:\n",
    "        \n",
    "        if 'publishtime' in i.keys() and dateutil.parser.parse(i['publishtime']).astimezone(pytz.UTC) > start_tz_obj and dateutil.parser.parse(i['publishtime']) < end_tz_obj:   \n",
    "            url_list.append(i['url'])\n",
    "            count += 1\n",
    "        \n",
    "    page_number = 2\n",
    "    \n",
    "    while last_retrieved_items_count > 0 :\n",
    "#     while count < 10 :\n",
    "        split_url = main_url.split('page')\n",
    "        new_url = split_url[0] + \"page=\" + str(page_number) + \"&fields=feed\" \n",
    "        try:\n",
    "            r = requests.get(new_url)\n",
    "        except requests.exceptions.RequestException as e:  \n",
    "            raise SystemExit(e)    \n",
    "            return None\n",
    "        \n",
    "        info = r.json()\n",
    "        last_retrieved_items_count= len(info)\n",
    "        \n",
    "        for i in info:\n",
    "            if  'publishtime' in i.keys() and dateutil.parser.parse(i['publishtime']).astimezone(pytz.UTC) > start_tz_obj and dateutil.parser.parse(i['publishtime']) < end_tz_obj:\n",
    "                url_list.append(i['url'])\n",
    "                count += 1\n",
    "                \n",
    "        page_number += 1   \n",
    "        print(\"page_number: \", page_number)\n",
    "\n",
    "        \n",
    "    print(\"The number of articles retrieved is: \", len(url_list))\n",
    "    return url_list\n",
    "\n",
    "# first_url = get_initial_url(\"interest rates\")\n",
    "# all_urls = scrape_urls(first_url, \"2019-01-01 00:00:00\", \"2020-05-01 00:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    \"\"\"returns the title of a BeautifulSoup article if it exists, None if cannot be found\n",
    "    \n",
    "    Assume title info is contained within h1 tag (class: detailHeadline)\n",
    "    \"\"\"\n",
    "    title_tag = soup.find(\"h1\", {\"class\": \"detailHeadline\"})\n",
    "    \n",
    "    if title_tag:\n",
    "        title_text = title_tag.text\n",
    "        return title_text\n",
    "    else:\n",
    "        #print(\"no title found in article!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_to_image(soup):\n",
    "    \"\"\"returns the url to the header image of a CBC article (BeautifulSoup) if it exists, None if not\n",
    "    \n",
    "    Assume image url is contained within src attribute of img tag \n",
    "    \"\"\"\n",
    "    main_image_tag = soup.find(\"figure\", {\"class\": \"imageMedia leadmedia-story full\"})\n",
    "    \n",
    "    if main_image_tag:\n",
    "        main_image_url = main_image_tag.find(\"img\").attrs[\"src\"]\n",
    "        return main_image_url\n",
    "    else:\n",
    "        #print(\"No main header image found in article!\")\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publish_time(soup):\n",
    "    \"\"\"returns a tuple of publish time string and datetime string if found in article, None if not\n",
    "    \n",
    "    Assume time is contained within time tag (class: timestamp)\n",
    "    \"\"\"\n",
    "    time_tag = soup.find(\"time\", {\"class\": \"timeStamp\"})\n",
    "    if time_tag:\n",
    "        datetime_str = time_tag.attrs[\"datetime\"]\n",
    "        \n",
    "        #NOTE: if we want to return a datetime object, error when writing to JSON\n",
    "        #datetime_obj = parser.isoparse(datetime_str)\n",
    "        #SOLUTION: return as string for now, convert to datetime object later in pipeline\n",
    "        \n",
    "        #format of time_tag.text: \n",
    "        timetext_str = time_tag.text.split(\"|\")[0].replace(\"Posted: \", \"\").strip()\n",
    "        return (timetext_str, datetime_str)\n",
    "    else:\n",
    "        #print(\"No time information found in article!\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(soup, specify_source_type=True):\n",
    "    \"\"\"Returns the source of the article if it exists\n",
    "    if specify_source_type, subdivision of CBC will be returned\n",
    "    if not, \"CBC\" will be returned as the source\n",
    "    \n",
    "    \n",
    "    Assume that source always starts with \"CBC\" (Ex: \"CBC news\", \"CBC radio\")\n",
    "    Assume that source comes before span tag (class: bullet)\n",
    "    \"\"\"\n",
    "    \n",
    "    #source appears before <span class=\"bullet\"> Â· </span>\n",
    "    #if author is attached, there are two bullet tags\n",
    "    #if no author attached, there is one bullet tag\n",
    "    source = None\n",
    "    \n",
    "    if specify_source_type:\n",
    "        bullet_spans = soup.find_all(\"span\", {\"class\": \"bullet\"})\n",
    "        for bullet_span in bullet_spans:\n",
    "            previous_str = str(bullet_span.previous_sibling)\n",
    "            if previous_str.startswith(\"CBC\"):\n",
    "                source = previous_str\n",
    "    else:\n",
    "        \n",
    "        source = \"CBC\"\n",
    "    \n",
    "    if source:\n",
    "        return source\n",
    "    else:\n",
    "        #print(\"no source found in article!\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_content(soup, as_string=True):\n",
    "    \"\"\"Returns the text content from a CBC article (as BeautifulSoup object)\n",
    "    if as_string is True, return content as one string,\n",
    "    if as_string is False, return content as list of paragraph strings\n",
    "    \n",
    "    Input: BeautifulSoup object, boolean\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    story_tag = soup.find(\"div\", {\"class\": \"story\"}) \n",
    "    content_list = []\n",
    "    \n",
    "    if story_tag:\n",
    "        for p_tag in story_tag.find_all(\"p\"):\n",
    "            p_text = p_tag.text + \"\\n\"\n",
    "            content_list.append(p_text)\n",
    "\n",
    "        if as_string:\n",
    "            final_content = \"\".join(content_list)\n",
    "        else:\n",
    "            final_content = content_list #return content as list of paragraph strings\n",
    "\n",
    "        return final_content\n",
    "    else:\n",
    "        #print(\"no content found in article!\")\n",
    "        return None\n",
    "    \n",
    "# get_content(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW - USING NEW FUNCTIONS: \n",
    "def extract_json_items(url, specify_source_type=True):\n",
    "    \"\"\"Returns a json containing the following items from a CBC article:\n",
    "        url: the url of the article\n",
    "        urlToImage: the url of the header image\n",
    "        title: the title of the article \n",
    "        description: subheader of the article\n",
    "        author: author (note that some articles do not specify author)\n",
    "        source: CBC if specify_source_type == False, subdivision of CBC if True (ex: \"CBC radio\")\n",
    "        publishedAt: tuple of (date_string, datetime object)\n",
    "        \n",
    "        input: url returned from CBC API in \"url\" field (missing \"http:\" as part of URL)\n",
    "        \n",
    "    Example:\n",
    "    extract_json_items('//www.cbc.ca/news/business/powel-trump-negative-rates-1.5567512')\n",
    "    \"\"\"\n",
    "    json_dict = {}\n",
    "    article_url = \"http:\" + url\n",
    "    \n",
    "    #get HTML from article URL into BeautifulSoup\n",
    "    try:\n",
    "        html_bytes = urllib.request.urlopen(article_url)\n",
    "  \n",
    "    except HTTPError as e:\n",
    "        print('Error code: ', e.code)\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        print('Reason: ', e.reason)\n",
    "        return None\n",
    "\n",
    "    else:    \n",
    "        mybytes = html_bytes.read()\n",
    "        html = mybytes.decode(\"utf8\")\n",
    "        html_bytes.close()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        author_name = get_author(soup)\n",
    "        title_text = get_title(soup)\n",
    "        desc_text = get_desc(soup)\n",
    "        image_url = get_url_to_image(soup)\n",
    "        publish_time = get_publish_time(soup)\n",
    "        news_source = get_source(soup)\n",
    "        content = get_content(soup, True)\n",
    "        \n",
    "        json_dict[\"author\"] = author_name\n",
    "        json_dict[\"title\"] = title_text \n",
    "        json_dict[\"description\"] = desc_text\n",
    "        json_dict[\"url\"] = article_url\n",
    "        json_dict[\"urlToImage\"] = image_url\n",
    "        json_dict[\"publishedAt\"] = publish_time\n",
    "        json_dict[\"source\"] = news_source\n",
    "        json_dict[\"content\"] = content\n",
    "        final_json = json.dumps(json_dict)\n",
    "        return json_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(query,start_date, end_date, project_path):\n",
    "    \"\"\"\n",
    "    This function takes a search string, the start date and end_date to retrieve the articles\n",
    "    from CBC website and stores articles retreived in a json file\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    url - string : The search term without special characters\n",
    "    start_date - date (format:''%Y-%m-%d %H:%M:%S') : The start date from which you want to retrieve articles from\n",
    "    end_date - date (format:''%Y-%m-%d %H:%M:%S') : The start date from which you want to retrieve articles till\n",
    "    \n",
    "    Note: The default time zone will be taken as UTC \n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    list of dictionaries of retrieved articles\n",
    "    \n",
    "    \"\"\"\n",
    "    directory_flag = os.path.isdir(project_path)\n",
    "    \n",
    "    if  directory_flag:\n",
    "        # path exists\n",
    "        first_url = get_initial_url(query)\n",
    "        all_urls = scrape_urls(first_url, start_date, end_date)\n",
    "        json_list = []\n",
    "    \n",
    "        try:\n",
    "            for each_url in all_urls:\n",
    "                retrieved_json  = extract_json_items(each_url)\n",
    "                if retrieved_json is not None:\n",
    "                    print(each_url)\n",
    "                    json_list.append(retrieved_json)\n",
    "\n",
    "            full_query = query.split(\" \")\n",
    "            file_name_prefix = \"\".join(full_query)\n",
    "            file_name = project_path + \"project/data_extraction/data/unannotated_data/cbc/\" + file_name_prefix + '_' +'CBC_article' + '.json' \n",
    "            print(\"The retrieved articles are written to the folder: \",file_name)\n",
    "            with open( file_name, 'w') as json_file:\n",
    "                json.dump(json_list, json_file)\n",
    "           \n",
    "            \n",
    "        except:\n",
    "            print(\"We could not match the selected criteria to extract articles, exiting...\")\n",
    "            return None\n",
    "        \n",
    "    elif directory_flag is False:\n",
    "        print(\"Project path does not exist,exiting...\")\n",
    "        return None\n",
    "        \n",
    "    \n",
    "    return json_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mortgage Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST URL API CALL:  https://www.cbc.ca/search_api/v1/search?q=mortgage%20rates&sortOrder=relevance&page=1&fields=feed\n",
      "page_number:  3\n",
      "page_number:  4\n",
      "page_number:  5\n",
      "page_number:  6\n",
      "page_number:  7\n",
      "page_number:  8\n",
      "page_number:  9\n",
      "page_number:  10\n",
      "page_number:  11\n",
      "page_number:  12\n",
      "page_number:  13\n",
      "page_number:  14\n",
      "page_number:  15\n",
      "page_number:  16\n",
      "page_number:  17\n",
      "page_number:  18\n",
      "page_number:  19\n",
      "page_number:  20\n",
      "page_number:  21\n",
      "page_number:  22\n",
      "page_number:  23\n",
      "page_number:  24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-8ea3df201864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mproject_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/nagasiri/Desktop/NagaSiri/MDS-CL/Capstone/better_dwelling_capstone/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcbc_mr_article\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mortgage rates\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2019-01-01 00:00:00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2020-05-01 00:00:00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbc_mr_article\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-65372472e530>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(query, start_date, end_date, project_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# path exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfirst_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_initial_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mall_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mjson_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-004ee69b2a7c>\u001b[0m in \u001b[0;36mscrape_urls\u001b[0;34m(url, start_date, end_date)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mnew_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_url\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"page=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_number\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"&fields=feed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unexpected EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "project_path=\"/Users/nagasiri/Desktop/NagaSiri/MDS-CL/Capstone/better_dwelling_capstone/\"\n",
    "cbc_mr_article = main(\"mortgage rates\", \"2019-01-01 00:00:00\", \"2020-05-01 00:00:00\", project_path)\n",
    "print(cbc_mr_article[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For other economic indicators\n",
    "#### For interest rates,  the search string used is \"interest rates\"\n",
    "#### For housing price, the search used is   'housing price'\n",
    "#### For employment, the  search string used is \"employment\"\n",
    "#### For GDP,  the search string used is \"gdp\"\n",
    "#### For TSX, the search string used is \"tsx\", \"stock market\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST URL API CALL:  https://www.cbc.ca/search_api/v1/search?q=interest%20rates&sortOrder=relevance&page=1&fields=feed\n",
      "FIRST URL API CALL:  https://www.cbc.ca/search_api/v1/search?q=interest%20rates&sortOrder=relevance&page=1&fields=feed\n",
      "The start date is more recent than end date, exiting... \n",
      "We could not match the selected criteria to extract articles, exiting...\n",
      "Project path does not exist,exiting...\n",
      "FIRST URL API CALL:  https://www.cbc.ca/search_api/v1/search?q=interest%20rates&sortOrder=relevance&page=1&fields=feed\n",
      "page_number:  3\n",
      "page_number:  4\n",
      "page_number:  5\n",
      "page_number:  6\n",
      "page_number:  7\n",
      "page_number:  8\n",
      "page_number:  9\n",
      "page_number:  10\n",
      "page_number:  11\n",
      "page_number:  12\n",
      "page_number:  13\n",
      "page_number:  14\n",
      "page_number:  15\n",
      "page_number:  16\n",
      "page_number:  17\n",
      "page_number:  18\n",
      "page_number:  19\n",
      "page_number:  20\n",
      "page_number:  21\n",
      "page_number:  22\n",
      "page_number:  23\n",
      "page_number:  24\n",
      "page_number:  25\n",
      "The number of articles retrieved is:  10\n",
      "//www.cbc.ca/news/business/interest-rate-hikes-1.4964689\n",
      "//www.cbc.ca/player/play/1423118915761\n",
      "Error code:  404\n",
      "//www.cbc.ca/news/business/fed-interest-rates-1.4999021\n",
      "//www.cbc.ca/news/thenational/bank-of-canada-keeps-interest-rates-steady-but-what-does-that-mean-for-you-1.4972639\n",
      "//www.cbc.ca/listen/shows/fresh-air/segment/15663034\n",
      "//www.cbc.ca/player/play/1424813123788\n",
      "//www.cbc.ca/news/canada/gm-s-oshawa-plant-closure-and-benchmark-interest-rate-unchanged-business-panel-1.4976276\n",
      "//www.cbc.ca/news/business/bank-of-canada-advance-1.4969951\n",
      "//www.cbc.ca/news/business/bank-of-canada-rate-decision-1.4971176\n",
      "The retrieved articles are written to the folder:  /Users/nagasiri/Desktop/NagaSiri/MDS-CL/Capstone/better_dwelling_capstone/project/data_extraction/data/unannotated_data/cbc/interestrates_CBC_article.json\n"
     ]
    }
   ],
   "source": [
    "def run_tests():\n",
    "    first_url = get_initial_url(\"interest rates\")\n",
    "    project_path=\"/Users/nagasiri/Desktop/NagaSiri/MDS-CL/Capstone/better_dwelling_capstone/\"\n",
    "    \n",
    "    # Check start date is earlier than end date\n",
    "    x = main(\"interest rates\", \"2019-02-01 00:00:00\", \"2019-01-01 00:00:00\", project_path)\n",
    "    assert x is None, \"if start date is greater than end date, None should be returned\"\n",
    "    \n",
    "    # Check the \"project\" path exists\n",
    "    project_path=\"/non_existenet_path\"\n",
    "    x = main(\"interest rates\", \"2019-01-01 00:00:00\", \"2019-02-01 00:00:00\", project_path)\n",
    "    assert x is None, \"if project directory path does not exist, None should be returned\"\n",
    "    \n",
    "    #Check if the output file is created, and it is in the correct folder\n",
    "    query = \"interest rates\"\n",
    "    full_query = query.split(\" \")\n",
    "    file_name_prefix = \"\".join(full_query)\n",
    "    project_path=\"/Users/nagasiri/Desktop/NagaSiri/MDS-CL/Capstone/better_dwelling_capstone/\"\n",
    "    file_name = project_path + \"project/data_extraction/data/unannotated_data/cbc/\" + file_name_prefix + '_' +'CBC_article' + '.json'\n",
    "    main(\"interest rates\", \"2019-01-01 00:00:00\", \"2019-02-01 00:00:00\", project_path)\n",
    "    output_file_flag = os.path.exists(file_name)\n",
    "    assert output_file_flag == True, \"The output .json file is not created\"\n",
    "\n",
    "    \n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
