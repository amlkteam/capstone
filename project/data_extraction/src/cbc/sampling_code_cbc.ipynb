{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creator: Pandramishi Naga Sirisha\n",
    "# Created on: 27-05-2020\n",
    "# Utilities functions to be created into a package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from datetime import datetime, timedelta, date\n",
    "import pytz\n",
    "import dateutil.parser\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_df(project_path,path_to_json):\n",
    "    \"\"\"This function reads a json file and outputs a dataframe\n",
    "    Input:\n",
    "    ------\n",
    "    project_path: path to project\n",
    "    path_to_json: path to json file\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    Dataframe object\n",
    "    \"\"\"\n",
    "    if  os.path.exists(project_path+path_to_json):\n",
    "        df = pd.read_json(project_path+path_to_json)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"From convert_json_to_df(): Following path does not exist -  \", project_path + path_to_json)\n",
    "        return None\n",
    "\n",
    "project_path = \"/Users/nagasiri/Desktop/NagaSiri/MDS-CL/Capstone/better_dwelling_capstone/\"\n",
    "file_path = \"project/data_extraction/data/unannotated_data/cbc/interestrates_CBC_article.json\"\n",
    "converted_df = convert_json_to_df(project_path, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df_object,column_name_list,remove_Nans = True):\n",
    "    \"\"\"\n",
    "    This function preprocesses the dataframe\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    df_object - object: The dataframe object to preprocess\n",
    "    column_name_list- list: list of required columns\n",
    "    remove_Nans - Boolean: To remove all rows which contain None or NaN\n",
    "    filter_query - string\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    object - The preprocessed dataframe object\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        subset_columns_df = df_object[column_name_list]\n",
    "    except:\n",
    "        print(\"From preprocess_df(): Check the dataframe object and column names\")\n",
    "        return None\n",
    "        \n",
    "    if remove_Nans:\n",
    "        subset_columns_df = subset_columns_df.dropna()\n",
    "\n",
    "    return  subset_columns_df\n",
    "    \n",
    "# k = preprocess_df(converted_df, ['title', 'description','publishedAt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataframe_by_month(dataframe, sample_size):\n",
    "    \"\"\"\n",
    "    create sample of dataframe based on publish date, sample size is the number of articles to be extracted from each month\n",
    "    \"\"\"\n",
    "    article_dictionary_by_month = defaultdict(list)\n",
    "    full_list = []\n",
    "    \n",
    "    if  type(dataframe) is  not pd.DataFrame or not sample_size.is_integer():\n",
    "        print(\"not integer\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        for column, row in dataframe.iterrows():\n",
    "            article_date = (dateutil.parser.parse(row['publishedAt']))\n",
    "            article_year = article_date.year\n",
    "            article_month = article_date.month\n",
    "            article_dictionary_by_month[str(article_year) + '-' + str(article_month)].append(row)\n",
    "\n",
    "        for month_number, list_of_articles in article_dictionary_by_month.items():\n",
    "            random.shuffle(list_of_articles)\n",
    "            subset_list = list_of_articles[:sample_size]\n",
    "            full_list.extend(subset_list)\n",
    "\n",
    "        sample_df = pd.DataFrame(full_list)\n",
    "        sample_df = sample_df.sort_values(by='publishedAt', ascending=False)\n",
    "    \n",
    "    except:\n",
    "        print(\"From function sample_dataframe_by_month() : Could not sample\")\n",
    "        return None\n",
    "    \n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lambda(df, column, lambda_string):\n",
    "    \"\"\"Takes a dataframe, column and applies a lambda function to it\"\"\"\n",
    "    try:\n",
    "        df[column] = df[column].apply(eval(lambda_string))\n",
    "        return df    \n",
    "    except:\n",
    "        print(\"Cannot apply lambda function\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_csv(df,project_path,file_path,file_name):\n",
    "    \"\"\"Takes a dataframe and writes to a file\"\"\"\n",
    "    if os.path.isdir(project_path+file_path):\n",
    "        df.to_csv(project_path+file_path+file_name, encoding='utf-8', index=False)\n",
    "    else:\n",
    "        print(\"Path does not exist:\", project_path+file_path)\n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not successfully sample the data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_sample_from_json(economic_indicator,project_path,json_file_path, column_names_list, sample_size,source_string, remove_Nans = True ):\n",
    "    \"\"\"Write the docstrings \"\"\"\n",
    "    try:\n",
    "        df = convert_json_to_df(project_path, json_file_path)\n",
    "        preprocessed_df = preprocess_df(df,column_names_list)\n",
    "        preprocessed_df[\"source\"] = source_string\n",
    "        preprocessed_df = apply_lambda(preprocessed_df,'publishedAt' ,\"lambda x: x[1]\")        \n",
    "        sampled_df = sample_dataframe_by_month(preprocessed_df, sample_size)\n",
    "\n",
    "        # Write sampled dataframe to a different file in a different path\n",
    "        relative_file_path = \"project/data_extraction/data/annotated_data/cbc/\"\n",
    "        write_df_to_csv(sampled_df,project_path,relative_file_path,economic_indicator+\"_to_annotate.csv\")\n",
    "        if os.path.exists(project_path + relative_file_path + economic_indicator+\"_to_annotate.csv\"):\n",
    "            return True\n",
    "    except:\n",
    "        print(\"Could not successfully sample the data\")\n",
    "        return False\n",
    "    \n",
    "project_path = \"/Users/nagasiri/Desktop/NagaSiri/MDS-CL/Capstone/better_dwelling_capstone/\"\n",
    "json_file_path = \"project/data_extraction/data/unannotated_data/cbc/mortgagerates_CBC_article.json\"\n",
    "create_sample_from_json(\"mortgagerates\",project_path,json_file_path, ['title', 'description','publishedAt'], 2,\"CBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From convert_json_to_df(): Following path does not exist -   /non existentnon_existent_file.json\n",
      "From preprocess_df(): Check the dataframe object and column names\n"
     ]
    }
   ],
   "source": [
    "def unit_tests():\n",
    "    project_path = \"/non existent\"\n",
    "    file_path = \"non_existent_file.json\"\n",
    "    converted_df = convert_json_to_df(project_path, file_path)\n",
    "    assert converted_df is None, \"If path is not present return None\"\n",
    "    \n",
    "    project_path = \"/Users/nagasiri/Desktop/NagaSiri/MDS-CL/Capstone/better_dwelling_capstone/\"\n",
    "    file_path = \"project/data_extraction/data/unannotated_data/cbc/interestrates_CBC_article.json\"\n",
    "    converted_df = convert_json_to_df(project_path, file_path)\n",
    "    df = preprocess_df(converted_df, ['xyz'])\n",
    "    assert df is None\n",
    "    k = preprocess_df(converted_df, ['title', 'description','publishedAt'])\n",
    "    assert isinstance(k, pd.DataFrame)\n",
    "    \n",
    "unit_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
