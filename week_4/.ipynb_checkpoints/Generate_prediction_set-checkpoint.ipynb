{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for extracting prediction articles\n",
    "# Logic (full_articles.json - articles_used_for_training)\n",
    "# Author: Pandramishi Naga Sirisha\n",
    "# Date: 26th May 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json \n",
    "import json\n",
    "import datetime\n",
    "import pytz\n",
    "import dateutil.parser\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(filename, list_name, file_suffix):\n",
    "    \"\"\"creates a csv containing title and description of articles in a given JSON.\n",
    "    Re-using this function from Sampling_articles_by_month.ipynb from week_2\"\"\"\n",
    "    ind = 0\n",
    "    title_list = []\n",
    "    desc_list = []\n",
    "    date_list =[]\n",
    "    source_list = []\n",
    "    invalid_articles = 0\n",
    "    \n",
    "    for json_dict in list_name:\n",
    "        #check if valid title exists\n",
    "        if json_dict[\"title\"]:\n",
    "            title_list.append(json_dict[\"title\"])\n",
    "            desc_list.append(json_dict[\"description\"])\n",
    "            date_list.append(dateutil.parser.parse(json_dict['publishedAt'][1]).date())\n",
    "            source_list.append(\"CBC\")\n",
    "            ind += 1\n",
    "            \n",
    "        else:\n",
    "            invalid_articles += 1\n",
    "            \n",
    "    print(\"Invalid articles :\", invalid_articles)        \n",
    "    prefix = filename.split(\".\")[0]\n",
    "    out_filename = prefix  + \"_\" + str(ind) + \"_\" + file_suffix + \".csv\"\n",
    "    with open(out_filename, 'w') as myfile:\n",
    "        writer = csv.writer(myfile)\n",
    "        #wr.writerow(mylist)\n",
    "        writer.writerow([\"title\", \"description\"])\n",
    "        for i in range(len(title_list)):\n",
    "            writer.writerow([title_list[i], desc_list[i], date_list[i], source_list[i]])\n",
    "    myfile.close()\n",
    "    print(\"Output file name is :\", out_filename)\n",
    "    return out_filename\n",
    "                \n",
    "# json_to_csv(\"mortgage_rates_CBC_article.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./Full_articles_unannotated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"housing_prices_CBC_article.json\"\n",
    "economic_indicator_name = \"housing_price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + file_name ) as f:\n",
    "    list_of_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid articles : 263\n",
      "Output file name is : housing_prices_CBC_article_541_convert.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title_desc</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBC</td>\n",
       "      <td>Expect housing prices to continue to rise in 2...</td>\n",
       "      <td>2020-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBC</td>\n",
       "      <td>Hamilton housing sales down since September, p...</td>\n",
       "      <td>2019-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBC</td>\n",
       "      <td>Soaring rents and house prices in Canadian cit...</td>\n",
       "      <td>2019-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBC</td>\n",
       "      <td>Toronto area housing sales up 24.3% in July, p...</td>\n",
       "      <td>2019-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBC</td>\n",
       "      <td>St. John's housing prices will lead country in...</td>\n",
       "      <td>2019-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                         title_desc publishedAt\n",
       "0    CBC  Expect housing prices to continue to rise in 2...  2020-01-07\n",
       "1    CBC  Hamilton housing sales down since September, p...  2019-12-03\n",
       "2    CBC  Soaring rents and house prices in Canadian cit...  2019-09-24\n",
       "3    CBC  Toronto area housing sales up 24.3% in July, p...  2019-08-09\n",
       "4    CBC  St. John's housing prices will lead country in...  2019-05-26"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing full articles' dataframe to get required format\n",
    "# Read article in json format and output as csv to process data easily as dataframes\n",
    "full_article_file_name = json_to_csv(file_name, list_of_json, \"convert\")\n",
    "full_df = pd.read_csv(full_article_file_name, sep=',', names=['title', 'description', 'publishedAt', 'source'], skiprows = 1)\n",
    "full_df[\"title_desc\"] = full_df ['title'] + \". \" + full_df['description']\n",
    "full_df = full_df.drop(columns = ['title', 'description'])\n",
    "full_df = full_df[['source','title_desc', 'publishedAt' ]]\n",
    "full_df = full_df.dropna(how='any',axis=0)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523, 3)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe type to datetime\n",
    "import pandas\n",
    "full_df['publishedAt'] =  pd.to_datetime(full_df['publishedAt'], format='%Y-%m-%d')\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523, 3)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to check if all the articles are from 2019-05-12 to 2020-05-12\n",
    "import pandas\n",
    "cond1 = full_df.publishedAt > pd.Timestamp(2019,5,12)\n",
    "x = full_df.loc[cond1, ]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Looking back at a decade of Vancouver real estate. It's been a long and strange trip,' says urban planning professor Andy Yan\""
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing training dataframe to get required format\n",
    "training_df = pd.read_csv(\"./final_cbc_annotations/\" + economic_indicator_name+ \"_combined_annotations_CBC.csv\", names = ['title','description', 'publishedAt', 'title_desc_sent_1', 'source'], skiprows = 1)\n",
    "training_df[\"title_desc\"] = training_df ['title'] + \". \" + training_df['description']\n",
    "training_df = training_df.drop(columns = ['title', 'description','title_desc_sent_1'])\n",
    "training_df = training_df[['source','title_desc', 'publishedAt' ]]\n",
    "training_df.iloc[0]['title_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 3)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do a left join  between two dataframes\n",
    "final = pd.merge(full_df,training_df,on='title_desc',how='left', indicator=True)\n",
    "# final = final.dropna(how='any',axis=0)\n",
    "\n",
    "# Getting only (left_only) rows to make it left OUTER join\n",
    "final = final[final['_merge'] == 'left_only']\n",
    "final = final.drop(columns = ['source_y','publishedAt_y','_merge'])\n",
    "final.columns = ['source','title_desc', 'publishedAt']\n",
    "final.shape\n",
    "# final.ix[62]['title_desc'] == training_df.iloc[0]['title_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output final prediction file\n",
    "final.to_csv(file_name.split(\".\")[0] + \"_to_predict.csv\",sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
