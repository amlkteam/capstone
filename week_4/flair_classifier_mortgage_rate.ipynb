{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair_classifier_mortgage_oversampled.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3298096fca834d25a9d25534302e9487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c12ed080d0424b72aaf87b35ad7a0a4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6c3725b319144aa99757b6d0e2772c1",
              "IPY_MODEL_b6457cec3e26465987517d2a635917c2"
            ]
          }
        },
        "c12ed080d0424b72aaf87b35ad7a0a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6c3725b319144aa99757b6d0e2772c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_060396156a574c6d854575aa823f4956",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70d07e2e1f414398b8996274e4023c91"
          }
        },
        "b6457cec3e26465987517d2a635917c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce80c903517e4518ab60e46e064f3724",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [01:49&lt;00:00, 2.11kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7843411f71b942319e3db5f771b624f7"
          }
        },
        "060396156a574c6d854575aa823f4956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70d07e2e1f414398b8996274e4023c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce80c903517e4518ab60e46e064f3724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7843411f71b942319e3db5f771b624f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff6503c8ecf24a91b5187decd0645d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5026e9167e784891bc97f472f6b6b807",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f4c642e774b4e38b71bf98de47a9f64",
              "IPY_MODEL_86f67bfffc9a4699ab061ae10cca815e"
            ]
          }
        },
        "5026e9167e784891bc97f472f6b6b807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f4c642e774b4e38b71bf98de47a9f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b514a3d57ac143b28161bb4a07ff534f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8980e7d68c75416789403fe21788ef7a"
          }
        },
        "86f67bfffc9a4699ab061ae10cca815e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_052d609c48854a4d9f53c38b3cde1234",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:07&lt;00:00, 58.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fc1f12c1a444bb093161112a168441d"
          }
        },
        "b514a3d57ac143b28161bb4a07ff534f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8980e7d68c75416789403fe21788ef7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "052d609c48854a4d9f53c38b3cde1234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fc1f12c1a444bb093161112a168441d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e2b756dd0de492e986acd200e17fdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5264bc7ec45e4995b6b5c49e77a1805d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31226549c9b54e5f9cc53c092b36100e",
              "IPY_MODEL_3940aa95dab84377b17d48aeda28f6c5"
            ]
          }
        },
        "5264bc7ec45e4995b6b5c49e77a1805d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31226549c9b54e5f9cc53c092b36100e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3cce444a636f482a839428229eb88be8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0951892f603948ccadb6a11954fa191d"
          }
        },
        "3940aa95dab84377b17d48aeda28f6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47b0fb32318f400bbfb8fc295ad0f3bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 60.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4a2a4b5d8294ccaa4d05cd8610aae30"
          }
        },
        "3cce444a636f482a839428229eb88be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0951892f603948ccadb6a11954fa191d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47b0fb32318f400bbfb8fc295ad0f3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4a2a4b5d8294ccaa4d05cd8610aae30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybjXa4UJ3g7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVY0ZiGk38i_",
        "colab_type": "code",
        "outputId": "51a503b6-608a-4ea5-c970-7ab793fe24c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-cbd67jg1\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-cbd67jg1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 21.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2.8.1)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 56.3MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/f9/9f2b6c672c8f8bb87a4c1bd52c1b57213627b035305aad745d015b2a62ae/pytest-5.4.2-py3-none-any.whl (247kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2019.12.20)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.5.0+cu101)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 48.8MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (3.0.12)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair==0.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.5) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (8.3.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair==0.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.5) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.10.0->flair==0.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.13.13)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.16.13)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.5-cp36-none-any.whl size=148939 sha256=aeb7ba1310603af19d4551b9aeb8b7f533b4b5dcb083c77651134f0f96208736\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1fdfd1__/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Building wheels for collected packages: sqlitedict, mpld3, segtok, langdetect, sacremoses\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=03de32ea22c65a47d5b93f6ee3814fac4cd1cfd0964e5afcdccb9ca962c5b187\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=4409d0f4c84ac73189715b0948a68a981d2f31e099ebccc73a173dfc2816258d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=15b96fbf251ef4b23ac42689e6ee1c4e989346698b370f80d980f89ad25e0dd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=dc4747fe10c5cf983c5387217525dd56f3ce6948702daeddfd68d3cf08d787fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=995750850161d91dc6bfea6817b153ecf48df4a1f4c003df7c19dc63468d4196\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sqlitedict mpld3 segtok langdetect sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers, sqlitedict, mpld3, deprecated, pluggy, pytest, segtok, langdetect, bpemb, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.2 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0 tokenizers-0.7.0 transformers-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP7gl75D39dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "from flair.data import Corpus\n",
        "import pandas as pd\n",
        "\n",
        "from flair.data import Sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfpsjw8I4Si-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBdZ1L34XwO",
        "colab_type": "code",
        "outputId": "b452e982-4e7e-448b-f346-357229ec4c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U90p69Xd5KIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_folder = \"./drive/My Drive/Colab Notebooks/capstone/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkUisuXz7tuK",
        "colab_type": "text"
      },
      "source": [
        "### First Stage (Train on benchmark dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-_Bmpa6gn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = pd.read_csv(data_folder + \"combined_benchmark.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVaSsyAn72AU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b852a5cb-bd59-4b47-914e-01c1a10b00f5"
      },
      "source": [
        "benchmark = benchmark[['label', 'text']]\n",
        "benchmark.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Why not subscribe to the magazine ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>Tornio Works employs 2,300 of whom more than 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>The move is aimed at boosting sales , cost-eff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>As a result of the merger , the largest profes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>18 March 2010 A leakage in the gypsum pond was...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0                Why not subscribe to the magazine ?\n",
              "1     -1  Tornio Works employs 2,300 of whom more than 1...\n",
              "2      1  The move is aimed at boosting sales , cost-eff...\n",
              "3      0  As a result of the merger , the largest profes...\n",
              "4     -1  18 March 2010 A leakage in the gypsum pond was..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_MVMXq8pvf",
        "colab_type": "text"
      },
      "source": [
        "#### Create train, dev and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUbbfcSC8ekr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = benchmark.sample(frac=1, random_state=42)\n",
        "\n",
        "\n",
        "benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', sep=',', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', sep=',', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', sep=',', index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewcNTUT7l8tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5c2f30dd-669f-4dbf-9a52-c2380bf22ca6"
      },
      "source": [
        "train_df = pd.read_csv(data_folder + \"train.csv\", header = None)\n",
        "train_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>About Elcoteq Elcoteq SE is a leading electron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>U.S. goods trade deficit deteriorates; factory...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Product coverage : baked goods ; biscuits ; br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Tyrv+Æinen is of the opinion that the airline ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>Wall St. Week Ahead: U.S. stock reign may not ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                                  1\n",
              "0  1  About Elcoteq Elcoteq SE is a leading electron...\n",
              "1 -1  U.S. goods trade deficit deteriorates; factory...\n",
              "2  0  Product coverage : baked goods ; biscuits ; br...\n",
              "3  0  Tyrv+Æinen is of the opinion that the airline ...\n",
              "4 -1  Wall St. Week Ahead: U.S. stock reign may not ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7QE3IS69txr",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz-2gNy58wDI",
        "colab_type": "code",
        "outputId": "9078f991-556a-4817-e299-2a9a9637b833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_folder), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
        "column_name_map = {1: \"text\", 0: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                         column_name_map,\n",
        "                                         skip_header=False, #no header in kaggle data\n",
        "                                         delimiter=',',    # comma separated rows\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 01:48:25,270 Reading data from drive/My Drive/Colab Notebooks/capstone/data\n",
            "2020-05-28 01:48:25,273 Train: drive/My Drive/Colab Notebooks/capstone/data/train.csv\n",
            "2020-05-28 01:48:25,278 Dev: drive/My Drive/Colab Notebooks/capstone/data/dev.csv\n",
            "2020-05-28 01:48:25,279 Test: drive/My Drive/Colab Notebooks/capstone/data/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb1lynSQ98-z",
        "colab_type": "text"
      },
      "source": [
        "#### Create word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u9PFUze9_5y",
        "colab_type": "code",
        "outputId": "cac2a334-2d08-4d41-e276-33157d9e2b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "3298096fca834d25a9d25534302e9487",
            "c12ed080d0424b72aaf87b35ad7a0a4d",
            "f6c3725b319144aa99757b6d0e2772c1",
            "b6457cec3e26465987517d2a635917c2",
            "060396156a574c6d854575aa823f4956",
            "70d07e2e1f414398b8996274e4023c91",
            "ce80c903517e4518ab60e46e064f3724",
            "7843411f71b942319e3db5f771b624f7",
            "ff6503c8ecf24a91b5187decd0645d07",
            "5026e9167e784891bc97f472f6b6b807",
            "0f4c642e774b4e38b71bf98de47a9f64",
            "86f67bfffc9a4699ab061ae10cca815e",
            "b514a3d57ac143b28161bb4a07ff534f",
            "8980e7d68c75416789403fe21788ef7a",
            "052d609c48854a4d9f53c38b3cde1234",
            "6fc1f12c1a444bb093161112a168441d",
            "0e2b756dd0de492e986acd200e17fdbf",
            "5264bc7ec45e4995b6b5c49e77a1805d",
            "31226549c9b54e5f9cc53c092b36100e",
            "3940aa95dab84377b17d48aeda28f6c5",
            "3cce444a636f482a839428229eb88be8",
            "0951892f603948ccadb6a11954fa191d",
            "47b0fb32318f400bbfb8fc295ad0f3bd",
            "f4a2a4b5d8294ccaa4d05cd8610aae30"
          ]
        }
      },
      "source": [
        "word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3298096fca834d25a9d25534302e9487",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff6503c8ecf24a91b5187decd0645d07",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e2b756dd0de492e986acd200e17fdbf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2020-05-28 01:48:47,646 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpdi50xosv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:04<00:00, 4626158.25B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 01:48:53,224 copying /tmp/tmpdi50xosv to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2020-05-28 01:48:53,248 removing temp file /tmp/tmpdi50xosv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 01:49:12,089 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp7ksl7k1w\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:04<00:00, 4730370.01B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 01:49:17,527 copying /tmp/tmp7ksl7k1w to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2020-05-28 01:49:17,547 removing temp file /tmp/tmp7ksl7k1w\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HovCqFfSMjmJ",
        "colab_type": "text"
      },
      "source": [
        "#### First Stage Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wik8DDxm-DKy",
        "colab_type": "code",
        "outputId": "b0fa82a5-7e73-4453-c50f-d8a00314452b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train(data_folder,\n",
        "              learning_rate=0.05, \n",
        "              max_epochs=15)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 01:50:22,214 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1314/1314 [00:01<00:00, 959.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 01:50:23,880 [b'1', b'-1', b'0']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 01:50:24,689 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:50:24,695 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-28 01:50:24,697 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:50:24,701 Corpus: \"Corpus: 1168 train + 147 dev + 146 test sentences\"\n",
            "2020-05-28 01:50:24,703 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:50:24,704 Parameters:\n",
            "2020-05-28 01:50:24,705  - learning_rate: \"0.05\"\n",
            "2020-05-28 01:50:24,705  - mini_batch_size: \"32\"\n",
            "2020-05-28 01:50:24,707  - patience: \"3\"\n",
            "2020-05-28 01:50:24,708  - anneal_factor: \"0.5\"\n",
            "2020-05-28 01:50:24,709  - max_epochs: \"15\"\n",
            "2020-05-28 01:50:24,711  - shuffle: \"True\"\n",
            "2020-05-28 01:50:24,712  - train_with_dev: \"False\"\n",
            "2020-05-28 01:50:24,713  - batch_growth_annealing: \"False\"\n",
            "2020-05-28 01:50:24,714 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:50:24,716 Model training base path: \"drive/My Drive/Colab Notebooks/capstone/data\"\n",
            "2020-05-28 01:50:24,718 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:50:24,718 Device: cuda:0\n",
            "2020-05-28 01:50:24,719 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:50:24,720 Embeddings storage mode: cpu\n",
            "2020-05-28 01:50:26,130 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:50:28,278 epoch 1 - iter 3/37 - loss 1.24104981 - samples/sec: 53.00\n",
            "2020-05-28 01:50:41,768 epoch 1 - iter 6/37 - loss 1.13129512 - samples/sec: 61.56\n",
            "2020-05-28 01:50:54,466 epoch 1 - iter 9/37 - loss 1.13656637 - samples/sec: 61.64\n",
            "2020-05-28 01:51:08,219 epoch 1 - iter 12/37 - loss 1.12735186 - samples/sec: 60.59\n",
            "2020-05-28 01:51:21,275 epoch 1 - iter 15/37 - loss 1.08650159 - samples/sec: 56.24\n",
            "2020-05-28 01:51:33,972 epoch 1 - iter 18/37 - loss 1.05979338 - samples/sec: 61.54\n",
            "2020-05-28 01:51:47,423 epoch 1 - iter 21/37 - loss 1.04909373 - samples/sec: 62.94\n",
            "2020-05-28 01:52:00,538 epoch 1 - iter 24/37 - loss 1.06046088 - samples/sec: 61.41\n",
            "2020-05-28 01:52:13,922 epoch 1 - iter 27/37 - loss 1.04785680 - samples/sec: 65.77\n",
            "2020-05-28 01:52:27,260 epoch 1 - iter 30/37 - loss 1.02969401 - samples/sec: 64.02\n",
            "2020-05-28 01:52:39,912 epoch 1 - iter 33/37 - loss 1.01150693 - samples/sec: 64.26\n",
            "2020-05-28 01:52:52,490 epoch 1 - iter 36/37 - loss 1.01643445 - samples/sec: 67.02\n",
            "2020-05-28 01:53:04,539 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:53:04,540 EPOCH 1 done: loss 1.0147 - lr 0.0500000\n",
            "2020-05-28 01:53:07,594 DEV : loss 0.9019950032234192 - score 0.7007\n",
            "2020-05-28 01:53:07,732 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-28 01:53:09,479 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:53:11,545 epoch 2 - iter 3/37 - loss 0.80660647 - samples/sec: 57.69\n",
            "2020-05-28 01:53:26,883 epoch 2 - iter 6/37 - loss 0.83539789 - samples/sec: 66.59\n",
            "2020-05-28 01:53:40,576 epoch 2 - iter 9/37 - loss 0.83096511 - samples/sec: 68.84\n",
            "2020-05-28 01:53:54,254 epoch 2 - iter 12/37 - loss 0.80922706 - samples/sec: 65.80\n",
            "2020-05-28 01:54:07,907 epoch 2 - iter 15/37 - loss 0.82671812 - samples/sec: 65.26\n",
            "2020-05-28 01:54:21,668 epoch 2 - iter 18/37 - loss 0.84515346 - samples/sec: 58.89\n",
            "2020-05-28 01:54:35,471 epoch 2 - iter 21/37 - loss 0.84713273 - samples/sec: 61.82\n",
            "2020-05-28 01:54:49,720 epoch 2 - iter 24/37 - loss 0.84391132 - samples/sec: 60.46\n",
            "2020-05-28 01:55:02,883 epoch 2 - iter 27/37 - loss 0.85483827 - samples/sec: 62.82\n",
            "2020-05-28 01:55:16,943 epoch 2 - iter 30/37 - loss 0.85094079 - samples/sec: 62.49\n",
            "2020-05-28 01:55:30,624 epoch 2 - iter 33/37 - loss 0.85871731 - samples/sec: 64.97\n",
            "2020-05-28 01:55:43,358 epoch 2 - iter 36/37 - loss 0.84229453 - samples/sec: 63.39\n",
            "2020-05-28 01:55:56,085 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:55:56,088 EPOCH 2 done: loss 0.8345 - lr 0.0500000\n",
            "2020-05-28 01:55:58,844 DEV : loss 1.1538550853729248 - score 0.7143\n",
            "2020-05-28 01:55:58,978 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-28 01:56:00,900 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:56:02,970 epoch 3 - iter 3/37 - loss 0.76308781 - samples/sec: 55.12\n",
            "2020-05-28 01:56:17,517 epoch 3 - iter 6/37 - loss 0.71059970 - samples/sec: 60.78\n",
            "2020-05-28 01:56:30,633 epoch 3 - iter 9/37 - loss 0.73607062 - samples/sec: 61.90\n",
            "2020-05-28 01:56:43,683 epoch 3 - iter 12/37 - loss 0.77806872 - samples/sec: 63.31\n",
            "2020-05-28 01:56:57,420 epoch 3 - iter 15/37 - loss 0.79194051 - samples/sec: 65.39\n",
            "2020-05-28 01:57:10,992 epoch 3 - iter 18/37 - loss 0.77144634 - samples/sec: 62.26\n",
            "2020-05-28 01:57:24,135 epoch 3 - iter 21/37 - loss 0.76448924 - samples/sec: 60.52\n",
            "2020-05-28 01:57:37,395 epoch 3 - iter 24/37 - loss 0.77348874 - samples/sec: 59.02\n",
            "2020-05-28 01:57:51,329 epoch 3 - iter 27/37 - loss 0.76014172 - samples/sec: 65.84\n",
            "2020-05-28 01:58:05,217 epoch 3 - iter 30/37 - loss 0.75343217 - samples/sec: 66.63\n",
            "2020-05-28 01:58:17,783 epoch 3 - iter 33/37 - loss 0.75385061 - samples/sec: 62.46\n",
            "2020-05-28 01:58:32,037 epoch 3 - iter 36/37 - loss 0.75814668 - samples/sec: 64.99\n",
            "2020-05-28 01:58:44,577 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:58:44,580 EPOCH 3 done: loss 0.7573 - lr 0.0500000\n",
            "2020-05-28 01:58:47,333 DEV : loss 0.8150318264961243 - score 0.7823\n",
            "2020-05-28 01:58:47,463 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-28 01:58:49,384 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 01:58:51,785 epoch 4 - iter 3/37 - loss 0.68882567 - samples/sec: 47.79\n",
            "2020-05-28 01:59:06,528 epoch 4 - iter 6/37 - loss 0.65051927 - samples/sec: 56.45\n",
            "2020-05-28 01:59:20,391 epoch 4 - iter 9/37 - loss 0.65031785 - samples/sec: 60.76\n",
            "2020-05-28 01:59:33,695 epoch 4 - iter 12/37 - loss 0.62747987 - samples/sec: 65.50\n",
            "2020-05-28 01:59:47,309 epoch 4 - iter 15/37 - loss 0.62544018 - samples/sec: 60.71\n",
            "2020-05-28 02:00:01,586 epoch 4 - iter 18/37 - loss 0.62387234 - samples/sec: 56.05\n",
            "2020-05-28 02:00:15,242 epoch 4 - iter 21/37 - loss 0.67584989 - samples/sec: 63.21\n",
            "2020-05-28 02:00:29,170 epoch 4 - iter 24/37 - loss 0.66352741 - samples/sec: 61.41\n",
            "2020-05-28 02:00:42,689 epoch 4 - iter 27/37 - loss 0.64740778 - samples/sec: 63.73\n",
            "2020-05-28 02:00:55,493 epoch 4 - iter 30/37 - loss 0.65324948 - samples/sec: 64.83\n",
            "2020-05-28 02:01:08,564 epoch 4 - iter 33/37 - loss 0.66239541 - samples/sec: 70.32\n",
            "2020-05-28 02:01:21,832 epoch 4 - iter 36/37 - loss 0.68211591 - samples/sec: 64.38\n",
            "2020-05-28 02:01:33,691 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:01:33,695 EPOCH 4 done: loss 0.6849 - lr 0.0500000\n",
            "2020-05-28 02:01:36,835 DEV : loss 0.7469678521156311 - score 0.7687\n",
            "2020-05-28 02:01:36,968 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 02:01:36,973 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:01:39,067 epoch 5 - iter 3/37 - loss 0.57836582 - samples/sec: 57.91\n",
            "2020-05-28 02:01:52,459 epoch 5 - iter 6/37 - loss 0.60565034 - samples/sec: 58.37\n",
            "2020-05-28 02:02:06,115 epoch 5 - iter 9/37 - loss 0.65135978 - samples/sec: 62.62\n",
            "2020-05-28 02:02:19,910 epoch 5 - iter 12/37 - loss 0.64761569 - samples/sec: 61.48\n",
            "2020-05-28 02:02:33,376 epoch 5 - iter 15/37 - loss 0.66398002 - samples/sec: 62.93\n",
            "2020-05-28 02:02:47,235 epoch 5 - iter 18/37 - loss 0.68517513 - samples/sec: 60.21\n",
            "2020-05-28 02:03:00,530 epoch 5 - iter 21/37 - loss 0.69032138 - samples/sec: 62.51\n",
            "2020-05-28 02:03:14,659 epoch 5 - iter 24/37 - loss 0.67610312 - samples/sec: 64.07\n",
            "2020-05-28 02:03:27,785 epoch 5 - iter 27/37 - loss 0.67045671 - samples/sec: 62.38\n",
            "2020-05-28 02:03:41,834 epoch 5 - iter 30/37 - loss 0.65332607 - samples/sec: 64.75\n",
            "2020-05-28 02:03:55,245 epoch 5 - iter 33/37 - loss 0.67390389 - samples/sec: 60.96\n",
            "2020-05-28 02:04:08,575 epoch 5 - iter 36/37 - loss 0.69217708 - samples/sec: 64.20\n",
            "2020-05-28 02:04:20,972 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:04:20,973 EPOCH 5 done: loss 0.7040 - lr 0.0500000\n",
            "2020-05-28 02:04:24,128 DEV : loss 0.9261205792427063 - score 0.6916\n",
            "2020-05-28 02:04:24,263 BAD EPOCHS (no improvement): 2\n",
            "2020-05-28 02:04:24,271 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:04:26,276 epoch 6 - iter 3/37 - loss 0.58944553 - samples/sec: 58.39\n",
            "2020-05-28 02:04:39,331 epoch 6 - iter 6/37 - loss 0.62145667 - samples/sec: 56.28\n",
            "2020-05-28 02:04:53,078 epoch 6 - iter 9/37 - loss 0.66568736 - samples/sec: 63.97\n",
            "2020-05-28 02:05:06,262 epoch 6 - iter 12/37 - loss 0.62554452 - samples/sec: 67.48\n",
            "2020-05-28 02:05:19,343 epoch 6 - iter 15/37 - loss 0.59166742 - samples/sec: 58.20\n",
            "2020-05-28 02:05:32,373 epoch 6 - iter 18/37 - loss 0.60396151 - samples/sec: 60.37\n",
            "2020-05-28 02:05:45,715 epoch 6 - iter 21/37 - loss 0.62741242 - samples/sec: 62.92\n",
            "2020-05-28 02:05:58,728 epoch 6 - iter 24/37 - loss 0.61828043 - samples/sec: 60.87\n",
            "2020-05-28 02:06:11,980 epoch 6 - iter 27/37 - loss 0.63198850 - samples/sec: 63.32\n",
            "2020-05-28 02:06:25,635 epoch 6 - iter 30/37 - loss 0.64168124 - samples/sec: 68.63\n",
            "2020-05-28 02:06:38,568 epoch 6 - iter 33/37 - loss 0.63514863 - samples/sec: 64.10\n",
            "2020-05-28 02:06:52,254 epoch 6 - iter 36/37 - loss 0.63539322 - samples/sec: 65.62\n",
            "2020-05-28 02:07:04,877 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:07:04,881 EPOCH 6 done: loss 0.6331 - lr 0.0500000\n",
            "2020-05-28 02:07:07,661 DEV : loss 1.0268752574920654 - score 0.6961\n",
            "2020-05-28 02:07:07,795 BAD EPOCHS (no improvement): 3\n",
            "2020-05-28 02:07:07,800 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:07:09,933 epoch 7 - iter 3/37 - loss 0.66600897 - samples/sec: 61.83\n",
            "2020-05-28 02:07:23,596 epoch 7 - iter 6/37 - loss 0.62634180 - samples/sec: 62.78\n",
            "2020-05-28 02:07:36,168 epoch 7 - iter 9/37 - loss 0.60453423 - samples/sec: 63.29\n",
            "2020-05-28 02:07:49,269 epoch 7 - iter 12/37 - loss 0.59046627 - samples/sec: 58.68\n",
            "2020-05-28 02:08:02,637 epoch 7 - iter 15/37 - loss 0.60015654 - samples/sec: 62.98\n",
            "2020-05-28 02:08:15,602 epoch 7 - iter 18/37 - loss 0.60547329 - samples/sec: 58.57\n",
            "2020-05-28 02:08:28,893 epoch 7 - iter 21/37 - loss 0.61006508 - samples/sec: 58.90\n",
            "2020-05-28 02:08:42,199 epoch 7 - iter 24/37 - loss 0.58369958 - samples/sec: 62.23\n",
            "2020-05-28 02:08:57,296 epoch 7 - iter 27/37 - loss 0.57718649 - samples/sec: 66.15\n",
            "2020-05-28 02:09:10,747 epoch 7 - iter 30/37 - loss 0.58104741 - samples/sec: 62.99\n",
            "2020-05-28 02:09:24,440 epoch 7 - iter 33/37 - loss 0.57631461 - samples/sec: 63.95\n",
            "2020-05-28 02:09:37,210 epoch 7 - iter 36/37 - loss 0.60374111 - samples/sec: 67.05\n",
            "2020-05-28 02:09:49,469 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:09:49,473 EPOCH 7 done: loss 0.6068 - lr 0.0500000\n",
            "2020-05-28 02:09:52,241 DEV : loss 0.9452976584434509 - score 0.7506\n",
            "Epoch     7: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-05-28 02:09:52,385 BAD EPOCHS (no improvement): 4\n",
            "2020-05-28 02:09:52,390 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:09:55,994 epoch 8 - iter 3/37 - loss 0.58351785 - samples/sec: 56.85\n",
            "2020-05-28 02:10:10,395 epoch 8 - iter 6/37 - loss 0.53395959 - samples/sec: 62.70\n",
            "2020-05-28 02:10:23,491 epoch 8 - iter 9/37 - loss 0.48815578 - samples/sec: 66.34\n",
            "2020-05-28 02:10:36,726 epoch 8 - iter 12/37 - loss 0.50304827 - samples/sec: 60.02\n",
            "2020-05-28 02:10:49,766 epoch 8 - iter 15/37 - loss 0.49527365 - samples/sec: 66.34\n",
            "2020-05-28 02:11:03,165 epoch 8 - iter 18/37 - loss 0.48999896 - samples/sec: 60.80\n",
            "2020-05-28 02:11:16,371 epoch 8 - iter 21/37 - loss 0.48718854 - samples/sec: 60.96\n",
            "2020-05-28 02:11:29,688 epoch 8 - iter 24/37 - loss 0.48957445 - samples/sec: 63.63\n",
            "2020-05-28 02:11:42,883 epoch 8 - iter 27/37 - loss 0.48931263 - samples/sec: 57.79\n",
            "2020-05-28 02:11:56,321 epoch 8 - iter 30/37 - loss 0.48527199 - samples/sec: 64.83\n",
            "2020-05-28 02:12:10,360 epoch 8 - iter 33/37 - loss 0.48658328 - samples/sec: 65.30\n",
            "2020-05-28 02:12:23,832 epoch 8 - iter 36/37 - loss 0.48477549 - samples/sec: 62.21\n",
            "2020-05-28 02:12:36,082 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:12:36,087 EPOCH 8 done: loss 0.4850 - lr 0.0250000\n",
            "2020-05-28 02:12:39,128 DEV : loss 0.762126624584198 - score 0.7732\n",
            "2020-05-28 02:12:39,267 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 02:12:39,272 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:12:41,208 epoch 9 - iter 3/37 - loss 0.40469352 - samples/sec: 59.69\n",
            "2020-05-28 02:12:54,930 epoch 9 - iter 6/37 - loss 0.34452086 - samples/sec: 62.96\n",
            "2020-05-28 02:13:09,583 epoch 9 - iter 9/37 - loss 0.37111395 - samples/sec: 52.47\n",
            "2020-05-28 02:13:22,483 epoch 9 - iter 12/37 - loss 0.39685442 - samples/sec: 61.61\n",
            "2020-05-28 02:13:36,473 epoch 9 - iter 15/37 - loss 0.41702487 - samples/sec: 65.90\n",
            "2020-05-28 02:13:50,254 epoch 9 - iter 18/37 - loss 0.44463618 - samples/sec: 60.54\n",
            "2020-05-28 02:14:04,642 epoch 9 - iter 21/37 - loss 0.45481670 - samples/sec: 65.78\n",
            "2020-05-28 02:14:18,663 epoch 9 - iter 24/37 - loss 0.43962522 - samples/sec: 64.49\n",
            "2020-05-28 02:14:32,311 epoch 9 - iter 27/37 - loss 0.43872472 - samples/sec: 64.69\n",
            "2020-05-28 02:14:45,538 epoch 9 - iter 30/37 - loss 0.43603266 - samples/sec: 60.56\n",
            "2020-05-28 02:14:59,786 epoch 9 - iter 33/37 - loss 0.43574614 - samples/sec: 64.04\n",
            "2020-05-28 02:15:14,213 epoch 9 - iter 36/37 - loss 0.43674685 - samples/sec: 65.37\n",
            "2020-05-28 02:15:26,674 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:15:26,677 EPOCH 9 done: loss 0.4411 - lr 0.0250000\n",
            "2020-05-28 02:15:30,648 DEV : loss 0.8327164053916931 - score 0.7551\n",
            "2020-05-28 02:15:30,790 BAD EPOCHS (no improvement): 2\n",
            "2020-05-28 02:15:30,796 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:15:32,709 epoch 10 - iter 3/37 - loss 0.43164535 - samples/sec: 60.62\n",
            "2020-05-28 02:15:45,923 epoch 10 - iter 6/37 - loss 0.42333687 - samples/sec: 61.23\n",
            "2020-05-28 02:16:00,040 epoch 10 - iter 9/37 - loss 0.41291755 - samples/sec: 55.18\n",
            "2020-05-28 02:16:13,287 epoch 10 - iter 12/37 - loss 0.40335203 - samples/sec: 63.88\n",
            "2020-05-28 02:16:26,612 epoch 10 - iter 15/37 - loss 0.38455201 - samples/sec: 64.91\n",
            "2020-05-28 02:16:40,222 epoch 10 - iter 18/37 - loss 0.39769477 - samples/sec: 63.11\n",
            "2020-05-28 02:16:53,930 epoch 10 - iter 21/37 - loss 0.42347472 - samples/sec: 54.25\n",
            "2020-05-28 02:17:07,406 epoch 10 - iter 24/37 - loss 0.42135762 - samples/sec: 63.40\n",
            "2020-05-28 02:17:21,517 epoch 10 - iter 27/37 - loss 0.43138146 - samples/sec: 60.62\n",
            "2020-05-28 02:17:35,640 epoch 10 - iter 30/37 - loss 0.42889111 - samples/sec: 61.96\n",
            "2020-05-28 02:17:48,963 epoch 10 - iter 33/37 - loss 0.43260554 - samples/sec: 56.79\n",
            "2020-05-28 02:18:02,473 epoch 10 - iter 36/37 - loss 0.42501950 - samples/sec: 61.19\n",
            "2020-05-28 02:18:15,519 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:18:15,522 EPOCH 10 done: loss 0.4218 - lr 0.0250000\n",
            "2020-05-28 02:18:18,297 DEV : loss 0.8165239691734314 - score 0.7778\n",
            "2020-05-28 02:18:18,432 BAD EPOCHS (no improvement): 3\n",
            "2020-05-28 02:18:18,436 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:18:20,644 epoch 11 - iter 3/37 - loss 0.26423881 - samples/sec: 59.72\n",
            "2020-05-28 02:18:33,775 epoch 11 - iter 6/37 - loss 0.31294659 - samples/sec: 59.71\n",
            "2020-05-28 02:18:46,846 epoch 11 - iter 9/37 - loss 0.32800786 - samples/sec: 59.32\n",
            "2020-05-28 02:19:00,059 epoch 11 - iter 12/37 - loss 0.35176612 - samples/sec: 67.14\n",
            "2020-05-28 02:19:14,661 epoch 11 - iter 15/37 - loss 0.37952005 - samples/sec: 62.22\n",
            "2020-05-28 02:19:28,308 epoch 11 - iter 18/37 - loss 0.40099830 - samples/sec: 56.75\n",
            "2020-05-28 02:19:41,760 epoch 11 - iter 21/37 - loss 0.40014810 - samples/sec: 60.41\n",
            "2020-05-28 02:19:54,914 epoch 11 - iter 24/37 - loss 0.40041303 - samples/sec: 63.19\n",
            "2020-05-28 02:20:08,720 epoch 11 - iter 27/37 - loss 0.40630810 - samples/sec: 60.83\n",
            "2020-05-28 02:20:22,521 epoch 11 - iter 30/37 - loss 0.40653646 - samples/sec: 62.60\n",
            "2020-05-28 02:20:36,466 epoch 11 - iter 33/37 - loss 0.40925828 - samples/sec: 64.06\n",
            "2020-05-28 02:20:49,667 epoch 11 - iter 36/37 - loss 0.40430182 - samples/sec: 65.55\n",
            "2020-05-28 02:21:02,564 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:21:02,565 EPOCH 11 done: loss 0.4000 - lr 0.0250000\n",
            "2020-05-28 02:21:05,357 DEV : loss 0.930494487285614 - score 0.7732\n",
            "Epoch    11: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-05-28 02:21:05,487 BAD EPOCHS (no improvement): 4\n",
            "2020-05-28 02:21:05,492 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:21:08,933 epoch 12 - iter 3/37 - loss 0.42957103 - samples/sec: 60.74\n",
            "2020-05-28 02:21:22,707 epoch 12 - iter 6/37 - loss 0.39597157 - samples/sec: 67.45\n",
            "2020-05-28 02:21:36,126 epoch 12 - iter 9/37 - loss 0.40073874 - samples/sec: 60.64\n",
            "2020-05-28 02:21:49,545 epoch 12 - iter 12/37 - loss 0.37644238 - samples/sec: 65.93\n",
            "2020-05-28 02:22:03,773 epoch 12 - iter 15/37 - loss 0.38885056 - samples/sec: 60.65\n",
            "2020-05-28 02:22:16,954 epoch 12 - iter 18/37 - loss 0.38471082 - samples/sec: 61.83\n",
            "2020-05-28 02:22:30,267 epoch 12 - iter 21/37 - loss 0.37189149 - samples/sec: 61.05\n",
            "2020-05-28 02:22:43,299 epoch 12 - iter 24/37 - loss 0.37378435 - samples/sec: 61.89\n",
            "2020-05-28 02:22:56,867 epoch 12 - iter 27/37 - loss 0.37828079 - samples/sec: 63.29\n",
            "2020-05-28 02:23:10,474 epoch 12 - iter 30/37 - loss 0.37760085 - samples/sec: 58.59\n",
            "2020-05-28 02:23:23,920 epoch 12 - iter 33/37 - loss 0.37139855 - samples/sec: 60.49\n",
            "2020-05-28 02:23:36,640 epoch 12 - iter 36/37 - loss 0.36178903 - samples/sec: 69.22\n",
            "2020-05-28 02:23:48,402 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:23:48,410 EPOCH 12 done: loss 0.3586 - lr 0.0125000\n",
            "2020-05-28 02:23:51,495 DEV : loss 0.8186808824539185 - score 0.7914\n",
            "2020-05-28 02:23:51,642 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-28 02:23:53,590 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:23:55,740 epoch 13 - iter 3/37 - loss 0.32176601 - samples/sec: 55.88\n",
            "2020-05-28 02:24:10,258 epoch 13 - iter 6/37 - loss 0.33622374 - samples/sec: 62.90\n",
            "2020-05-28 02:24:24,548 epoch 13 - iter 9/37 - loss 0.34971332 - samples/sec: 58.75\n",
            "2020-05-28 02:24:38,202 epoch 13 - iter 12/37 - loss 0.34878034 - samples/sec: 55.84\n",
            "2020-05-28 02:24:51,426 epoch 13 - iter 15/37 - loss 0.32974271 - samples/sec: 61.67\n",
            "2020-05-28 02:25:04,726 epoch 13 - iter 18/37 - loss 0.34216555 - samples/sec: 62.65\n",
            "2020-05-28 02:25:18,829 epoch 13 - iter 21/37 - loss 0.34945370 - samples/sec: 61.07\n",
            "2020-05-28 02:25:33,615 epoch 13 - iter 24/37 - loss 0.35522493 - samples/sec: 63.75\n",
            "2020-05-28 02:25:47,870 epoch 13 - iter 27/37 - loss 0.35978266 - samples/sec: 62.79\n",
            "2020-05-28 02:26:01,103 epoch 13 - iter 30/37 - loss 0.34803375 - samples/sec: 60.20\n",
            "2020-05-28 02:26:14,251 epoch 13 - iter 33/37 - loss 0.34539532 - samples/sec: 69.47\n",
            "2020-05-28 02:26:27,983 epoch 13 - iter 36/37 - loss 0.34272347 - samples/sec: 64.10\n",
            "2020-05-28 02:26:39,947 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:26:39,948 EPOCH 13 done: loss 0.3419 - lr 0.0125000\n",
            "2020-05-28 02:26:42,795 DEV : loss 0.901214599609375 - score 0.7823\n",
            "2020-05-28 02:26:42,941 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 02:26:42,945 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:26:44,871 epoch 14 - iter 3/37 - loss 0.28213541 - samples/sec: 62.21\n",
            "2020-05-28 02:26:58,686 epoch 14 - iter 6/37 - loss 0.28319896 - samples/sec: 52.25\n",
            "2020-05-28 02:27:11,725 epoch 14 - iter 9/37 - loss 0.32564566 - samples/sec: 65.00\n",
            "2020-05-28 02:27:25,050 epoch 14 - iter 12/37 - loss 0.30934653 - samples/sec: 64.07\n",
            "2020-05-28 02:27:38,021 epoch 14 - iter 15/37 - loss 0.31201284 - samples/sec: 59.71\n",
            "2020-05-28 02:27:51,588 epoch 14 - iter 18/37 - loss 0.31404533 - samples/sec: 62.30\n",
            "2020-05-28 02:28:04,661 epoch 14 - iter 21/37 - loss 0.31765742 - samples/sec: 58.86\n",
            "2020-05-28 02:28:18,266 epoch 14 - iter 24/37 - loss 0.32313589 - samples/sec: 65.33\n",
            "2020-05-28 02:28:31,423 epoch 14 - iter 27/37 - loss 0.32581713 - samples/sec: 64.98\n",
            "2020-05-28 02:28:44,780 epoch 14 - iter 30/37 - loss 0.32531424 - samples/sec: 67.53\n",
            "2020-05-28 02:28:58,610 epoch 14 - iter 33/37 - loss 0.33220289 - samples/sec: 59.83\n",
            "2020-05-28 02:29:12,145 epoch 14 - iter 36/37 - loss 0.33218864 - samples/sec: 61.10\n",
            "2020-05-28 02:29:24,248 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:29:24,249 EPOCH 14 done: loss 0.3274 - lr 0.0125000\n",
            "2020-05-28 02:29:27,061 DEV : loss 0.8072444200515747 - score 0.8005\n",
            "2020-05-28 02:29:27,196 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-28 02:29:29,254 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:29:31,442 epoch 15 - iter 3/37 - loss 0.27642053 - samples/sec: 55.92\n",
            "2020-05-28 02:29:46,253 epoch 15 - iter 6/37 - loss 0.30034433 - samples/sec: 61.89\n",
            "2020-05-28 02:29:59,457 epoch 15 - iter 9/37 - loss 0.29453169 - samples/sec: 62.58\n",
            "2020-05-28 02:30:12,096 epoch 15 - iter 12/37 - loss 0.29987210 - samples/sec: 64.61\n",
            "2020-05-28 02:30:25,995 epoch 15 - iter 15/37 - loss 0.29894662 - samples/sec: 58.41\n",
            "2020-05-28 02:30:39,308 epoch 15 - iter 18/37 - loss 0.29668860 - samples/sec: 61.93\n",
            "2020-05-28 02:30:52,900 epoch 15 - iter 21/37 - loss 0.30189387 - samples/sec: 62.21\n",
            "2020-05-28 02:31:06,050 epoch 15 - iter 24/37 - loss 0.29971749 - samples/sec: 59.75\n",
            "2020-05-28 02:31:19,257 epoch 15 - iter 27/37 - loss 0.30770940 - samples/sec: 62.98\n",
            "2020-05-28 02:31:32,170 epoch 15 - iter 30/37 - loss 0.30142216 - samples/sec: 57.24\n",
            "2020-05-28 02:31:45,366 epoch 15 - iter 33/37 - loss 0.30915122 - samples/sec: 61.22\n",
            "2020-05-28 02:31:58,741 epoch 15 - iter 36/37 - loss 0.30971410 - samples/sec: 63.49\n",
            "2020-05-28 02:32:10,420 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:32:10,421 EPOCH 15 done: loss 0.3043 - lr 0.0125000\n",
            "2020-05-28 02:32:13,192 DEV : loss 0.8259391784667969 - score 0.7914\n",
            "2020-05-28 02:32:13,326 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 02:32:26,462 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:32:26,467 Testing using best model ...\n",
            "2020-05-28 02:32:26,471 loading file drive/My Drive/Colab Notebooks/capstone/data/best-model.pt\n",
            "2020-05-28 02:32:30,816 0.6301369863013698\t0.6301369863013698\t0.6301369863013698\n",
            "2020-05-28 02:32:30,821 \n",
            "MICRO_AVG: acc 0.7534246575342466 - f1-score 0.6301369863013698\n",
            "MACRO_AVG: acc 0.7534246575342465 - f1-score 0.6358490566037736\n",
            "-1         tp: 36 - fp: 17 - fn: 17 - tn: 76 - precision: 0.6792 - recall: 0.6792 - accuracy: 0.7671 - f1-score: 0.6792\n",
            "0          tp: 28 - fp: 14 - fn: 10 - tn: 94 - precision: 0.6667 - recall: 0.7368 - accuracy: 0.8356 - f1-score: 0.7000\n",
            "1          tp: 28 - fp: 23 - fn: 27 - tn: 68 - precision: 0.5490 - recall: 0.5091 - accuracy: 0.6575 - f1-score: 0.5283\n",
            "2020-05-28 02:32:30,824 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.9019950032234192,\n",
              "  1.1538550853729248,\n",
              "  0.8150318264961243,\n",
              "  0.7469678521156311,\n",
              "  0.9261205792427063,\n",
              "  1.0268752574920654,\n",
              "  0.9452976584434509,\n",
              "  0.762126624584198,\n",
              "  0.8327164053916931,\n",
              "  0.8165239691734314,\n",
              "  0.930494487285614,\n",
              "  0.8186808824539185,\n",
              "  0.901214599609375,\n",
              "  0.8072444200515747,\n",
              "  0.8259391784667969],\n",
              " 'dev_score_history': [0.7006802721088435,\n",
              "  0.7142857142857143,\n",
              "  0.782312925170068,\n",
              "  0.7687074829931972,\n",
              "  0.691609977324263,\n",
              "  0.6961451247165533,\n",
              "  0.7505668934240363,\n",
              "  0.7732426303854876,\n",
              "  0.7551020408163265,\n",
              "  0.7777777777777778,\n",
              "  0.7732426303854876,\n",
              "  0.7913832199546486,\n",
              "  0.782312925170068,\n",
              "  0.800453514739229,\n",
              "  0.7913832199546486],\n",
              " 'test_score': 0.7534246575342466,\n",
              " 'train_loss_history': [1.0146753707447567,\n",
              "  0.8344538695103413,\n",
              "  0.7572574841009604,\n",
              "  0.6848842445257548,\n",
              "  0.7039970771686451,\n",
              "  0.6330873716521908,\n",
              "  0.6067641562706715,\n",
              "  0.4849680855467513,\n",
              "  0.44107394927256816,\n",
              "  0.4217929240014102,\n",
              "  0.39998088172964147,\n",
              "  0.3585525291997033,\n",
              "  0.3418691077747861,\n",
              "  0.32738670344288284,\n",
              "  0.30430523306131363]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2JikhOEZFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5maM-7gQWqJ",
        "colab_type": "text"
      },
      "source": [
        "### Second Stage (train on hand annotated datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbrXhSRlnCR3",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0E6iEy9UgYP",
        "colab_type": "code",
        "outputId": "5a8d2a59-cc82-4e19-c5df-d0c72ebc5e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "new_data_folder = \"./drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled\"\n",
        "new_column_name_map = {5: \"text\", 4: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(new_data_folder,\n",
        "                                         new_column_name_map,\n",
        "                                         skip_header=True, #yes header in \n",
        "                                         delimiter=',',    # comma separated rows\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 02:53:45,186 Reading data from drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled\n",
            "2020-05-28 02:53:45,187 Train: drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/train.csv\n",
            "2020-05-28 02:53:45,189 Dev: drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/dev.csv\n",
            "2020-05-28 02:53:45,190 Test: drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGDir71nHb6",
        "colab_type": "text"
      },
      "source": [
        "#### Second Stage fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWg4fjqNYMKa",
        "colab_type": "code",
        "outputId": "76eec3f2-df7a-477e-ef3a-3179af02077e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# benchmark_embeddings = FlairEmbeddings(data_folder + 'best-model.pt')\n",
        "#data_folder = wherever the best-model.pt is put\n",
        "\n",
        "benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 02:53:56,331 loading file ./drive/My Drive/Colab Notebooks/capstone/data/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1XWYH6QZGl",
        "colab_type": "code",
        "outputId": "9af31f8f-fd2b-461d-b2c9-274a258db17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer = ModelTrainer(benchmark_classifier, corpus)\n",
        "trainer.train(new_data_folder, \n",
        "              learning_rate=0.05,\n",
        "              max_epochs=20)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 02:54:08,202 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:54:08,208 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-28 02:54:08,209 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:54:08,210 Corpus: \"Corpus: 165 train + 25 dev + 25 test sentences\"\n",
            "2020-05-28 02:54:08,211 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:54:08,212 Parameters:\n",
            "2020-05-28 02:54:08,213  - learning_rate: \"0.05\"\n",
            "2020-05-28 02:54:08,214  - mini_batch_size: \"32\"\n",
            "2020-05-28 02:54:08,215  - patience: \"3\"\n",
            "2020-05-28 02:54:08,216  - anneal_factor: \"0.5\"\n",
            "2020-05-28 02:54:08,217  - max_epochs: \"20\"\n",
            "2020-05-28 02:54:08,218  - shuffle: \"True\"\n",
            "2020-05-28 02:54:08,222  - train_with_dev: \"False\"\n",
            "2020-05-28 02:54:08,223  - batch_growth_annealing: \"False\"\n",
            "2020-05-28 02:54:08,224 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:54:08,225 Model training base path: \"drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled\"\n",
            "2020-05-28 02:54:08,226 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:54:08,227 Device: cuda:0\n",
            "2020-05-28 02:54:08,228 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:54:08,229 Embeddings storage mode: cpu\n",
            "2020-05-28 02:54:08,246 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:54:09,201 epoch 1 - iter 1/6 - loss 3.10564065 - samples/sec: 47.53\n",
            "2020-05-28 02:54:21,654 epoch 1 - iter 2/6 - loss 2.24775201 - samples/sec: 60.58\n",
            "2020-05-28 02:54:33,769 epoch 1 - iter 3/6 - loss 1.79770851 - samples/sec: 60.03\n",
            "2020-05-28 02:54:46,100 epoch 1 - iter 4/6 - loss 1.65529799 - samples/sec: 62.37\n",
            "2020-05-28 02:54:58,451 epoch 1 - iter 5/6 - loss 1.63784516 - samples/sec: 61.11\n",
            "2020-05-28 02:55:10,351 epoch 1 - iter 6/6 - loss 1.71376489 - samples/sec: 187.41\n",
            "2020-05-28 02:55:22,654 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:55:22,656 EPOCH 1 done: loss 1.7138 - lr 0.0500000\n",
            "2020-05-28 02:55:23,453 DEV : loss 1.811440110206604 - score 0.52\n",
            "2020-05-28 02:55:23,485 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-28 02:55:25,536 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:55:26,521 epoch 2 - iter 1/6 - loss 0.90219784 - samples/sec: 50.65\n",
            "2020-05-28 02:55:40,351 epoch 2 - iter 2/6 - loss 1.11555183 - samples/sec: 55.25\n",
            "2020-05-28 02:55:53,545 epoch 2 - iter 3/6 - loss 0.97015160 - samples/sec: 61.74\n",
            "2020-05-28 02:56:06,463 epoch 2 - iter 4/6 - loss 1.09868653 - samples/sec: 64.68\n",
            "2020-05-28 02:56:19,143 epoch 2 - iter 5/6 - loss 1.27564255 - samples/sec: 60.77\n",
            "2020-05-28 02:56:30,907 epoch 2 - iter 6/6 - loss 1.42637071 - samples/sec: 220.89\n",
            "2020-05-28 02:56:43,279 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:56:43,283 EPOCH 2 done: loss 1.4264 - lr 0.0500000\n",
            "2020-05-28 02:56:44,040 DEV : loss 2.0882046222686768 - score 0.5467\n",
            "2020-05-28 02:56:44,069 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-28 02:56:46,077 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:56:46,993 epoch 3 - iter 1/6 - loss 0.78626245 - samples/sec: 50.78\n",
            "2020-05-28 02:57:01,041 epoch 3 - iter 2/6 - loss 1.11273155 - samples/sec: 48.42\n",
            "2020-05-28 02:57:13,905 epoch 3 - iter 3/6 - loss 1.03037212 - samples/sec: 60.42\n",
            "2020-05-28 02:57:26,003 epoch 3 - iter 4/6 - loss 0.95262453 - samples/sec: 56.22\n",
            "2020-05-28 02:57:38,342 epoch 3 - iter 5/6 - loss 0.96468284 - samples/sec: 62.28\n",
            "2020-05-28 02:57:50,806 epoch 3 - iter 6/6 - loss 0.95127424 - samples/sec: 227.87\n",
            "2020-05-28 02:58:03,219 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:58:03,223 EPOCH 3 done: loss 0.9513 - lr 0.0500000\n",
            "2020-05-28 02:58:04,014 DEV : loss 1.1117914915084839 - score 0.7867\n",
            "2020-05-28 02:58:04,046 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-28 02:58:05,996 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:58:06,930 epoch 4 - iter 1/6 - loss 0.66106564 - samples/sec: 49.02\n",
            "2020-05-28 02:58:19,967 epoch 4 - iter 2/6 - loss 0.60338554 - samples/sec: 62.42\n",
            "2020-05-28 02:58:32,814 epoch 4 - iter 3/6 - loss 0.76435727 - samples/sec: 62.41\n",
            "2020-05-28 02:58:45,416 epoch 4 - iter 4/6 - loss 0.83697249 - samples/sec: 59.24\n",
            "2020-05-28 02:58:57,465 epoch 4 - iter 5/6 - loss 0.82217233 - samples/sec: 59.76\n",
            "2020-05-28 02:59:09,734 epoch 4 - iter 6/6 - loss 0.82076061 - samples/sec: 234.26\n",
            "2020-05-28 02:59:21,724 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:59:21,725 EPOCH 4 done: loss 0.8208 - lr 0.0500000\n",
            "2020-05-28 02:59:22,528 DEV : loss 0.9923803210258484 - score 0.7333\n",
            "2020-05-28 02:59:22,563 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 02:59:22,568 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 02:59:23,386 epoch 5 - iter 1/6 - loss 0.51885980 - samples/sec: 68.44\n",
            "2020-05-28 02:59:36,729 epoch 5 - iter 2/6 - loss 0.50318588 - samples/sec: 55.03\n",
            "2020-05-28 02:59:49,776 epoch 5 - iter 3/6 - loss 0.54415211 - samples/sec: 51.71\n",
            "2020-05-28 03:00:02,252 epoch 5 - iter 4/6 - loss 0.52633785 - samples/sec: 58.25\n",
            "2020-05-28 03:00:14,849 epoch 5 - iter 5/6 - loss 0.56130552 - samples/sec: 56.24\n",
            "2020-05-28 03:00:27,762 epoch 5 - iter 6/6 - loss 0.62680806 - samples/sec: 207.48\n",
            "2020-05-28 03:00:41,646 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:00:41,653 EPOCH 5 done: loss 0.6268 - lr 0.0500000\n",
            "2020-05-28 03:00:42,417 DEV : loss 1.1513042449951172 - score 0.6533\n",
            "2020-05-28 03:00:42,447 BAD EPOCHS (no improvement): 2\n",
            "2020-05-28 03:00:42,452 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:00:43,304 epoch 6 - iter 1/6 - loss 0.21905085 - samples/sec: 63.96\n",
            "2020-05-28 03:00:56,237 epoch 6 - iter 2/6 - loss 0.27910769 - samples/sec: 64.37\n",
            "2020-05-28 03:01:08,487 epoch 6 - iter 3/6 - loss 0.30267723 - samples/sec: 60.34\n",
            "2020-05-28 03:01:21,499 epoch 6 - iter 4/6 - loss 0.31990094 - samples/sec: 58.05\n",
            "2020-05-28 03:01:33,453 epoch 6 - iter 5/6 - loss 0.41120387 - samples/sec: 60.06\n",
            "2020-05-28 03:01:46,256 epoch 6 - iter 6/6 - loss 0.38925520 - samples/sec: 185.35\n",
            "2020-05-28 03:01:58,511 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:01:58,516 EPOCH 6 done: loss 0.3893 - lr 0.0500000\n",
            "2020-05-28 03:01:59,865 DEV : loss 1.442038893699646 - score 0.6533\n",
            "2020-05-28 03:01:59,899 BAD EPOCHS (no improvement): 3\n",
            "2020-05-28 03:01:59,902 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:02:00,633 epoch 7 - iter 1/6 - loss 0.54223752 - samples/sec: 71.30\n",
            "2020-05-28 03:02:13,397 epoch 7 - iter 2/6 - loss 0.59493527 - samples/sec: 53.52\n",
            "2020-05-28 03:02:26,228 epoch 7 - iter 3/6 - loss 0.62867930 - samples/sec: 63.24\n",
            "2020-05-28 03:02:38,868 epoch 7 - iter 4/6 - loss 0.58215664 - samples/sec: 52.18\n",
            "2020-05-28 03:02:51,287 epoch 7 - iter 5/6 - loss 0.53487862 - samples/sec: 64.12\n",
            "2020-05-28 03:03:03,283 epoch 7 - iter 6/6 - loss 0.49492125 - samples/sec: 226.70\n",
            "2020-05-28 03:03:15,449 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:03:15,450 EPOCH 7 done: loss 0.4949 - lr 0.0500000\n",
            "2020-05-28 03:03:16,228 DEV : loss 1.5963996648788452 - score 0.68\n",
            "Epoch     7: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-05-28 03:03:16,256 BAD EPOCHS (no improvement): 4\n",
            "2020-05-28 03:03:16,261 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:03:17,049 epoch 8 - iter 1/6 - loss 0.68803030 - samples/sec: 62.91\n",
            "2020-05-28 03:03:29,961 epoch 8 - iter 2/6 - loss 0.40170440 - samples/sec: 55.49\n",
            "2020-05-28 03:03:43,319 epoch 8 - iter 3/6 - loss 0.33722375 - samples/sec: 61.14\n",
            "2020-05-28 03:03:55,855 epoch 8 - iter 4/6 - loss 0.33536978 - samples/sec: 55.30\n",
            "2020-05-28 03:04:08,717 epoch 8 - iter 5/6 - loss 0.31250834 - samples/sec: 51.53\n",
            "2020-05-28 03:04:21,095 epoch 8 - iter 6/6 - loss 0.34632398 - samples/sec: 224.16\n",
            "2020-05-28 03:04:33,861 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:04:33,865 EPOCH 8 done: loss 0.3463 - lr 0.0250000\n",
            "2020-05-28 03:04:35,209 DEV : loss 1.0166499614715576 - score 0.76\n",
            "2020-05-28 03:04:35,249 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 03:04:35,255 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:04:36,100 epoch 9 - iter 1/6 - loss 0.19477713 - samples/sec: 63.29\n",
            "2020-05-28 03:04:49,534 epoch 9 - iter 2/6 - loss 0.19357381 - samples/sec: 55.81\n",
            "2020-05-28 03:05:02,701 epoch 9 - iter 3/6 - loss 0.21475890 - samples/sec: 60.86\n",
            "2020-05-28 03:05:14,948 epoch 9 - iter 4/6 - loss 0.20844624 - samples/sec: 61.93\n",
            "2020-05-28 03:05:27,321 epoch 9 - iter 5/6 - loss 0.20335724 - samples/sec: 59.42\n",
            "2020-05-28 03:05:39,316 epoch 9 - iter 6/6 - loss 0.25401831 - samples/sec: 229.47\n",
            "2020-05-28 03:05:53,381 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:05:53,383 EPOCH 9 done: loss 0.2540 - lr 0.0250000\n",
            "2020-05-28 03:05:54,125 DEV : loss 1.0162858963012695 - score 0.76\n",
            "2020-05-28 03:05:54,154 BAD EPOCHS (no improvement): 2\n",
            "2020-05-28 03:05:54,158 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:05:54,996 epoch 10 - iter 1/6 - loss 0.12064578 - samples/sec: 56.63\n",
            "2020-05-28 03:06:08,291 epoch 10 - iter 2/6 - loss 0.15294114 - samples/sec: 56.27\n",
            "2020-05-28 03:06:20,745 epoch 10 - iter 3/6 - loss 0.13227950 - samples/sec: 61.92\n",
            "2020-05-28 03:06:33,303 epoch 10 - iter 4/6 - loss 0.16948650 - samples/sec: 64.70\n",
            "2020-05-28 03:06:46,536 epoch 10 - iter 5/6 - loss 0.18116388 - samples/sec: 60.46\n",
            "2020-05-28 03:06:58,719 epoch 10 - iter 6/6 - loss 0.19311242 - samples/sec: 213.28\n",
            "2020-05-28 03:07:11,091 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:07:11,093 EPOCH 10 done: loss 0.1931 - lr 0.0250000\n",
            "2020-05-28 03:07:11,878 DEV : loss 1.1404460668563843 - score 0.7867\n",
            "2020-05-28 03:07:11,918 BAD EPOCHS (no improvement): 3\n",
            "2020-05-28 03:07:11,924 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:07:12,787 epoch 11 - iter 1/6 - loss 0.26568478 - samples/sec: 57.34\n",
            "2020-05-28 03:07:25,191 epoch 11 - iter 2/6 - loss 0.18801435 - samples/sec: 59.78\n",
            "2020-05-28 03:07:38,067 epoch 11 - iter 3/6 - loss 0.19088905 - samples/sec: 59.66\n",
            "2020-05-28 03:07:50,837 epoch 11 - iter 4/6 - loss 0.17168897 - samples/sec: 59.51\n",
            "2020-05-28 03:08:04,023 epoch 11 - iter 5/6 - loss 0.16638561 - samples/sec: 57.68\n",
            "2020-05-28 03:08:16,439 epoch 11 - iter 6/6 - loss 0.16797467 - samples/sec: 206.25\n",
            "2020-05-28 03:08:28,399 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:08:28,403 EPOCH 11 done: loss 0.1680 - lr 0.0250000\n",
            "2020-05-28 03:08:29,153 DEV : loss 1.3253134489059448 - score 0.6533\n",
            "Epoch    11: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-05-28 03:08:29,191 BAD EPOCHS (no improvement): 4\n",
            "2020-05-28 03:08:29,196 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:08:29,984 epoch 12 - iter 1/6 - loss 0.13469511 - samples/sec: 66.89\n",
            "2020-05-28 03:08:42,548 epoch 12 - iter 2/6 - loss 0.12432185 - samples/sec: 61.25\n",
            "2020-05-28 03:08:55,031 epoch 12 - iter 3/6 - loss 0.14596565 - samples/sec: 57.27\n",
            "2020-05-28 03:09:07,273 epoch 12 - iter 4/6 - loss 0.15253596 - samples/sec: 54.84\n",
            "2020-05-28 03:09:19,323 epoch 12 - iter 5/6 - loss 0.14840778 - samples/sec: 61.34\n",
            "2020-05-28 03:09:31,118 epoch 12 - iter 6/6 - loss 0.13535491 - samples/sec: 179.87\n",
            "2020-05-28 03:09:43,584 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:09:43,585 EPOCH 12 done: loss 0.1354 - lr 0.0125000\n",
            "2020-05-28 03:09:44,640 DEV : loss 1.1137051582336426 - score 0.6533\n",
            "2020-05-28 03:09:44,671 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 03:09:44,675 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:09:45,482 epoch 13 - iter 1/6 - loss 0.15314701 - samples/sec: 65.63\n",
            "2020-05-28 03:09:57,450 epoch 13 - iter 2/6 - loss 0.14507085 - samples/sec: 63.06\n",
            "2020-05-28 03:10:10,853 epoch 13 - iter 3/6 - loss 0.12882649 - samples/sec: 56.03\n",
            "2020-05-28 03:10:23,300 epoch 13 - iter 4/6 - loss 0.13641292 - samples/sec: 61.73\n",
            "2020-05-28 03:10:35,898 epoch 13 - iter 5/6 - loss 0.13671029 - samples/sec: 54.97\n",
            "2020-05-28 03:10:47,926 epoch 13 - iter 6/6 - loss 0.14494878 - samples/sec: 203.44\n",
            "2020-05-28 03:11:02,200 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:11:02,202 EPOCH 13 done: loss 0.1449 - lr 0.0125000\n",
            "2020-05-28 03:11:02,964 DEV : loss 1.0922951698303223 - score 0.68\n",
            "2020-05-28 03:11:03,003 BAD EPOCHS (no improvement): 2\n",
            "2020-05-28 03:11:03,008 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:11:03,767 epoch 14 - iter 1/6 - loss 0.09212555 - samples/sec: 63.25\n",
            "2020-05-28 03:11:16,356 epoch 14 - iter 2/6 - loss 0.14081588 - samples/sec: 58.61\n",
            "2020-05-28 03:11:28,904 epoch 14 - iter 3/6 - loss 0.11583765 - samples/sec: 54.42\n",
            "2020-05-28 03:11:41,417 epoch 14 - iter 4/6 - loss 0.11313756 - samples/sec: 57.31\n",
            "2020-05-28 03:11:53,909 epoch 14 - iter 5/6 - loss 0.11161168 - samples/sec: 58.25\n",
            "2020-05-28 03:12:05,883 epoch 14 - iter 6/6 - loss 0.10057791 - samples/sec: 211.69\n",
            "2020-05-28 03:12:17,654 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:12:17,658 EPOCH 14 done: loss 0.1006 - lr 0.0125000\n",
            "2020-05-28 03:12:18,403 DEV : loss 1.110708475112915 - score 0.6533\n",
            "2020-05-28 03:12:18,432 BAD EPOCHS (no improvement): 3\n",
            "2020-05-28 03:12:18,436 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:12:19,565 epoch 15 - iter 1/6 - loss 0.07094371 - samples/sec: 65.94\n",
            "2020-05-28 03:12:32,252 epoch 15 - iter 2/6 - loss 0.08021223 - samples/sec: 60.68\n",
            "2020-05-28 03:12:46,012 epoch 15 - iter 3/6 - loss 0.08271502 - samples/sec: 60.52\n",
            "2020-05-28 03:12:58,967 epoch 15 - iter 4/6 - loss 0.08824816 - samples/sec: 60.88\n",
            "2020-05-28 03:13:11,415 epoch 15 - iter 5/6 - loss 0.10005146 - samples/sec: 60.70\n",
            "2020-05-28 03:13:23,156 epoch 15 - iter 6/6 - loss 0.09089661 - samples/sec: 173.06\n",
            "2020-05-28 03:13:35,121 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:13:35,126 EPOCH 15 done: loss 0.0909 - lr 0.0125000\n",
            "2020-05-28 03:13:35,896 DEV : loss 1.1028305292129517 - score 0.7067\n",
            "Epoch    15: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-05-28 03:13:35,926 BAD EPOCHS (no improvement): 4\n",
            "2020-05-28 03:13:35,931 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:13:36,736 epoch 16 - iter 1/6 - loss 0.17079657 - samples/sec: 63.37\n",
            "2020-05-28 03:13:49,607 epoch 16 - iter 2/6 - loss 0.12167060 - samples/sec: 58.94\n",
            "2020-05-28 03:14:02,080 epoch 16 - iter 3/6 - loss 0.11178646 - samples/sec: 59.85\n",
            "2020-05-28 03:14:15,113 epoch 16 - iter 4/6 - loss 0.11224450 - samples/sec: 56.16\n",
            "2020-05-28 03:14:27,956 epoch 16 - iter 5/6 - loss 0.11442808 - samples/sec: 61.83\n",
            "2020-05-28 03:14:41,106 epoch 16 - iter 6/6 - loss 0.10162134 - samples/sec: 273.64\n",
            "2020-05-28 03:14:53,483 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:14:53,486 EPOCH 16 done: loss 0.1016 - lr 0.0062500\n",
            "2020-05-28 03:14:54,222 DEV : loss 1.1079765558242798 - score 0.68\n",
            "2020-05-28 03:14:54,255 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 03:14:54,393 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:14:55,199 epoch 17 - iter 1/6 - loss 0.09472555 - samples/sec: 62.26\n",
            "2020-05-28 03:15:08,568 epoch 17 - iter 2/6 - loss 0.13002031 - samples/sec: 61.24\n",
            "2020-05-28 03:15:21,062 epoch 17 - iter 3/6 - loss 0.11751722 - samples/sec: 56.06\n",
            "2020-05-28 03:15:34,138 epoch 17 - iter 4/6 - loss 0.10638249 - samples/sec: 58.37\n",
            "2020-05-28 03:15:46,670 epoch 17 - iter 5/6 - loss 0.10679577 - samples/sec: 62.92\n",
            "2020-05-28 03:15:59,650 epoch 17 - iter 6/6 - loss 0.09327372 - samples/sec: 265.08\n",
            "2020-05-28 03:16:13,211 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:16:13,213 EPOCH 17 done: loss 0.0933 - lr 0.0062500\n",
            "2020-05-28 03:16:13,977 DEV : loss 1.1085872650146484 - score 0.68\n",
            "2020-05-28 03:16:14,005 BAD EPOCHS (no improvement): 2\n",
            "2020-05-28 03:16:14,009 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:16:14,795 epoch 18 - iter 1/6 - loss 0.04870404 - samples/sec: 67.98\n",
            "2020-05-28 03:16:27,884 epoch 18 - iter 2/6 - loss 0.08176420 - samples/sec: 56.67\n",
            "2020-05-28 03:16:40,198 epoch 18 - iter 3/6 - loss 0.10009388 - samples/sec: 55.95\n",
            "2020-05-28 03:16:53,876 epoch 18 - iter 4/6 - loss 0.09515629 - samples/sec: 62.20\n",
            "2020-05-28 03:17:06,276 epoch 18 - iter 5/6 - loss 0.08945093 - samples/sec: 56.48\n",
            "2020-05-28 03:17:19,180 epoch 18 - iter 6/6 - loss 0.08103054 - samples/sec: 182.18\n",
            "2020-05-28 03:17:30,847 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:17:30,850 EPOCH 18 done: loss 0.0810 - lr 0.0062500\n",
            "2020-05-28 03:17:31,636 DEV : loss 1.113206386566162 - score 0.7067\n",
            "2020-05-28 03:17:31,668 BAD EPOCHS (no improvement): 3\n",
            "2020-05-28 03:17:31,672 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:17:32,519 epoch 19 - iter 1/6 - loss 0.07827168 - samples/sec: 58.95\n",
            "2020-05-28 03:17:45,510 epoch 19 - iter 2/6 - loss 0.06234453 - samples/sec: 60.38\n",
            "2020-05-28 03:17:58,059 epoch 19 - iter 3/6 - loss 0.07441143 - samples/sec: 61.93\n",
            "2020-05-28 03:18:10,831 epoch 19 - iter 4/6 - loss 0.07117948 - samples/sec: 59.59\n",
            "2020-05-28 03:18:23,270 epoch 19 - iter 5/6 - loss 0.09801768 - samples/sec: 64.53\n",
            "2020-05-28 03:18:35,483 epoch 19 - iter 6/6 - loss 0.09227156 - samples/sec: 198.26\n",
            "2020-05-28 03:18:48,450 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:18:48,452 EPOCH 19 done: loss 0.0923 - lr 0.0062500\n",
            "2020-05-28 03:18:49,237 DEV : loss 1.094724416732788 - score 0.7333\n",
            "Epoch    19: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-05-28 03:18:49,268 BAD EPOCHS (no improvement): 4\n",
            "2020-05-28 03:18:49,272 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:18:50,062 epoch 20 - iter 1/6 - loss 0.12694003 - samples/sec: 61.39\n",
            "2020-05-28 03:19:02,813 epoch 20 - iter 2/6 - loss 0.11953995 - samples/sec: 51.61\n",
            "2020-05-28 03:19:15,650 epoch 20 - iter 3/6 - loss 0.12268541 - samples/sec: 52.65\n",
            "2020-05-28 03:19:28,781 epoch 20 - iter 4/6 - loss 0.10522909 - samples/sec: 56.67\n",
            "2020-05-28 03:19:42,026 epoch 20 - iter 5/6 - loss 0.10050799 - samples/sec: 52.62\n",
            "2020-05-28 03:19:54,908 epoch 20 - iter 6/6 - loss 0.08600429 - samples/sec: 229.11\n",
            "2020-05-28 03:20:07,191 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:20:07,192 EPOCH 20 done: loss 0.0860 - lr 0.0031250\n",
            "2020-05-28 03:20:07,942 DEV : loss 1.0950584411621094 - score 0.7333\n",
            "2020-05-28 03:20:07,975 BAD EPOCHS (no improvement): 1\n",
            "2020-05-28 03:20:09,920 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-28 03:20:09,922 Testing using best model ...\n",
            "2020-05-28 03:20:09,926 loading file drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/best-model.pt\n",
            "2020-05-28 03:20:12,061 0.68\t0.68\t0.68\n",
            "2020-05-28 03:20:12,066 \n",
            "MICRO_AVG: acc 0.7866666666666666 - f1-score 0.68\n",
            "MACRO_AVG: acc 0.7866666666666666 - f1-score 0.4259259259259259\n",
            "-1         tp: 3 - fp: 0 - fn: 6 - tn: 16 - precision: 1.0000 - recall: 0.3333 - accuracy: 0.7600 - f1-score: 0.5000\n",
            "0          tp: 14 - fp: 8 - fn: 0 - tn: 3 - precision: 0.6364 - recall: 1.0000 - accuracy: 0.6800 - f1-score: 0.7778\n",
            "1          tp: 0 - fp: 0 - fn: 2 - tn: 23 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.9200 - f1-score: 0.0000\n",
            "2020-05-28 03:20:12,069 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [1.811440110206604,\n",
              "  2.0882046222686768,\n",
              "  1.1117914915084839,\n",
              "  0.9923803210258484,\n",
              "  1.1513042449951172,\n",
              "  1.442038893699646,\n",
              "  1.5963996648788452,\n",
              "  1.0166499614715576,\n",
              "  1.0162858963012695,\n",
              "  1.1404460668563843,\n",
              "  1.3253134489059448,\n",
              "  1.1137051582336426,\n",
              "  1.0922951698303223,\n",
              "  1.110708475112915,\n",
              "  1.1028305292129517,\n",
              "  1.1079765558242798,\n",
              "  1.1085872650146484,\n",
              "  1.113206386566162,\n",
              "  1.094724416732788,\n",
              "  1.0950584411621094],\n",
              " 'dev_score_history': [0.52,\n",
              "  0.5466666666666666,\n",
              "  0.7866666666666666,\n",
              "  0.7333333333333333,\n",
              "  0.6533333333333333,\n",
              "  0.6533333333333333,\n",
              "  0.68,\n",
              "  0.76,\n",
              "  0.76,\n",
              "  0.7866666666666666,\n",
              "  0.6533333333333333,\n",
              "  0.6533333333333333,\n",
              "  0.68,\n",
              "  0.6533333333333333,\n",
              "  0.7066666666666667,\n",
              "  0.68,\n",
              "  0.68,\n",
              "  0.7066666666666667,\n",
              "  0.7333333333333333,\n",
              "  0.7333333333333333],\n",
              " 'test_score': 0.7866666666666666,\n",
              " 'train_loss_history': [1.7137648860613506,\n",
              "  1.4263707101345062,\n",
              "  0.9512742360432943,\n",
              "  0.8207606077194214,\n",
              "  0.6268080621957779,\n",
              "  0.38925519585609436,\n",
              "  0.4949212471644084,\n",
              "  0.34632398188114166,\n",
              "  0.25401831418275833,\n",
              "  0.19311241805553436,\n",
              "  0.16797466824452081,\n",
              "  0.13535491128762564,\n",
              "  0.14494878302017847,\n",
              "  0.10057791074117024,\n",
              "  0.09089661141236623,\n",
              "  0.10162133537232876,\n",
              "  0.0932737197726965,\n",
              "  0.08103054451445739,\n",
              "  0.09227155956129234,\n",
              "  0.08600428545226653]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKyyw1CSZFy",
        "colab_type": "code",
        "outputId": "74c49450-2c94-4490-c559-3d14018f0be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "mortgage_classifier = TextClassifier.load(new_data_folder + '/best-model.pt')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-28 03:20:44,817 loading file ./drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRpxvYnV1fCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.read_csv(data_folder + \"mortgage_rates_CBC_article_to_predict.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkUvqlX212UC",
        "colab_type": "code",
        "outputId": "b72e25a9-5f5d-4220-8a82-44db27772524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pred_df.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>title_desc</th>\n",
              "      <th>publishedAt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Mortgage arrears rate could spike to double wh...</td>\n",
              "      <td>2020-05-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Interest rates are plunging — so why aren't mo...</td>\n",
              "      <td>2020-04-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Why worries about the coronavirus are pushing ...</td>\n",
              "      <td>2020-01-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CBC</td>\n",
              "      <td>U.S. Fed chair rules out negative interest rat...</td>\n",
              "      <td>2020-05-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Mortgages in arrears in Alberta hit highest ra...</td>\n",
              "      <td>2019-08-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... publishedAt\n",
              "0           0  ...  2020-05-14\n",
              "1           1  ...  2020-04-04\n",
              "2           2  ...  2020-01-29\n",
              "3           3  ...  2020-05-13\n",
              "4           4  ...  2019-08-14\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRvRZ5gw29St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQV5zEwF14Cw",
        "colab_type": "code",
        "outputId": "071c2fe1-c139-499c-f5cd-e5e754614eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pred_list = []\n",
        "conf_list = []\n",
        "\n",
        "for index, row in pred_df.iterrows():\n",
        "  article_text = row[\"title_desc\"]\n",
        "  article_sentence = Sentence(article_text)\n",
        "  mortgage_classifier.predict(article_sentence)\n",
        "  pred = article_sentence.labels[0].value\n",
        "  print(pred)\n",
        "  pred_list.append(pred)\n",
        "\n",
        "  conf_score = article_sentence.labels[0].score\n",
        "  print(conf_score)\n",
        "  conf_list.append(conf_score)\n",
        "\n",
        "  print('----')\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0.5833262801170349\n",
            "----\n",
            "0\n",
            "0.8457203507423401\n",
            "----\n",
            "-1\n",
            "0.3939833641052246\n",
            "----\n",
            "-1\n",
            "0.7230633497238159\n",
            "----\n",
            "-1\n",
            "0.7956459522247314\n",
            "----\n",
            "-1\n",
            "0.5243971347808838\n",
            "----\n",
            "0\n",
            "0.8241885900497437\n",
            "----\n",
            "-1\n",
            "0.5161066651344299\n",
            "----\n",
            "0\n",
            "0.9054300785064697\n",
            "----\n",
            "0\n",
            "0.5838729739189148\n",
            "----\n",
            "-1\n",
            "0.9202001690864563\n",
            "----\n",
            "-1\n",
            "0.7700586915016174\n",
            "----\n",
            "-1\n",
            "0.7929283380508423\n",
            "----\n",
            "-1\n",
            "0.5186101198196411\n",
            "----\n",
            "-1\n",
            "0.7283235192298889\n",
            "----\n",
            "0\n",
            "0.7462179660797119\n",
            "----\n",
            "0\n",
            "0.9179391264915466\n",
            "----\n",
            "-1\n",
            "0.723307728767395\n",
            "----\n",
            "-1\n",
            "0.723307728767395\n",
            "----\n",
            "0\n",
            "0.9848251938819885\n",
            "----\n",
            "-1\n",
            "0.6162759065628052\n",
            "----\n",
            "0\n",
            "0.8945677876472473\n",
            "----\n",
            "-1\n",
            "0.6524528861045837\n",
            "----\n",
            "-1\n",
            "0.8799123167991638\n",
            "----\n",
            "-1\n",
            "0.61030113697052\n",
            "----\n",
            "-1\n",
            "0.61030113697052\n",
            "----\n",
            "0\n",
            "0.9861264824867249\n",
            "----\n",
            "0\n",
            "0.987683117389679\n",
            "----\n",
            "-1\n",
            "0.6217166185379028\n",
            "----\n",
            "0\n",
            "0.4838629364967346\n",
            "----\n",
            "0\n",
            "0.8227150440216064\n",
            "----\n",
            "-1\n",
            "0.5220191478729248\n",
            "----\n",
            "0\n",
            "0.8764476776123047\n",
            "----\n",
            "0\n",
            "0.9738495945930481\n",
            "----\n",
            "0\n",
            "0.7048612236976624\n",
            "----\n",
            "0\n",
            "0.9464749097824097\n",
            "----\n",
            "-1\n",
            "0.6920495629310608\n",
            "----\n",
            "0\n",
            "0.9608901143074036\n",
            "----\n",
            "0\n",
            "0.7481488585472107\n",
            "----\n",
            "0\n",
            "0.9535633325576782\n",
            "----\n",
            "-1\n",
            "0.9190465211868286\n",
            "----\n",
            "-1\n",
            "0.5463420748710632\n",
            "----\n",
            "0\n",
            "0.8133000135421753\n",
            "----\n",
            "0\n",
            "0.957953155040741\n",
            "----\n",
            "-1\n",
            "0.8195844888687134\n",
            "----\n",
            "0\n",
            "0.730255126953125\n",
            "----\n",
            "-1\n",
            "0.6552487015724182\n",
            "----\n",
            "-1\n",
            "0.9461883902549744\n",
            "----\n",
            "0\n",
            "0.8879565596580505\n",
            "----\n",
            "0\n",
            "0.9701850414276123\n",
            "----\n",
            "-1\n",
            "0.5205972194671631\n",
            "----\n",
            "0\n",
            "0.9987040758132935\n",
            "----\n",
            "0\n",
            "0.48939162492752075\n",
            "----\n",
            "0\n",
            "0.9774554967880249\n",
            "----\n",
            "0\n",
            "0.8820390701293945\n",
            "----\n",
            "0\n",
            "0.6866989731788635\n",
            "----\n",
            "0\n",
            "0.9774554967880249\n",
            "----\n",
            "0\n",
            "0.6904755234718323\n",
            "----\n",
            "-1\n",
            "0.8698023557662964\n",
            "----\n",
            "0\n",
            "0.964982807636261\n",
            "----\n",
            "1\n",
            "0.4242871403694153\n",
            "----\n",
            "0\n",
            "0.8386717438697815\n",
            "----\n",
            "0\n",
            "0.5362359881401062\n",
            "----\n",
            "0\n",
            "0.7498077750205994\n",
            "----\n",
            "0\n",
            "0.6681461334228516\n",
            "----\n",
            "0\n",
            "0.9279248118400574\n",
            "----\n",
            "0\n",
            "0.9279248118400574\n",
            "----\n",
            "-1\n",
            "0.8517391681671143\n",
            "----\n",
            "0\n",
            "0.9788872003555298\n",
            "----\n",
            "0\n",
            "0.6765930652618408\n",
            "----\n",
            "-1\n",
            "0.5427541136741638\n",
            "----\n",
            "-1\n",
            "0.5127909779548645\n",
            "----\n",
            "0\n",
            "0.6567027568817139\n",
            "----\n",
            "0\n",
            "0.9628497362136841\n",
            "----\n",
            "0\n",
            "0.9954694509506226\n",
            "----\n",
            "0\n",
            "0.9612399935722351\n",
            "----\n",
            "-1\n",
            "0.5127909779548645\n",
            "----\n",
            "0\n",
            "0.5480616688728333\n",
            "----\n",
            "-1\n",
            "0.7482961416244507\n",
            "----\n",
            "0\n",
            "0.5651090145111084\n",
            "----\n",
            "0\n",
            "0.9298241138458252\n",
            "----\n",
            "0\n",
            "0.5651090145111084\n",
            "----\n",
            "0\n",
            "0.9954694509506226\n",
            "----\n",
            "0\n",
            "0.9874289631843567\n",
            "----\n",
            "0\n",
            "0.9955001473426819\n",
            "----\n",
            "0\n",
            "0.9955001473426819\n",
            "----\n",
            "-1\n",
            "0.5992812514305115\n",
            "----\n",
            "1\n",
            "0.5158616304397583\n",
            "----\n",
            "0\n",
            "0.8970370888710022\n",
            "----\n",
            "1\n",
            "0.6774313449859619\n",
            "----\n",
            "0\n",
            "0.972307026386261\n",
            "----\n",
            "0\n",
            "0.7627779841423035\n",
            "----\n",
            "0\n",
            "0.7784238457679749\n",
            "----\n",
            "0\n",
            "0.994499921798706\n",
            "----\n",
            "0\n",
            "0.9298712015151978\n",
            "----\n",
            "-1\n",
            "0.5683609247207642\n",
            "----\n",
            "-1\n",
            "0.5683609247207642\n",
            "----\n",
            "0\n",
            "0.994499921798706\n",
            "----\n",
            "0\n",
            "0.4891136884689331\n",
            "----\n",
            "1\n",
            "0.7017706036567688\n",
            "----\n",
            "0\n",
            "0.9857171773910522\n",
            "----\n",
            "0\n",
            "0.9961250424385071\n",
            "----\n",
            "0\n",
            "0.6760703325271606\n",
            "----\n",
            "-1\n",
            "0.9577069878578186\n",
            "----\n",
            "0\n",
            "0.9298712015151978\n",
            "----\n",
            "-1\n",
            "0.5614399313926697\n",
            "----\n",
            "-1\n",
            "0.7680593729019165\n",
            "----\n",
            "-1\n",
            "0.6201648116111755\n",
            "----\n",
            "0\n",
            "0.9833446145057678\n",
            "----\n",
            "0\n",
            "0.992198646068573\n",
            "----\n",
            "-1\n",
            "0.4607471525669098\n",
            "----\n",
            "0\n",
            "0.9910138249397278\n",
            "----\n",
            "0\n",
            "0.6249313354492188\n",
            "----\n",
            "0\n",
            "0.8453556895256042\n",
            "----\n",
            "0\n",
            "0.7165437936782837\n",
            "----\n",
            "0\n",
            "0.7165437936782837\n",
            "----\n",
            "0\n",
            "0.928024172782898\n",
            "----\n",
            "0\n",
            "0.8453556895256042\n",
            "----\n",
            "1\n",
            "0.6148869395256042\n",
            "----\n",
            "-1\n",
            "0.5346603393554688\n",
            "----\n",
            "0\n",
            "0.9862318634986877\n",
            "----\n",
            "0\n",
            "0.9383276700973511\n",
            "----\n",
            "0\n",
            "0.9435617327690125\n",
            "----\n",
            "0\n",
            "0.9174548387527466\n",
            "----\n",
            "0\n",
            "0.627829909324646\n",
            "----\n",
            "0\n",
            "0.6656681895256042\n",
            "----\n",
            "0\n",
            "0.5340589284896851\n",
            "----\n",
            "0\n",
            "0.5952253937721252\n",
            "----\n",
            "0\n",
            "0.9306917786598206\n",
            "----\n",
            "0\n",
            "0.9057310223579407\n",
            "----\n",
            "0\n",
            "0.9760484099388123\n",
            "----\n",
            "0\n",
            "0.7148228287696838\n",
            "----\n",
            "0\n",
            "0.9816107749938965\n",
            "----\n",
            "0\n",
            "0.5099163055419922\n",
            "----\n",
            "0\n",
            "0.7148228287696838\n",
            "----\n",
            "0\n",
            "0.5725260972976685\n",
            "----\n",
            "0\n",
            "0.9583832621574402\n",
            "----\n",
            "0\n",
            "0.5481159687042236\n",
            "----\n",
            "0\n",
            "0.8957244157791138\n",
            "----\n",
            "0\n",
            "0.6800258159637451\n",
            "----\n",
            "0\n",
            "0.6800258159637451\n",
            "----\n",
            "0\n",
            "0.7798213362693787\n",
            "----\n",
            "0\n",
            "0.9863714575767517\n",
            "----\n",
            "-1\n",
            "0.6840746998786926\n",
            "----\n",
            "0\n",
            "0.43224287033081055\n",
            "----\n",
            "0\n",
            "0.6042570471763611\n",
            "----\n",
            "-1\n",
            "0.7142716646194458\n",
            "----\n",
            "0\n",
            "0.895915687084198\n",
            "----\n",
            "1\n",
            "0.49335193634033203\n",
            "----\n",
            "0\n",
            "0.9764546751976013\n",
            "----\n",
            "0\n",
            "0.9986944794654846\n",
            "----\n",
            "0\n",
            "0.9527829885482788\n",
            "----\n",
            "0\n",
            "0.9986944794654846\n",
            "----\n",
            "0\n",
            "0.6502994894981384\n",
            "----\n",
            "0\n",
            "0.5378075242042542\n",
            "----\n",
            "0\n",
            "0.9444385170936584\n",
            "----\n",
            "-1\n",
            "0.5341562628746033\n",
            "----\n",
            "0\n",
            "0.9244308471679688\n",
            "----\n",
            "0\n",
            "0.8028528690338135\n",
            "----\n",
            "0\n",
            "0.8847524523735046\n",
            "----\n",
            "0\n",
            "0.9527829885482788\n",
            "----\n",
            "0\n",
            "0.9444385170936584\n",
            "----\n",
            "-1\n",
            "0.65311199426651\n",
            "----\n",
            "-1\n",
            "0.6118548512458801\n",
            "----\n",
            "0\n",
            "0.9244308471679688\n",
            "----\n",
            "-1\n",
            "0.6118548512458801\n",
            "----\n",
            "0\n",
            "0.8223796486854553\n",
            "----\n",
            "1\n",
            "0.9382610321044922\n",
            "----\n",
            "1\n",
            "0.5431433320045471\n",
            "----\n",
            "0\n",
            "0.5803050994873047\n",
            "----\n",
            "0\n",
            "0.8223796486854553\n",
            "----\n",
            "0\n",
            "0.9952138662338257\n",
            "----\n",
            "0\n",
            "0.9952138662338257\n",
            "----\n",
            "0\n",
            "0.6048591732978821\n",
            "----\n",
            "0\n",
            "0.9249727129936218\n",
            "----\n",
            "0\n",
            "0.9952138662338257\n",
            "----\n",
            "0\n",
            "0.8534560799598694\n",
            "----\n",
            "0\n",
            "0.6048591732978821\n",
            "----\n",
            "0\n",
            "0.5058773756027222\n",
            "----\n",
            "-1\n",
            "0.455570250749588\n",
            "----\n",
            "0\n",
            "0.5058773756027222\n",
            "----\n",
            "-1\n",
            "0.5905554294586182\n",
            "----\n",
            "0\n",
            "0.8261200189590454\n",
            "----\n",
            "-1\n",
            "0.5905554294586182\n",
            "----\n",
            "0\n",
            "0.9061497449874878\n",
            "----\n",
            "0\n",
            "0.9935964345932007\n",
            "----\n",
            "0\n",
            "0.8707551956176758\n",
            "----\n",
            "0\n",
            "0.8707551956176758\n",
            "----\n",
            "0\n",
            "0.9935964345932007\n",
            "----\n",
            "0\n",
            "0.8001543879508972\n",
            "----\n",
            "0\n",
            "0.8149585723876953\n",
            "----\n",
            "1\n",
            "0.950413167476654\n",
            "----\n",
            "0\n",
            "0.9660902619361877\n",
            "----\n",
            "-1\n",
            "0.6384871006011963\n",
            "----\n",
            "0\n",
            "0.9660902619361877\n",
            "----\n",
            "-1\n",
            "0.4781244695186615\n",
            "----\n",
            "1\n",
            "0.4373388886451721\n",
            "----\n",
            "0\n",
            "0.8058847188949585\n",
            "----\n",
            "0\n",
            "0.9009319543838501\n",
            "----\n",
            "0\n",
            "0.9009319543838501\n",
            "----\n",
            "0\n",
            "0.6575592160224915\n",
            "----\n",
            "-1\n",
            "0.5184411406517029\n",
            "----\n",
            "0\n",
            "0.6575592160224915\n",
            "----\n",
            "0\n",
            "0.8591176867485046\n",
            "----\n",
            "0\n",
            "0.8127198815345764\n",
            "----\n",
            "1\n",
            "0.6706447005271912\n",
            "----\n",
            "0\n",
            "0.8591176867485046\n",
            "----\n",
            "1\n",
            "0.46332210302352905\n",
            "----\n",
            "0\n",
            "0.8127198815345764\n",
            "----\n",
            "0\n",
            "0.9413312077522278\n",
            "----\n",
            "-1\n",
            "0.4578247666358948\n",
            "----\n",
            "0\n",
            "0.9413312077522278\n",
            "----\n",
            "0\n",
            "0.9722641706466675\n",
            "----\n",
            "0\n",
            "0.931847870349884\n",
            "----\n",
            "0\n",
            "0.629153311252594\n",
            "----\n",
            "-1\n",
            "0.4578247666358948\n",
            "----\n",
            "0\n",
            "0.9181478023529053\n",
            "----\n",
            "0\n",
            "0.9119212031364441\n",
            "----\n",
            "0\n",
            "0.9924029111862183\n",
            "----\n",
            "1\n",
            "0.9169769883155823\n",
            "----\n",
            "0\n",
            "0.9181478023529053\n",
            "----\n",
            "0\n",
            "0.914290189743042\n",
            "----\n",
            "-1\n",
            "0.7489941120147705\n",
            "----\n",
            "0\n",
            "0.9610273838043213\n",
            "----\n",
            "1\n",
            "0.5704066157341003\n",
            "----\n",
            "0\n",
            "0.9924029111862183\n",
            "----\n",
            "1\n",
            "0.9140901565551758\n",
            "----\n",
            "1\n",
            "0.5704066157341003\n",
            "----\n",
            "1\n",
            "0.9140901565551758\n",
            "----\n",
            "1\n",
            "0.5849648118019104\n",
            "----\n",
            "0\n",
            "0.9610273838043213\n",
            "----\n",
            "1\n",
            "0.5704066157341003\n",
            "----\n",
            "0\n",
            "0.8249685168266296\n",
            "----\n",
            "0\n",
            "0.8249685168266296\n",
            "----\n",
            "-1\n",
            "0.5715274810791016\n",
            "----\n",
            "0\n",
            "0.9768720269203186\n",
            "----\n",
            "0\n",
            "0.8408538699150085\n",
            "----\n",
            "0\n",
            "0.9242126941680908\n",
            "----\n",
            "0\n",
            "0.9903573393821716\n",
            "----\n",
            "0\n",
            "0.5293673872947693\n",
            "----\n",
            "0\n",
            "0.9881261587142944\n",
            "----\n",
            "0\n",
            "0.9903573393821716\n",
            "----\n",
            "0\n",
            "0.9881261587142944\n",
            "----\n",
            "0\n",
            "0.866226077079773\n",
            "----\n",
            "0\n",
            "0.9300028681755066\n",
            "----\n",
            "0\n",
            "0.9497312903404236\n",
            "----\n",
            "0\n",
            "0.9300028681755066\n",
            "----\n",
            "0\n",
            "0.9436260461807251\n",
            "----\n",
            "0\n",
            "0.9300028681755066\n",
            "----\n",
            "0\n",
            "0.9497312903404236\n",
            "----\n",
            "-1\n",
            "0.5753954648971558\n",
            "----\n",
            "-1\n",
            "0.6113917827606201\n",
            "----\n",
            "0\n",
            "0.9855823516845703\n",
            "----\n",
            "-1\n",
            "0.5753954648971558\n",
            "----\n",
            "-1\n",
            "0.6113917827606201\n",
            "----\n",
            "0\n",
            "0.8868564963340759\n",
            "----\n",
            "-1\n",
            "0.6113917827606201\n",
            "----\n",
            "0\n",
            "0.946033239364624\n",
            "----\n",
            "0\n",
            "0.9699277281761169\n",
            "----\n",
            "0\n",
            "0.7384837865829468\n",
            "----\n",
            "0\n",
            "0.7384837865829468\n",
            "----\n",
            "-1\n",
            "0.4728853702545166\n",
            "----\n",
            "0\n",
            "0.5945981740951538\n",
            "----\n",
            "0\n",
            "0.9904341697692871\n",
            "----\n",
            "0\n",
            "0.9904341697692871\n",
            "----\n",
            "0\n",
            "0.7934226989746094\n",
            "----\n",
            "-1\n",
            "0.4728853702545166\n",
            "----\n",
            "0\n",
            "0.4737481474876404\n",
            "----\n",
            "0\n",
            "0.7782605290412903\n",
            "----\n",
            "0\n",
            "0.6489474177360535\n",
            "----\n",
            "0\n",
            "0.8667775988578796\n",
            "----\n",
            "0\n",
            "0.7636364698410034\n",
            "----\n",
            "-1\n",
            "0.8524603843688965\n",
            "----\n",
            "0\n",
            "0.9019364714622498\n",
            "----\n",
            "0\n",
            "0.9947376847267151\n",
            "----\n",
            "0\n",
            "0.9323815703392029\n",
            "----\n",
            "0\n",
            "0.8276392817497253\n",
            "----\n",
            "0\n",
            "0.7139638066291809\n",
            "----\n",
            "0\n",
            "0.9397067427635193\n",
            "----\n",
            "-1\n",
            "0.5557470321655273\n",
            "----\n",
            "-1\n",
            "0.5557470321655273\n",
            "----\n",
            "-1\n",
            "0.6337345838546753\n",
            "----\n",
            "0\n",
            "0.8523023724555969\n",
            "----\n",
            "0\n",
            "0.8891795873641968\n",
            "----\n",
            "0\n",
            "0.9496447443962097\n",
            "----\n",
            "0\n",
            "0.9496447443962097\n",
            "----\n",
            "0\n",
            "0.9944211840629578\n",
            "----\n",
            "0\n",
            "0.9661639332771301\n",
            "----\n",
            "0\n",
            "0.9944211840629578\n",
            "----\n",
            "0\n",
            "0.9145631194114685\n",
            "----\n",
            "0\n",
            "0.9145631194114685\n",
            "----\n",
            "0\n",
            "0.9968365430831909\n",
            "----\n",
            "0\n",
            "0.5990732908248901\n",
            "----\n",
            "0\n",
            "0.5341294407844543\n",
            "----\n",
            "0\n",
            "0.9501262903213501\n",
            "----\n",
            "0\n",
            "0.9898331165313721\n",
            "----\n",
            "0\n",
            "0.5990732908248901\n",
            "----\n",
            "0\n",
            "0.4920549690723419\n",
            "----\n",
            "0\n",
            "0.8592660427093506\n",
            "----\n",
            "0\n",
            "0.9841258525848389\n",
            "----\n",
            "-1\n",
            "0.6699318885803223\n",
            "----\n",
            "0\n",
            "0.8490521311759949\n",
            "----\n",
            "0\n",
            "0.786296546459198\n",
            "----\n",
            "0\n",
            "0.786296546459198\n",
            "----\n",
            "0\n",
            "0.9397538304328918\n",
            "----\n",
            "0\n",
            "0.7597381472587585\n",
            "----\n",
            "0\n",
            "0.44951143860816956\n",
            "----\n",
            "0\n",
            "0.9397538304328918\n",
            "----\n",
            "0\n",
            "0.6742253303527832\n",
            "----\n",
            "0\n",
            "0.9868032336235046\n",
            "----\n",
            "0\n",
            "0.9868032336235046\n",
            "----\n",
            "0\n",
            "0.9001421332359314\n",
            "----\n",
            "0\n",
            "0.9001421332359314\n",
            "----\n",
            "0\n",
            "0.9143128395080566\n",
            "----\n",
            "0\n",
            "0.9143128395080566\n",
            "----\n",
            "0\n",
            "0.9819638729095459\n",
            "----\n",
            "-1\n",
            "0.7012293338775635\n",
            "----\n",
            "0\n",
            "0.9443699717521667\n",
            "----\n",
            "0\n",
            "0.8823479413986206\n",
            "----\n",
            "0\n",
            "0.8823479413986206\n",
            "----\n",
            "-1\n",
            "0.6246797442436218\n",
            "----\n",
            "0\n",
            "0.8615285754203796\n",
            "----\n",
            "0\n",
            "0.9673453569412231\n",
            "----\n",
            "0\n",
            "0.9673453569412231\n",
            "----\n",
            "0\n",
            "0.9673453569412231\n",
            "----\n",
            "0\n",
            "0.961482048034668\n",
            "----\n",
            "0\n",
            "0.961482048034668\n",
            "----\n",
            "0\n",
            "0.8594030141830444\n",
            "----\n",
            "0\n",
            "0.6569146513938904\n",
            "----\n",
            "0\n",
            "0.6246793866157532\n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pM-EFFv3J4O",
        "colab_type": "code",
        "outputId": "8d353b79-ce81-409c-fd98-fd0413829cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(conf_list))\n",
        "print(len(pred_list))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "330\n",
            "330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We-qZI5A7f_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pred_df[\"pred_label\"] = pd.Series(pred_list)\n",
        "pred_df[\"confidence\"] = pd.Series(conf_list)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHzwpiCK8pia",
        "colab_type": "code",
        "outputId": "813116ea-3250-41d2-b764-cd2dd827300c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "pred_df.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>title_desc</th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Mortgage arrears rate could spike to double wh...</td>\n",
              "      <td>2020-05-14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.583326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Interest rates are plunging — so why aren't mo...</td>\n",
              "      <td>2020-04-04</td>\n",
              "      <td>0</td>\n",
              "      <td>0.845720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Why worries about the coronavirus are pushing ...</td>\n",
              "      <td>2020-01-29</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.393983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CBC</td>\n",
              "      <td>U.S. Fed chair rules out negative interest rat...</td>\n",
              "      <td>2020-05-13</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.723063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Mortgages in arrears in Alberta hit highest ra...</td>\n",
              "      <td>2019-08-14</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.795646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 source  ... pred_label confidence\n",
              "0           0    CBC  ...          0   0.583326\n",
              "1           1    CBC  ...          0   0.845720\n",
              "2           2    CBC  ...         -1   0.393983\n",
              "3           3    CBC  ...         -1   0.723063\n",
              "4           4    CBC  ...         -1   0.795646\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nbTLQd67yfh",
        "colab_type": "code",
        "outputId": "d9ef8794-69c1-4d74-a0ed-77e5093d62bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index, row in pred_df.iterrows():\n",
        "  print(row[\"title_desc\"])\n",
        "  print(row[\"pred_label\"])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mortgage arrears rate could spike to double what it was in 2009, Bank of Canada says. Central bank says number of people falling behind on mortgages could almost quadruple\n",
            "0\n",
            "Interest rates are plunging — so why aren't mortgage rates?. Bond yields and central bank rates have never been lower, but not all the savings are filtering down\n",
            "0\n",
            "Why worries about the coronavirus are pushing mortgage rates down. Fear has pushed investors to buy up bonds, which is causing cheaper borrowing for home buyers\n",
            "-1\n",
            "U.S. Fed chair rules out negative interest rates even as Trump trumpets them. U.S. president goes negative on Jerome Powell for rejection of below-zero interest rates\n",
            "-1\n",
            "Mortgages in arrears in Alberta hit highest rate since 2013. Rate seen as a 'lagging indicator' of the economy, driven largely by unemployment\n",
            "-1\n",
            "'Pretty cheap money': Canadian mortgage rates falling to their lowest level in 2 years. Fixed and variable loans have gotten cheaper because costs for lenders are down too\n",
            "-1\n",
            "Housing starts up in some parts of Canada despite COVID-19. Multi-unit housing projects remained strong in some provinces in April, CMHC says\n",
            "0\n",
            "Federal deficit likely to be higher than $252 billion, parliamentary budget officer says. PBO says it's possible federal debt will hit $1 trillion because of pandemic relief spending\n",
            "-1\n",
            "Time to buy? What the pandemic means for Vancouver's real estate market. Mark Ting, On the Coast's finance columnist, on what lies ahead for buyers and sellers amid COVID-19\n",
            "0\n",
            "Put yourself in their shoes: Let's thank the women on the front line of the pandemic. Women are often in harm's way in this pandemic, says MUN president \n",
            "0\n",
            "Canada lost nearly 2 million jobs in April amid COVID-19 crisis: Statistics Canada. Statistics Canada says unemployment rate soared to 13% as full force of pandemic hit\n",
            "-1\n",
            "Ontario has now lost more than 1 million jobs during the COVID-19 pandemic. Unemployment rate climbs to 11.3%, with a warning that many workers have simply left the job market\n",
            "-1\n",
            "Another quarter-million Albertans lost work in April as COVID-19 shutdown grips province. Employment rate for young women cut nearly in half as pandemic hits service sector especially hard\n",
            "-1\n",
            "U.S. economy lost 20.5 million jobs in April. Unemployment rate surged to 14.7 per cent last month\n",
            "-1\n",
            "CMHC to take more mortgages off banks' books to free up cash for loans amid COVID-19 crisis. Government had similar program in place during 2009 financial crisis\n",
            "-1\n",
            "Deficit reduction will have to wait for the economic recovery, federal officials say. Federal aid programs could continue well into the recovery phase, says government official\n",
            "0\n",
            "Tiff Macklem to lead the Bank of Canada. Stephen Poloz’s term as governor ends in June\n",
            "0\n",
            "Canada's big banks cut credit card interest rates to ease coronavirus impact. Big Six will temporarily reduce credit card interest rates amid COVID-19 pandemic\n",
            "-1\n",
            "Canada's big banks cut credit card interest rates to ease coronavirus impact. Big Six will temporarily reduce credit card interest rates amid COVID-19 pandemic\n",
            "-1\n",
            "Why high interest rates were a problem for '80s renters, too. They didn't have mortgages, but their landlords did\n",
            "0\n",
            "Quebec lost 264,000 jobs to COVID-19 crisis last month. Quebec's unemployment rate rose to 8.1 per cent last month\n",
            "-1\n",
            "Changes to mortgage stress test rules good news for young home buyers, says P.E.I. broker. Broker says wiggle room will make a difference for people carrying extra debt\n",
            "0\n",
            "Bank of Canada holds rate steady at 0.25% and hints it has no plans to go any lower. Bank expects economic activity to slow by as much as 30% from end of 2019\n",
            "-1\n",
            "Bank of Canada makes emergency interest rate cut. Move comes on top of previous 50-point cut last week\n",
            "-1\n",
            "B.C. home sales to fall by 40 per cent but comeback is likely, report says. Provincial economy expected to shrink by 4 per cent, economist says \n",
            "-1\n",
            "B.C. home sales to fall by 40 per cent but comeback is likely, report says. Provincial economy expected to shrink by 4 per cent, economist says \n",
            "-1\n",
            "Ottawa unveils new mortgage stress test rules that will make it easier to pass. New rules will be in force as of April\n",
            "0\n",
            "Financially impacted by COVID-19? A personal-finance expert answers your most pressing questions. How to approach issues like cash flow, mortgage deferral, retirement investments and more right now\n",
            "0\n",
            "Tenants left homeless after Campbell River apartment fire granted hotel housing until end of May. Nearly 90 residents lost their homes after a low-income apartment building fire on April 8\n",
            "-1\n",
            "Foreclosure rate steadily increasing in Fort McMurray. 'There's a lot of homeowners that are very much underwater' as house prices drop\n",
            "0\n",
            "The economy's on life support and Canadians need help now. What's the holdup?. As Canadians wait anxiously for household financial aid, many wonder why banks aren't doing more\n",
            "0\n",
            "COVID-19 crisis may usher in new financial era if the world begins to shun risk: Don Pittis. Ants and grasshoppers: Consumers, businesses with savings will have to help the rest\n",
            "-1\n",
            "As COVID-19 bailouts pile up, Canadians ask for relief on credit card rates. Credit cards have much higher interest rates than other forms of debt and so far, are drawing less scrutiny\n",
            "0\n",
            "Italians allowed to visit relatives as country loosens more coronavirus restrictions. Anyone wearing a mask and following physical distancing can visit relatives to sixth degree and kin to fourth\n",
            "0\n",
            "Low vacancy rates for Saint John apartments could spell trouble for low-income renters. 'Affordability becomes an issue' when vacancy rate outpaces supply, says analyst with CMHC \n",
            "0\n",
            "U.S. Federal Reserve slashes rate to near 0 in effort to offset COVID-19 impact. Fed also said it will drop some bank requirements in order to encourage lending\n",
            "0\n",
            "Calgary home prices forecast to decline again in 2020, but by less than in 2019. Real estate board expects prices to drop 0.7%, compared with 3.4% last year\n",
            "-1\n",
            "Rents in Regina, Saskatoon expected to increase slightly in 2020: report. Vacancy rates in both cities have been declining according to CMHC\n",
            "0\n",
            "Will COVID-19 affect the spring real estate market?. Mark Ting, On the Coast's finance columnist, on what you should do if you're looking to buy — or sell\n",
            "0\n",
            "Interest rates made home buyers look beyond their comfort zone in 1979. Interest rate of almost 15 per cent drove property seekers to less desirable districts\n",
            "0\n",
            "Sask. finance minister to provide an update Friday amid fiscal uncertainty. COVID-19 and economic situation could have Sask. headed for $1B deficit: analysts\n",
            "-1\n",
            "TSX and Dow Jones lose another 10% as coronavirus sell-off continues. When stock markets go down by 7%, automatic trading halts kick in to calm the situation\n",
            "-1\n",
            "P.E.I. vacancy rate improved, but still lowest in country. Charlottetown vacancy rate now at 1.2% \n",
            "0\n",
            "How COVID might affect our food supply; Wedding delays might have hidden costs: CBC's Marketplace cheat sheet. Newsletter: Consumer and health news you need from the week\n",
            "0\n",
            "Fewer homes on the market could mean bargains for buyers still on the hunt during COVID-19. Real estate market has slowed to a halt, leaving buyer's market during COVID-19 pandemic\n",
            "-1\n",
            "Tough to tell when P.E.I. vacancy rate will rebound, says analyst. 'I would say now ... at 1.2 per cent it’s still very low'\n",
            "0\n",
            "Inflation's return would upend consumer and market strategies: Don Pittis. Experts warn record spending and printing money could lead to post-COVID price rises\n",
            "-1\n",
            "U.S. Federal Reserve cuts benchmark interest rate by half-point to offset coronavirus impact. Rate cut is biggest since 2008 financial crisis\n",
            "-1\n",
            "Will COVID-19 cause the next North American recession?. Finance columnist Mark Ting answers questions about the financial impact of coronavirus\n",
            "0\n",
            "Strategic Group puts 50 Calgary properties, with $650M in mortgages, under creditor protection. Company cited high vacancy rate, economic conditions as factors\n",
            "0\n",
            "Tight rental market has Dartmouth renters worried over looming 'renoviction'. Tenants can reapply to the building after renovations, but rents will be hundreds of dollars higher\n",
            "-1\n",
            "What it's like being 30 and going through the 3rd recession of your adult life. Millennials who coped with previous economic downturns share tips on surviving\n",
            "0\n",
            "Average rent in Calgary climbs by 1.7% as population, labour force grow. New rental units added to market also tend to demand higher rent, analyst says\n",
            "0\n",
            "Bank of Canada holds interest rates steady. Central bank holds the overnight rate steady at 1.75%\n",
            "0\n",
            "Mortgage stress test rules get more lenient for first time. Posted mortgage rates in Canada have inched lower, so stress test benchmark has followed suit\n",
            "0\n",
            "What's happened in Canada since WHO declared COVID-19 a pandemic. Canada had more than 100 confirmed cases on March 11 when pandemic declared\n",
            "0\n",
            "Bank of Canada holds interest rates steady. Central bank holds the overnight rate steady at 1.75%\n",
            "0\n",
            "Stephen Poloz gets racier as his farewell tour progresses: Don Pittis. Bank governor warns on Trump re-election and slams premiers on internal trade\n",
            "0\n",
            "Bank of Canada follows U.S. with half-point rate cut to soften blow of coronavirus. Bank rate reduction comes amid economic concerns over coronavirus outbreak\n",
            "-1\n",
            "Vacancy rates for some B.C. seniors' facilities up for first time in years. Spaces still in high demand for those with low income or high-level care needs\n",
            "0\n",
            "2019 home sales outlook improves, after 5% rise in August. Canadian Real Estate Association says declining mortgage rates luring buyers back\n",
            "1\n",
            "Home sales rise for 5th month in a row in July, prices up 4% in past year. Canada's housing market is showing signs of coming out of stress-test slumber \n",
            "0\n",
            "Fed saw last month less risk of U.S. recession. Central bank noted U.S. economy 'showing resilience' despite trade war, according to minutes of Dec. meeting\n",
            "0\n",
            "What profits at Canada's big banks are saying about the odds of a recession. Royal and CIBC revealed numbers last week. Now it's BMO, Scotia and TD's turn\n",
            "0\n",
            "'Renoviction' rates soar due to big-city housing crunch. 'It's a way of making outrageous profits in a very short time,' housing advocate says\n",
            "0\n",
            "Moncton, Dieppe break building permit records as construction booms. Residential construction is increasing but vacancy rates are falling \n",
            "0\n",
            "Moncton, Dieppe break building permit records as construction booms. Residential construction is increasing but vacancy rates are falling \n",
            "0\n",
            "Economic forecasts for Alberta point to recession, thousands of job losses. Province's economy to be hit hard by double whammy of COVID-19 and oil-price shock\n",
            "-1\n",
            "Why it was hard to sell or buy a home in Vancouver in 1981. Interest rates were the stumbling point \n",
            "0\n",
            "Fed chair sees North America as an economic oasis in 2020: Don Pittis. Solidifying our trade link with the U.S. means optimism could spread north next year\n",
            "0\n",
            "Canada's economy grew at 0.3% pace in fourth quarter, slowest level in almost 4 years. Bad weather and strikes slowed growth to a crawl\n",
            "-1\n",
            "Interest rate cut for COVID-19 is like surgery with a club: Don Pittis. Cheap money is a blunt instrument that won't fix specific economic problems caused by coronavirus outbreak\n",
            "-1\n",
            "Real estate market hits new heights in Ottawa-Gatineau. Record comes amidst affordable housing shortage\n",
            "0\n",
            "Home Capital Group to sell $425M worth of uninsured mortgage-backed securities. Move by alternative mortgage lender is likely to be welcomed by the Bank of Canada\n",
            "0\n",
            "COVID-19 unknowns leave economy dazed and wobbly: Don Pittis. It is certain the world will recover, but doubts remain over when and how\n",
            "0\n",
            "'It's been tough': Edmonton's job market limps into new year. 'I'm beginning to see now that the statistics ring true so it's been tough'\n",
            "0\n",
            "Interest rate cut for COVID-19 is like surgery with a club: Don Pittis. Cheap money is a blunt instrument that won't fix specific economic problems caused by coronavirus outbreak\n",
            "-1\n",
            "Calgary realtors bracing for a 'double whammy'. Price declines already predicted for 2020, now COVID-19 brings more uncertainty\n",
            "0\n",
            "'Agonizing': The prospect of a historic oil glut weighs on crude prices. North American benchmark price drops below $30 US per barrel\n",
            "-1\n",
            "Poloz sees parts of Canadian economy beginning to restart in 'late May'. But Bank of Canada governor tells MPs full recovery could take a year under 'best-case' scenario\n",
            "0\n",
            "Feds announce $200M for affordable rentals where Honest Ed's once stood. Mirvish Village project will ensure location stays true to roots as low-income hub, Ahmed Hussen says\n",
            "0\n",
            "Poloz sees parts of Canadian economy beginning to restart in 'late May'. But Bank of Canada governor tells MPs full recovery could take a year under 'best-case' scenario\n",
            "0\n",
            "COVID-19 unknowns leave economy dazed and wobbly: Don Pittis. It is certain the world will recover, but doubts remain over when and how\n",
            "0\n",
            "Manitoba Liberal leader calls on Ottawa to forgive personal, government debts. Dougald Lamont is calling for mass debt forgiveness across Canada\n",
            "0\n",
            "Here's some of the financial help available in B.C. during the COVID-19 crisis. This list will be updated as more funds and programs become available \n",
            "0\n",
            "Here's some of the financial help available in B.C. during the COVID-19 crisis. This list will be updated as more funds and programs become available \n",
            "0\n",
            "Fed's Powell sees steady growth, signals pause in rate cuts. Powell's testimony comes a day after Trump attacked the Fed for not cutting interest rates further\n",
            "-1\n",
            "Vancouver keeps crown as Canadian metropolis with highest rents and lowest vacancies. Property values went down — but average rents increased higher than inflation \n",
            "1\n",
            "Businesses in B.C. 'feeling the pinch' of coronavirus outbreak on global markets. Wide sector of industries affected — from manufacturing to tourism\n",
            "0\n",
            "Inflation rate nudges down to 1.9% as gasoline and vegetables got cheaper. Air fare increases one of the biggest factors to the upside\n",
            "1\n",
            "Chris Hall: Bill Morneau's keeping his pandemic focus firmly on the near-term. He knows Canadians want to be told when to expect a return to 'normal' — but he's got bigger problems\n",
            "0\n",
            "Bank of Canada deputy says Canadian economy is 'resilient'. Despite trade war between U.S. and China, deputy governor Timothy Lane says economy is strong\n",
            "0\n",
            "'Less bad' doesn't mean good: What Vancouver's housing market could hold in 2020. For the first time in five years, there were no major surges in any aspect of the market \n",
            "0\n",
            "Bank of Canada may cut rates to aid economy sickened by COVID-19: Don Pittis. Central bank action may be part of a co-ordinated G7 plan as recommended by OECD\n",
            "0\n",
            "Coronavirus: What's happening in Canada and around the world Wednesday. B.C. announces plan to ease COVID-19 restrictions, allowing small gatherings\n",
            "0\n",
            "Alaska population at lowest level since 2012. The state's population decline is second only to West Virginia in U.S.\n",
            "-1\n",
            "Alaska population at lowest level since 2012. The state's population decline is second only to West Virginia in U.S.\n",
            "-1\n",
            "Bank of Canada may cut rates to aid economy sickened by COVID-19: Don Pittis. Central bank action may be part of a co-ordinated G7 plan as recommended by OECD\n",
            "0\n",
            "Surging rent costs push families to choose between housing and food, says advocate. The Benedict Labre House says there has been a surge in demand for food baskets in the last year\n",
            "0\n",
            "Cheaper energy pulls Canada's inflation rate down to 2% in June. If energy is stripped out, cost of living increased at a 2.6% annual pace last month\n",
            "1\n",
            "Ottawa-area residents love where they live, but not what they're paying: survey. Capital region renters among least satisfied with housing affordability\n",
            "0\n",
            "Bank of Canada holds interest rates steady. Holds benchmark interest rate at 1.75 per cent\n",
            "0\n",
            "Sask. Landlord Association sees sharp spike in unpaid rents during COVID-19. Association says survey found 27 per cent of renters haven't paid bills yet\n",
            "0\n",
            "Alberta men under 25 and over 55 face highest unemployment rates, says StatsCan. Job market in province stagnates, adding just 1,200 full-time jobs in August\n",
            "-1\n",
            "Coronavirus: What's happening in Canada and around the world Wednesday. B.C. announces plan to ease COVID-19 restrictions, allowing small gatherings\n",
            "0\n",
            "'Now is the time for action,' says Mayor Valérie Plante, as Montreal vacancy rate hits 15-year low. Tenants' advocates worry critical housing shortage will lead to 'renters finding themselves on the streets'\n",
            "-1\n",
            "Containment efforts will delay, not prevent, COVID-19 outbreak in Canada, Hajdu warns. Health authorities hope delay will buy time to get hospitals through the busy flu season\n",
            "-1\n",
            "Employment held steady in October, Statistics Canada says. Economy lost 1,800 jobs, a number low enough that unemployment rate is unchanged\n",
            "-1\n",
            "Home sales climb higher in July, Canadian Real Estate Association reports. Sales up in most large markets, including Calgary, Edmonton, Toronto, Montreal, B.C. Lower Mainland\n",
            "0\n",
            "Meet the Toronto man who is spending $400 a month to live in a backyard yurt. Man says he slept in $3,000 structure through the winter\n",
            "0\n",
            "Canada's inflation rate held steady at 2% in July, higher than expected. Loonie inches higher on strong number, and odds of a rate cut next month get lower\n",
            "-1\n",
            "'This is a choice': Fort McMurray residents brave the winter cold in their RVs. 'We don't live in here because we have to'\n",
            "0\n",
            "In 1987, a triple-digit-point stock market drop was huge. Frenzied selloff at TSE drew in curious spectators on Black Monday\n",
            "0\n",
            "Vacancy rate on the rise in Regina, so why isn't the cost of rent going down?. Some residents struggle to afford rent in Regina despite oversupply\n",
            "0\n",
            "Morneau says he's not worried about a recession despite job numbers. Finance minister says investment remains strong, Canada's economy expected to continue growing\n",
            "0\n",
            "Morneau says he's not worried about a recession despite job numbers. Finance minister says investment remains strong, Canada's economy expected to continue growing\n",
            "0\n",
            "Winter is coming, and so is an uncharted economic abyss: Neil Macdonald. The economic situation scares me. But then, I'm not an economist\n",
            "0\n",
            "Vacancy rate on the rise in Regina, so why isn't the cost of rent going down?. Some residents struggle to afford rent in Regina despite oversupply\n",
            "0\n",
            "Canadian inflation 1.9% in September as lower gas prices keep rate steady. Rate held at 1.9% for second straight month, close to Bank of Canada's ideal target of 2%\n",
            "1\n",
            "Tenants left homeless after apartment fire struggle with Campbell River housing crisis — and a pandemic. Nearly 90 Campbell River residents are struggling to find housing while emergency supports are running out\n",
            "-1\n",
            "Big families, small budgets: The challenge of housing for refugees. Valentina Cerka works to overcome barriers and find affordable housing for refugees in Winnipeg\n",
            "0\n",
            "Toronto must be 'brave' and enact bold new zoning laws to confront housing crisis, advocates say. Detached houses are all the city allows on more than a third of residential land\n",
            "0\n",
            "Soaring condo insurance rates help push Fort McMurray homeowner into bankruptcy. 'There's not anything we can do anymore,' Kaleena Carriere says\n",
            "0\n",
            "Breaking down Canadians' questions about the cost of living. It's the number one concern among Canadians heading into the fall federal election \n",
            "0\n",
            "Bank of Canada holds interest rate at 1.75%, wary of global slowdown. Central bank says outlook for global economy 'has weakened further' since July\n",
            "0\n",
            "45 per cent of Hamilton renters living in unaffordable housing, new report says. Average rent in the downtown core, mountain has risen 40 per cent in 8 years\n",
            "0\n",
            "U.S. reports on GDP, consumer spending remain positive. Improvement in economic data seemingly reduces the risks of a recession in the near term\n",
            "0\n",
            "Bank of Canada holds key interest rate steady at 1.75%. Decision in line with what economists were expecting\n",
            "0\n",
            "Expect Bank of Canada to take heart from an improving U.S. economic climate: Don Pittis. The sun is shining, the birds are chirping, but central bankers must plan for storms\n",
            "0\n",
            "All eyes on Bank of Canada's interest rate decision, view of global economic climate. Governor Stephen Poloz to give 1st policy announcement since early July\n",
            "0\n",
            "Whitehorse residents paint picture of what dismal rental market looks like. Median price for renting in Whitehorse is $1,050 a month, according to Yukon Bureau of Statistics\n",
            "0\n",
            "European Central Bank keeps rates low as new president takes helm. Decision follows a similar one by the U.S. Federal Reserve\n",
            "0\n",
            "The Liberals' first-time homebuyers incentive is a bad deal. The program asks too much in exchange for savings of a couple of hundred dollars a month\n",
            "0\n",
            "Toronto home sales jump 17.4% in December, average price up 12%. Condos saw the biggest price gains through 2019\n",
            "0\n",
            "European Central Bank keeps rates low as new president takes helm. Decision follows a similar one by the U.S. Federal Reserve\n",
            "0\n",
            "Canadian and U.S. economies are converging but danger lurks: Don Pittis. Poloz and Wilkins warn that markets overestimate the power of a rate-cut quick fix\n",
            "0\n",
            "Toronto to explore tax targeting vacant storefronts on city's main streets. A busy 2.3-kilometre section of Queen Street East is home to 44 vacant stores\n",
            "0\n",
            "More Fed cuts expected to push Canadian interest rates lower: Don Pittis. Watch for effects of shrinking global economy to hit Canada as well\n",
            "0\n",
            "Bank of Canada unlikely to follow any Fed interest rate cut. U.S. central bank expected to drop interbank lending rate by 25 basis points\n",
            "0\n",
            "Name calling and market pressure may curb U.S. Fed's independence: Don Pittis. With few signs of recession, could Jerome  Powell leave rates unchanged even if he wanted to?\n",
            "0\n",
            "Name calling and market pressure may curb U.S. Fed's independence: Don Pittis. With few signs of recession, could Jerome  Powell leave rates unchanged even if he wanted to?\n",
            "0\n",
            "Bank of Canada's Poloz says global growth to remain slow, low global interest rates. Central bank kept key interest rate on hold last week at 1.75 per cent\n",
            "0\n",
            "New home construction in Halifax driving higher assessment values. Home values in Nova Scotia up 2.9 per cent, commercial properties 1.2 per cent\n",
            "0\n",
            "Pallister repeats call for Ottawa to borrow on behalf of provinces. Provinces need help to keep costs of COVID-19 down, Manitoba premier says\n",
            "-1\n",
            "Faced with rental housing crisis, Rosemont—La Petite-Patrie moves to restrict Airbnbs. Borough cracks down on hundreds of property owners who are turning apartments into hotels\n",
            "0\n",
            "Inflation climbs to 2.2%, Statistics Canada reports. Annual pace of inflation heated up in November as gas prices rose\n",
            "0\n",
            "The price of an average London home could hit $450K in 2020. While sales aren't expected to match the frenetic pace of 2017, tight inventories will cause prices to rise\n",
            "-1\n",
            "Calgary housing market among the most affordable in Canada, report says. 'If you are the median income earner, there are options for you'\n",
            "0\n",
            "Canada's economy rebounded with 0.1% GDP increase in November. October contraction reversed by slight expansion in November\n",
            "1\n",
            "Port Hawkesbury Paper cutting wood deliveries due to declining markets, COVID-19. Nova Scotia sawmills expecting almost immediate effects from the change\n",
            "0\n",
            "City of Charlottetown wants short-term rentals defined as tourism accommodations. 'We just want to make sure that they're properly regulated'\n",
            "0\n",
            "Bank of Canada flags Alberta economic challenges in latest update. Crown corporation anticipates province will stablilize next year\n",
            "0\n",
            "City of Charlottetown wants short-term rentals defined as tourism accommodations. 'We just want to make sure that they're properly regulated'\n",
            "0\n",
            "Hamilton looks at an empty homes tax to ward off speculators and help local rents. More than half of vacant Vancouver homes are back on the market, but can it work in Hamilton?\n",
            "0\n",
            "Blip or trend? This week will test Canada's job-creation machine: Don Pittis. Some experts called doom when the country's job numbers plunged. But there's another view.\n",
            "0\n",
            "Powell hints Federal Reserve will cut rates if needed over trade wars. Expectations are rising that the Fed will cut rates at least once and possibly twice before year's end\n",
            "0\n",
            "Business sentiment improves after downturn early in year. Global trade tensions, weakness in oilpatch still hang over Canadian outlook\n",
            "-1\n",
            "Police worry about budget cuts at social agencies as crime rate increases. DOAP Team is dramatically scaling back patrols\n",
            "0\n",
            "Bank of Canada resists pressure to cut its interest rate — for now. Central bank leaves key rate at 1.75%, but appears ready to adjust lower\n",
            "0\n",
            "U.S. Federal Reserve cuts interest rates for 3rd time this year. The target range for the federal funds is now 1.5 to 1.75%\n",
            "0\n",
            "Bank of Canada flags Alberta economic challenges in latest update. Crown corporation anticipates province will stablilize next year\n",
            "0\n",
            "Powell hints Federal Reserve will cut rates if needed over trade wars. Expectations are rising that the Fed will cut rates at least once and possibly twice before year's end\n",
            "0\n",
            "Canada's economy lost 2,200 jobs last month. Jobless rate ticks up to 5.5%, although past year has seen 421,000 jobs added\n",
            "-1\n",
            "As the U.S. economy tilts toward concern, Canada's is on the upswing: Don Pittis. Federal Reserve chair Jerome Powell holds interest rates steady, but opens the door to future cuts\n",
            "-1\n",
            "Police worry about budget cuts at social agencies as crime rate increases. DOAP Team is dramatically scaling back patrols\n",
            "0\n",
            "As the U.S. economy tilts toward concern, Canada's is on the upswing: Don Pittis. Federal Reserve chair Jerome Powell holds interest rates steady, but opens the door to future cuts\n",
            "-1\n",
            "If COVID-19 creates an economic crisis, many see stimulus as a chance for change: Don Pittis. Morneau and others must decide whether to use bailouts to perpetuate what some see as an ailing status quo\n",
            "0\n",
            "Saint John tax assessment not yet catching up to hot sales market. 1.83% assessment growth actually improves on much of past 6 years\n",
            "1\n",
            "Calgary had a lot more shoplifting but a lot fewer homicides last year. City's crime severity index rose 5% in 2018 while provincial rating remains steady\n",
            "1\n",
            "Retailers foresee holiday joy — even as Poloz looks to hold line on rates: Don Pittis. While the world cuts interest rates, the Bank of Canada likely won't if we keep shopping\n",
            "0\n",
            "If COVID-19 creates an economic crisis, many see stimulus as a chance for change: Don Pittis. Morneau and others must decide whether to use bailouts to perpetuate what some see as an ailing status quo\n",
            "0\n",
            "'Stop building' hotels in Calgary, industry urges, as supply of rooms outstrips demand. City has seen 2,600 new rooms added in the past 3 years, and 1,200 of those are less than a year old\n",
            "0\n",
            "'Stop building' hotels in Calgary, industry urges, as supply of rooms outstrips demand. City has seen 2,600 new rooms added in the past 3 years, and 1,200 of those are less than a year old\n",
            "0\n",
            "'Secret' memo outlines tools the finance department and Bank of Canada could use in a recession. Economists say Ottawa needs a new playbook to tackle the next global recession\n",
            "0\n",
            "Growing demand prompts Sydney shelter to move into bigger location. 'It's very difficult to find affordable housing right now in this community'\n",
            "0\n",
            "'Stop building' hotels in Calgary, industry urges, as supply of rooms outstrips demand. City has seen 2,600 new rooms added in the past 3 years, and 1,200 of those are less than a year old\n",
            "0\n",
            "Last week's gloom and doom has not seized Canadian economy yet: Don Pittis. Can the economy withstand the latest barrage of gloomy economic news?\n",
            "0\n",
            "'Secret' memo outlines tools the finance department and Bank of Canada could use in a recession. Economists say Ottawa needs a new playbook to tackle the next global recession\n",
            "0\n",
            "New mortgage loans slowed in Canada but overall value is still rising, says CMHC. The average value of a mortgage reached $209,570, which is more than 3% higher than a year ago\n",
            "0\n",
            "Rising home prices encourage consumers to borrow and spend, giving economy a boost. Bank of Canada study analyzes spending triggered by borrowing against the house\n",
            "-1\n",
            "New mortgage loans slowed in Canada but overall value is still rising, says CMHC. The average value of a mortgage reached $209,570, which is more than 3% higher than a year ago\n",
            "0\n",
            "Who is Daniel Bard, the elusive man at centre of missing money scandal?. Moncton man, formerly employed by government-funded agency, being investigated by RCMP for breach of trust\n",
            "-1\n",
            "Growing push to tax both vacant, luxury homes during city's budget process. Hiking tax on pricey properties is 'housing paying for housing,' councillor says\n",
            "0\n",
            "Who is Daniel Bard, the elusive man at centre of missing money scandal?. Moncton man, formerly employed by government-funded agency, being investigated by RCMP for breach of trust\n",
            "-1\n",
            "Everything happens at once: how one week of the COVID-19 crisis went for the Trudeau government. The early response is hitting the right notes - but there will be opportunities for recrimination later\n",
            "0\n",
            "When student housing was hard to come by in Vancouver. In 1981, there wasn't much available for students and what was available was pretty expensive\n",
            "0\n",
            "Government says new Victoria micro-apartments will help with middle-income housing crisis. Housing advocates say the project still doesn't address the growing need for middle-income family housing\n",
            "0\n",
            "Government says new Victoria micro-apartments will help with middle-income housing crisis. Housing advocates say the project still doesn't address the growing need for middle-income family housing\n",
            "0\n",
            "When student housing was hard to come by in Vancouver. In 1981, there wasn't much available for students and what was available was pretty expensive\n",
            "0\n",
            "Saskatoon downtown office vacancy rate will increase as River Landing progresses: analyst. Vacancy rate will grow to more than 20 per cent, observers say\n",
            "0\n",
            "Pro-democracy activist Joshua Wong barred from Hong Kong election. Wong has been repeatedly arrested and jailed since playing key role in 2014 protests\n",
            "0\n",
            "Moncton gets fair share of real estate boom. Home sales in Moncton are up 23.7 per cent compared to the first five months of 2018\n",
            "1\n",
            "Counterfeit crackdown; cannabis costs: CBC's Marketplace consumer cheat sheet. Newsletter: Consumer and health news you need from the week\n",
            "0\n",
            "Nygard company signed $50M US loan security on Christmas Day. Peter Nygard also owes $1.6M to crisis-response firm; company wants Manitoba court to make him pay\n",
            "-1\n",
            "Counterfeit crackdown; cannabis costs: CBC's Marketplace consumer cheat sheet. Newsletter: Consumer and health news you need from the week\n",
            "0\n",
            "Ontario's rising rents hurt the poor, Ottawa advocates say. Province raises cap on rent increase to 2.2% for 2020, highest hike since 2013\n",
            "-1\n",
            "CMHC reports annual pace of housing starts climbed 1.9% in August. Housing starts rose to 226,639 units in August, up from 222,467 units in July\n",
            "1\n",
            "Green Party bill to provide snapshot of short-term rentals on P.E.I. using 'accurate, objective data'. MLA says idea is to eventually curtail growth of the industry to ease pressure on housing\n",
            "0\n",
            "Harsh winter cools Sudbury's real estate market. In some aspects it's cheaper to own a home than rent, Real Estate Board says\n",
            "0\n",
            "Harsh winter cools Sudbury's real estate market. In some aspects it's cheaper to own a home than rent, Real Estate Board says\n",
            "0\n",
            "N.L. home construction at 50-year low, but sales on the rise following disastrous year. Real estate leaders hoping industry has bottomed out, and better days ahead\n",
            "0\n",
            "Stock markets sell off as inverted yield curve in bond market prompts recession fears. Dow Jones loses 800 points, TSX down almost 300\n",
            "-1\n",
            "N.L. home construction at 50-year low, but sales on the rise following disastrous year. Real estate leaders hoping industry has bottomed out, and better days ahead\n",
            "0\n",
            "With real estate market booming, Montreal property assessments climb 13.7%. Beaconsfield, Hampstead, Mount Royal, Kirkland and Westmount among those with biggest jumps\n",
            "0\n",
            "From fossil fuels to Muskrat: How MUN could lead the charge to electrify public buildings. Shift to electricity at Memorial University could displace 11 million litres of diesel annually\n",
            "0\n",
            "Can the Tories double the rate of job creation in Manitoba?. PCs promise 40,000 new jobs in 4 years ... that's more new jobs than Manitoba added in the previous 9 years\n",
            "1\n",
            "With real estate market booming, Montreal property assessments climb 13.7%. Beaconsfield, Hampstead, Mount Royal, Kirkland and Westmount among those with biggest jumps\n",
            "0\n",
            "New cabinet must make the best of an uncertain economic outlook: Don Pittis. Market indicators turn optimistic on global economy but others say, 'Hold on'\n",
            "1\n",
            "From fossil fuels to Muskrat: How MUN could lead the charge to electrify public buildings. Shift to electricity at Memorial University could displace 11 million litres of diesel annually\n",
            "0\n",
            "Former Bank of Canada governor Mark Carney to serve as UN special envoy on climate. Carney drew international acclaim during his 5 years as Canada's top central banker\n",
            "0\n",
            "U.S. central bank cuts interest rate again — but split on what to do next. Federal Reserve moving to stimulate economy as trade fears mount\n",
            "-1\n",
            "Former Bank of Canada governor Mark Carney to serve as UN special envoy on climate. Carney drew international acclaim during his 5 years as Canada's top central banker\n",
            "0\n",
            "Interest in off-grid homes growing, but mortgages haven't kept pace. People who work in the solar power industry report growing interest in self-sufficient homes\n",
            "0\n",
            "Rent hike tension spills over at Carling Avenue highrise. After protest, Timbercreek management agrees to meet with tenants\n",
            "0\n",
            "CMHC sees 'moderate overvaluation' in Canada's housing market, but little vulnerability overall. Quarterly report finds pockets of concern, but overall lower level of risk\n",
            "0\n",
            "U.S. central bank cuts interest rate again — but split on what to do next. Federal Reserve moving to stimulate economy as trade fears mount\n",
            "-1\n",
            "The search for jobs and a recovery in Red Deer: 'There's absolutely nothing out there'. People, business owners, social agencies 'continue to struggle' in central Alberta city\n",
            "0\n",
            "Demand for rental units on the rise in Saint John. Study indicates 1,500 new rental units in development, thousands more needed\n",
            "0\n",
            "How fast is your cost of living going up? Play our interactive game. Try your hand at guessing inflation rates in various categories\n",
            "0\n",
            "Canadians took on less debt in first quarter of 2019 — but total amount they owe is still growing. Debt to disposable income ratio holds steady at 177%, just below record high set in 2018\n",
            "1\n",
            "The search for jobs and a recovery in Red Deer: 'There's absolutely nothing out there'. People, business owners, social agencies 'continue to struggle' in central Alberta city\n",
            "0\n",
            "This Toronto landlord has only raised rent by $100 — since the 1980s. Downtown apartments going for as little as $800 per month, thanks to novelist David Kendall\n",
            "0\n",
            "St. John's housing prices will lead country in growth, according to Moody's. Economist says below-trend prices, drop in unemployment rate leading to predicted increase\n",
            "-1\n",
            "Short-term rental owners speak out over proposed Charlottetown bylaw. 'If all of my units were returned to the long-term market — none of them are affordable'\n",
            "0\n",
            "Federal Reserve holds key interest rate steady — but its patience is wearing thin. U.S. central bank keeps benchmark rate in range between 2.25% and 2.5%\n",
            "1\n",
            "How fast is your cost of living going up? Play our interactive game. Try your hand at guessing inflation rates in various categories\n",
            "0\n",
            "Housing market rebounded in May from record lows earlier in the year, CREA says. Number of home sales inching higher, but prices still lower than they were in 2018\n",
            "1\n",
            "Federal Reserve holds key interest rate steady — but its patience is wearing thin. U.S. central bank keeps benchmark rate in range between 2.25% and 2.5%\n",
            "1\n",
            "Housing market rebounded in May from record lows earlier in the year, CREA says. Number of home sales inching higher, but prices still lower than they were in 2018\n",
            "1\n",
            "His business nearly collapsed when the EU was created. Now this customs broker is readying for a Brexit boom. With Boris Johnson poised to 'get Brexit done,' George Baker says he could see a 500 per cent jump in business\n",
            "1\n",
            "Short-term rental owners speak out over proposed Charlottetown bylaw. 'If all of my units were returned to the long-term market — none of them are affordable'\n",
            "0\n",
            "Federal Reserve holds key interest rate steady — but its patience is wearing thin. U.S. central bank keeps benchmark rate in range between 2.25% and 2.5%\n",
            "1\n",
            "To pay off or borrow more is the question facing Canadians: Don Pittis. As recession threatens and an election beckons is it time for us to borrow or time to shuck debt? \n",
            "0\n",
            "To pay off or borrow more is the question facing Canadians: Don Pittis. As recession threatens and an election beckons is it time for us to borrow or time to shuck debt? \n",
            "0\n",
            "Global uncertainty prompts rethink of B.C. budget projections. Finance Minister Carole James delivered the 2019 first-quarter financial results Monday\n",
            "-1\n",
            "'Unprecedented times' could mean unprecedented options on the table to aid provinces. Academics, think-tanks believe federal government may need to do more\n",
            "0\n",
            "Toronto police union calls allegations it mishandled millions of dollars 'misinformation'. TPA sold its HQ for $7.4M. It was flipped a year later for $11.5M, records show\n",
            "0\n",
            "International buyers eye N.S. vacation properties — especially in Cape Breton. Recent numbers from Statistics Canada show N.S. has higher rate of non-resident owners than B.C., Ontario\n",
            "0\n",
            "North Bay real estate investors share how to finalize the deal. Dave and Melanie Dupuis share tips on navigating the real estate investment world\n",
            "0\n",
            "Dow at record above 27,000 as U.S. rate cuts look likely. Powell's testimony to Congress indicates key rate could be cut in July\n",
            "0\n",
            "Saint John housing programs more effective, but shelter use on the rise, report shows. More co-ordinated approach to homelessness needed, says Human Development Council \n",
            "0\n",
            "North Bay real estate investors share how to finalize the deal. Dave and Melanie Dupuis share tips on navigating the real estate investment world\n",
            "0\n",
            "Saint John housing programs more effective, but shelter use on the rise, report shows. More co-ordinated approach to homelessness needed, says Human Development Council \n",
            "0\n",
            "U.S. corporate leaders swing left to fix 'frayed' American dream: Don Pittis. But critics call 11th-hour conversion a smokescreen to block new rules and taxes\n",
            "0\n",
            "Extreme measures: European governments pull out the stops to slow COVID-19. Europe's measures could offer a glimpse of Canada's future\n",
            "0\n",
            "'We should approach the issue very carefully': Nations pressured to loosen COVID-19-related rules. The decisions are complicated because each country is on its own coronavirus arc\n",
            "0\n",
            "Extreme measures: European governments pull out the stops to slow COVID-19. Europe's measures could offer a glimpse of Canada's future\n",
            "0\n",
            "Green MLA calls on province to regulate short-term rentals. Minister Ernie Hudson says he wants to collaborate with municipalities, not 'dictate' \n",
            "0\n",
            "Extreme measures: European governments pull out the stops to slow COVID-19. Europe's measures could offer a glimpse of Canada's future\n",
            "0\n",
            "'We should approach the issue very carefully': Nations pressured to loosen COVID-19-related rules. The decisions are complicated because each country is on its own coronavirus arc\n",
            "0\n",
            "Yellowknife's housing market slows as economic slump looms on the horizon: CMHC. CMHC's annual report on Northern housing shows mixed outlook across the 3 territories \n",
            "-1\n",
            "Even in an 'affordable' Canadian city, cost-of-living squeeze has people putting pressure on politicians. Cost of living is a big federal election issue, even in places where daily expenses are lower than average\n",
            "-1\n",
            "P.E.I. needs more pet-friendly housing, say violence prevention advocates. 'Finding housing even if you have no barriers is very very difficult'\n",
            "0\n",
            "Yellowknife's housing market slows as economic slump looms on the horizon: CMHC. CMHC's annual report on Northern housing shows mixed outlook across the 3 territories \n",
            "-1\n",
            "Even in an 'affordable' Canadian city, cost-of-living squeeze has people putting pressure on politicians. Cost of living is a big federal election issue, even in places where daily expenses are lower than average\n",
            "-1\n",
            "Having trouble finding housing in eastern P.E.I.? Rotary wants to know. Vacancy rates on P.E.I. are at a record low\n",
            "0\n",
            "Even in an 'affordable' Canadian city, cost-of-living squeeze has people putting pressure on politicians. Cost of living is a big federal election issue, even in places where daily expenses are lower than average\n",
            "-1\n",
            "When grocery stores are the only game in town, even entrepreneurs turn into employees. Leadership coaches, fashion designers jump at chance to deliver groceries, wash down produce\n",
            "0\n",
            "Vancouver Tenants Union wants to build an eviction database. Group says there's a 'big gap' because most eviction data isn't currently recorded anywhere\n",
            "0\n",
            "Province not prepared to ease policies as housing market sputters. Vancouver homeowners cite rising taxes, falling equity; NDP argues moderation is improving affordability\n",
            "0\n",
            "Province not prepared to ease policies as housing market sputters. Vancouver homeowners cite rising taxes, falling equity; NDP argues moderation is improving affordability\n",
            "0\n",
            "Low-income rates could rise as StatsCan moves to redraw poverty line. Poverty rates increased by 2.2 per cent the last time the measurement changed in 2008\n",
            "-1\n",
            "Oil prices take biggest plunge in decades, taking another bite out of reeling Alberta. Alberta Premier Kenney, with softened tone, shifts emphasis from restraint to protection of economy, jobs\n",
            "0\n",
            "Getting past the senior stereotypes: U of A researcher says attitudes need to mature. As population ages, discrimination based on age will cause increasing harm\n",
            "0\n",
            "Getting past the senior stereotypes: U of A researcher says attitudes need to mature. As population ages, discrimination based on age will cause increasing harm\n",
            "0\n",
            "Shutdown order will kill some businesses, advocates warn. Ontario, Quebec ordering non-essential businesses closed for 14 days by midnight\n",
            "0\n",
            "Low-income rates could rise as StatsCan moves to redraw poverty line. Poverty rates increased by 2.2 per cent the last time the measurement changed in 2008\n",
            "-1\n",
            "'Recessionary conditions' pushing home prices lower in B.C., report says. Median price projected to be 4.1% lower in 2019, marking 1st decline in 7 years\n",
            "0\n",
            "Mike Bloomberg courts black voters, but past record as NYC mayor under scrutiny. Opponents unearth past comments on policing and housing, which they say aren't reflective of Democratic Party\n",
            "0\n",
            "Support coming for Canadians quarantined due to coronavirus, finance minister says. Liberal government will increase the risk adjustment provision in the upcoming budget\n",
            "0\n",
            "All eyes on Canadian jobs numbers as election heads into 5th week: Don Pittis. Still few signs of Canadian recession, but this week's data may tell us more\n",
            "0\n",
            "Why this economist says equalization reform isn't the answer if Alberta wants help during its busts. Revised fiscal stabilization program would hold most promise for the province, Bev Dahlby argues\n",
            "0\n",
            "'They squandered the good times': Poilievre says Canada lacks 'cushion' to weather economic crises. Conservative finance committee members criticize Liberal record ahead of federal budget\n",
            "-1\n",
            "Should you feel guilty for taking family money to buy a home?. One woman explains why she felt guilty after getting family money to pay for her down payment\n",
            "0\n",
            "Former Bank of Canada governor Mark Carney urges financial sector to act against climate change. Carney is set to become the UN's special envoy for climate change next year\n",
            "0\n",
            "'Cheaper, warmer and newer': P.E.I. seniors move into new affordable building. 'Some people can’t afford $1,200, $1,300 a month in rent, it’s crazy' \n",
            "0\n",
            "Fort Saskatchewan condo residents waiting for answers a month after evacuation. Resident says 95 per cent of belongings left behind, doesn't know when he can get them\n",
            "0\n",
            "High household debt, possible housing market shocks are main risks to the economy: Bank of Canada. Stephen Poloz, governor of the Bank of Canada, will speak to reporters after latest financial review\n",
            "0\n",
            "Vancouver is still in a housing crisis. But when will we know if it's over?. It's a question without a defined answer — but one that could have big policy implications down the road\n",
            "0\n",
            "Highrise condo buyer denied insurance due to flood emergency. Aviva Canada turned down Inna Nei, citing state of emergency declared in April\n",
            "-1\n",
            "Highrise condo buyer denied insurance due to flood emergency. Aviva Canada turned down Inna Nei, citing state of emergency declared in April\n",
            "-1\n",
            "She fled domestic abuse. Now she and her daughter are victims of the housing crisis. Shelters are full, wait lists are long and market rents are too high for most single mothers\n",
            "-1\n",
            "When 'math is accessible to any brain,' we can make better political, social choices, says mathematician. Math could help people make more rational, thought-out decisions, says John Mighton\n",
            "0\n",
            "Zombie debt will haunt more Canadians as scourge of indebtedness rises: experts. Be warned, old debts can be resurrected\n",
            "0\n",
            "How a leaner, regulated Nalcor could save millions and better protect consumers. Liberty Consulting is proposing a dramatic shakeup at embattled Crown corporation in the Muskrat era\n",
            "0\n",
            "How a leaner, regulated Nalcor could save millions and better protect consumers. Liberty Consulting is proposing a dramatic shakeup at embattled Crown corporation in the Muskrat era\n",
            "0\n",
            "Why 4 websites give you 4 different credit scores — and none is the number most lenders actually see. The most popular credit score that lenders use in Canada can’t be accessed directly by consumers\n",
            "0\n",
            "A tale of two tenants: B.C. renters feeling affordability squeeze as parties campaign on housing. Metro Vancouver is home to 6 of the most expensive ridings for renters in all of Canada\n",
            "0\n",
            "Why 4 websites give you 4 different credit scores — and none is the number most lenders actually see. The most popular credit score that lenders use in Canada can’t be accessed directly by consumers\n",
            "0\n",
            "Island voters prepare to go back to the polls. 'People were not looking forward to this election, more like dreading this election'\n",
            "0\n",
            "Island voters prepare to go back to the polls. 'People were not looking forward to this election, more like dreading this election'\n",
            "0\n",
            "Here's what Calgarians will be paying more for in 2020. Here's a list of what goes up in price for Calgarians as of Jan. 1\n",
            "0\n",
            "COVID-19: Here's what's happening around the world March 4. Italy cases top 3,000 with over 100 dead, as the sick in South Korea wait for beds\n",
            "0\n",
            "Stock markets down on growing concern about coronavirus in China. Canada's main stock index fell for the first time in 7 sessions on concerns about the outbreak\n",
            "0\n",
            "'Tent town' draws attention to Island's affordable housing crisis. 'There are people that are very close to this situation … there are people living in cars.'\n",
            "0\n",
            "Why earnings in Alberta have been stagnant for years. Albertans earn less because they're working less, and working differently\n",
            "0\n",
            "COVID-19: Here's what's happening around the world March 4. Italy cases top 3,000 with over 100 dead, as the sick in South Korea wait for beds\n",
            "0\n",
            "Modelling suggests as many as 800,000 COVID-19 infections could sweep Alberta, Premier Jason Kenney says. ‘Perhaps the greatest challenge of our generation,’ Kenney says during televised address \n",
            "0\n",
            "'Rents have just gone sky high': Cardigan candidates, voters weigh in on housing crisis. 'It's nothing that a senior can really afford'\n",
            "0\n",
            "Forget Toronto. Buying in P.E.I. increasingly 'cutthroat' as home prices rise. 'People are banging on doors, saying 'I really like your house, are you interested in selling?'\n",
            "0\n",
            "Scheer pitches east-west energy corridor, blasts Trudeau for 'all-out attack' on oil. Conservative leader insists he can return budget to balance without deep spending cuts\n",
            "-1\n",
            "Ford layoffs another hint Canada is heading for peak car: Don Pittis. The automotive industry has lost its place as a keystone of the Canadian economy\n",
            "0\n",
            "Recounting a devastating week in North America's biggest oil play. A day-by-day account in the west Texas oilfields as oil markets in a free fall\n",
            "0\n",
            "Recounting a devastating week in North America's biggest oil play. A day-by-day account in the west Texas oilfields as oil markets in a free fall\n",
            "0\n",
            "Toronto area housing sales up 24.3% in July, prices rise due to tighter supply. Overall average selling price for properties in GTA was $806,755\n",
            "0\n",
            "Liberals move to deliver tax cut they say will help 20 million Canadians. Finance minister says new measure will lower taxes for people earning less than about $150K a year\n",
            "0\n",
            "PM says closures, social distancing measures could be in place for weeks or months. COVID-19 emergency funds will be flowing in 2 to 3 weeks, government promises\n",
            "0\n",
            "Toronto area housing sales up 24.3% in July, prices rise due to tighter supply. Overall average selling price for properties in GTA was $806,755\n",
            "0\n",
            "'I've never felt shame like this in my life': 500 homeless, 5,000 await affordable housing. Despite desperate need for affordable housing, new agreement will create just 151 units in first 3 years \n",
            "0\n",
            "What's the difference between the Conservative and Liberal platforms? The colour: Robyn Urback. This election essentially comes down to whose face you won't mind staring at for the next 4 years\n",
            "0\n",
            "What's the difference between the Conservative and Liberal platforms? The colour: Robyn Urback. This election essentially comes down to whose face you won't mind staring at for the next 4 years\n",
            "0\n",
            "Stocks fall as trade concerns spark growth fears, push investors to bonds. Each of the major U.S. indexes suffered their fourth decline in five sessions\n",
            "0\n",
            "Stocks fall as trade concerns spark growth fears, push investors to bonds. Each of the major U.S. indexes suffered their fourth decline in five sessions\n",
            "0\n",
            "CIBC, TD close bleak 4th-quarter earning season with lower profit. CIBC drew an impairment charge for the sale of its stake in Barbadian bank\n",
            "0\n",
            "CIBC, TD close bleak 4th-quarter earning season with lower profit. CIBC drew an impairment charge for the sale of its stake in Barbadian bank\n",
            "0\n",
            "Green Party platform aims to transition economy, protect consumers, promote tax fairness. Leader Elizabeth May says full costing of election promises to come within a week\n",
            "0\n",
            "As province gets stable credit ratings, finance minister says can't cut services for surplus. Tom Osborne is no longer promising the province will reach surplus in 2022-23\n",
            "-1\n",
            "Transat still negotiating takeover with Air Canada, as rival bidder says counteroffer is coming. Two companies are still negotiating until exclusive window closes on June 26\n",
            "0\n",
            "Coronavirus: Here's what's happening in Canada and around the world on March 13. The federal government warns Canadians against travelling outside of the country\n",
            "0\n",
            "Coronavirus: Here's what's happening in Canada and around the world on March 13. The federal government warns Canadians against travelling outside of the country\n",
            "0\n",
            "Coronavirus: What's happening in Canada and around the world on March 27. Bank of Canada makes another emergency rate cut, U.K. prime minister tests positive\n",
            "-1\n",
            "Coronavirus: Here's what's happening in Canada and the world March 19. PM talks about need for increased testing, travel restrictions between Canada and U.S.\n",
            "0\n",
            "Crown, Keith Hobbs spar in day 13 of former mayor's extortion trial. Keith Hobbs, wife Marisa, Mary Voss all face one charge each of extortion\n",
            "0\n",
            "Crown, Keith Hobbs spar in day 13 of former mayor's extortion trial. Keith Hobbs, wife Marisa, Mary Voss all face one charge each of extortion\n",
            "0\n",
            "Crown, Keith Hobbs spar in day 13 of former mayor's extortion trial. Keith Hobbs, wife Marisa, Mary Voss all face one charge each of extortion\n",
            "0\n",
            "Signs gambling has become a potential problem. And what you can do to get back on track\n",
            "0\n",
            "Signs gambling has become a potential problem. And what you can do to get back on track\n",
            "0\n",
            "On housing, local authorities bemoan territory's 'paternalistic' policies. Local authorities, contractors point finger at the N.W.T. Housing Corporation for granting ‘limited control’\n",
            "0\n",
            "N.B. COVID-19 roundup: Province braces for 'next big wave' of coronavirus. Premier Blaine Higgs and Dr. Jennifer Russell say returning travellers who have no symptoms pose risk\n",
            "0\n",
            "OPINION | NDP climate plan tries (and fails) to carve out middle ground. The plan is riddled with inconsistencies and short on details\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqxuE1-C8C3Q",
        "colab_type": "code",
        "outputId": "836828f7-2e43-4e02-a7ba-3324c58ad070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "out_filepath = data_folder + \"/unannotated_mortgagerate_CBC_predictions.csv\"\n",
        "print(out_filepath)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./drive/My Drive/Colab Notebooks/capstone/data//unannotated_mortgagerate_CBC_predictions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3wJcDN0-NcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df.to_csv(out_filepath,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LJrM4eJ4-6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c6988ba8-6365-48ac-bec4-9967f79e1823"
      },
      "source": [
        "mort_test_df = pd.read_csv(data_folder + \"/test.csv\", header=None)\n",
        "\n",
        "mort_test_df.head()\n",
        "  "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>Finnish metal products company Componenta Oyj ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Incap and Lankapaja aim to enter into actual a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>Turkish stocks tumble as crackdown on lira spe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Summer Winds Down, and Big Tech Is Called Befo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>Here's why the slump in semiconductor stocks m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                                  1\n",
              "0 -1  Finnish metal products company Componenta Oyj ...\n",
              "1  1  Incap and Lankapaja aim to enter into actual a...\n",
              "2 -1  Turkish stocks tumble as crackdown on lira spe...\n",
              "3  1  Summer Winds Down, and Big Tech Is Called Befo...\n",
              "4 -1  Here's why the slump in semiconductor stocks m..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_vRywDs-ePH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2817e498-7110-46fc-b1eb-f04d51f4f3dc"
      },
      "source": [
        "correct = 0\n",
        "severe_incorrect = 0\n",
        "for i in range(len(corpus.test)):\n",
        "  print(i)\n",
        "\n",
        "  \n",
        "  #get predictions\n",
        "  #print(gdp_test_df['title_desc'].iloc[i])\n",
        "  #print(mort_test_df.iloc[i,1])\n",
        "  sentence = Sentence(mort_test_df.iloc[i,1])\n",
        "  mortgage_classifier.predict(sentence)\n",
        "  #print(sentence.labels)\n",
        "  # #get gold label\n",
        "  # print(corpus.test[i].labels)\n",
        "  # #calculate correct guesses\n",
        "  if sentence.labels[0].value == corpus.test[i].labels[0].value:\n",
        "    correct += 1\n",
        "  else:\n",
        "\n",
        "    print(\"INCORRECT CLASSIFICATION: \")\n",
        "    print(\"TEXT: \", sentence)\n",
        "    print(\"TRUE LABEL: \", corpus.test[i].labels[0].value)\n",
        "    print(\"PRED: \",sentence.labels[0].value)\n",
        "    \n",
        "    if corpus.test[i].labels[0].value != \"0\" and sentence.labels[0].value != \"0\":\n",
        "      severe_incorrect += 1\n",
        "\n",
        "\n",
        "  print(\"----\")\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "----\n",
            "1\n",
            "----\n",
            "2\n",
            "----\n",
            "3\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Summer Winds Down, and Big Tech Is Called Before Congress. The newest jobs numbers are expected to show healthy gains, and Detroit automakers will report sales for August.\"   [− Tokens: 28  − Sentence-Labels: {'class': [0 (0.5657)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "4\n",
            "----\n",
            "5\n",
            "----\n",
            "6\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Many listed stocks currently undervalued. More than half of listed stocks here are trading at prices below \"book value\" . suited for valuing capital-intensive companies or financial businesses with a lot of .\"   [− Tokens: 33  − Sentence-Labels: {'class': [1 (0.4755)]}]\n",
            "TRUE LABEL:  0\n",
            "PRED:  1\n",
            "----\n",
            "7\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Revenue grew 1 percent to euro742 .2 million US$ 964 million from euro735 million .\"   [− Tokens: 15  − Sentence-Labels: {'class': [0 (0.8079)]}]\n",
            "TRUE LABEL:  1\n",
            "PRED:  0\n",
            "----\n",
            "8\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"The Point Village , designed by Scott Tallon Walker , will include a shopping center , office premises , a hotel and a cinema .\"   [− Tokens: 25  − Sentence-Labels: {'class': [0 (0.9933)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "9\n",
            "----\n",
            "10\n",
            "----\n",
            "11\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Outokumpu of Finland , stainless steel manufacturer , plans to enter into a supply agreement with the Indian Railways .\"   [− Tokens: 20  − Sentence-Labels: {'class': [0 (0.982)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "12\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"How 9/11 still affects stock, bond investors. Moreover, without strong economic growth to cushion it, the market likely will . . “China developed a business model based on reinforcing the worst aspects of .\"   [− Tokens: 34  − Sentence-Labels: {'class': [0 (0.6038)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "13\n",
            "----\n",
            "14\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Aspocomp has repaid its interest bearing liability to Standard Chartered Bank and will use the rest of the consideration to partially repay its interest bearing liabilities in Finland and to improve its liquidity .\"   [− Tokens: 34  − Sentence-Labels: {'class': [0 (0.9596)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "15\n",
            "----\n",
            "16\n",
            "----\n",
            "17\n",
            "----\n",
            "18\n",
            "----\n",
            "19\n",
            "----\n",
            "20\n",
            "----\n",
            "21\n",
            "----\n",
            "22\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"This includes a EUR 39.5 mn change in the fair value of investment properties .\"   [− Tokens: 15  − Sentence-Labels: {'class': [0 (0.992)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "23\n",
            "----\n",
            "24\n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg-KPkMC370O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "64299eb4-dc9d-45ed-ec2e-225fc1616b57"
      },
      "source": [
        "\n",
        "print(\"CORRECT: \",correct/len(corpus.test))\n",
        "print(\"INCORRECT: \",1 - correct/len(corpus.test))\n",
        "print(\"OPPOSITE PREDICTIONS (SEVERELY INCORRECT): \",severe_incorrect/len(corpus.test))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CORRECT:  0.68\n",
            "INCORRECT:  0.31999999999999995\n",
            "OPPOSITE PREDICTIONS (SEVERELY INCORRECT):  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzj8_OEJ63_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}