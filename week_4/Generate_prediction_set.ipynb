{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for extracting prediction articles\n",
    "# Logic (full_articles.json - articles_used_for_training)\n",
    "# Author: Pandramishi Naga Sirisha\n",
    "# Date: 26th May 2020\n",
    "## Enhancements:\n",
    "#1. encapsulate in a function, modify week2 code as well so you can import that function\n",
    "#2. write code to delete _to_convert.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json \n",
    "import json\n",
    "import datetime\n",
    "import pytz\n",
    "import dateutil.parser\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(filename, list_name, file_suffix):\n",
    "    \"\"\"creates a csv containing title and description of articles in a given JSON.\n",
    "    Re-using this function from Sampling_articles_by_month.ipynb from week_2\"\"\"\n",
    "    ind = 0\n",
    "    title_list = []\n",
    "    desc_list = []\n",
    "    date_list =[]\n",
    "    source_list = []\n",
    "    invalid_articles = 0\n",
    "    \n",
    "    for json_dict in list_name:\n",
    "        #check if valid title exists\n",
    "        if json_dict[\"title\"]:\n",
    "            title_list.append(json_dict[\"title\"])\n",
    "            desc_list.append(json_dict[\"description\"])\n",
    "            date_list.append(dateutil.parser.parse(json_dict['publishedAt'][1]).date())\n",
    "            source_list.append(\"CBC\")\n",
    "            ind += 1\n",
    "            \n",
    "        else:\n",
    "            invalid_articles += 1\n",
    "            \n",
    "    print(\"Invalid articles :\", invalid_articles)        \n",
    "    prefix = filename.split(\".\")[0]\n",
    "    out_filename = prefix  + \"_\" + str(ind) + \"_\" + file_suffix + \".csv\"\n",
    "    with open(out_filename, 'w') as myfile:\n",
    "        writer = csv.writer(myfile)\n",
    "        #wr.writerow(mylist)\n",
    "        writer.writerow([\"title\", \"description\"])\n",
    "        for i in range(len(title_list)):\n",
    "            writer.writerow([title_list[i], desc_list[i], date_list[i], source_list[i]])\n",
    "    myfile.close()\n",
    "    print(\"Output file name is :\", out_filename)\n",
    "    return out_filename\n",
    "                \n",
    "# json_to_csv(\"mortgage_rates_CBC_article.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./Full_articles_unannotated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"TSX_CBC_article.json\"\n",
    "economic_indicator_name = \"stock_market\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + file_name ) as f:\n",
    "    list_of_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid articles : 84\n",
      "Output file name is : TSX_CBC_article_886_convert.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title_desc</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBC</td>\n",
       "      <td>TSX and NYSE closed for Good Friday but Asian ...</td>\n",
       "      <td>2020-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBC</td>\n",
       "      <td>TSX and Dow make gains Thursday but coronaviru...</td>\n",
       "      <td>2020-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBC</td>\n",
       "      <td>TSX and Dow plunge back into the red Friday, c...</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CBC</td>\n",
       "      <td>TSX and Dow Jones bounce back somewhat after m...</td>\n",
       "      <td>2020-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBC</td>\n",
       "      <td>TSX and Dow Jones lose another 10% as coronavi...</td>\n",
       "      <td>2020-03-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                         title_desc publishedAt\n",
       "0    CBC  TSX and NYSE closed for Good Friday but Asian ...  2020-04-10\n",
       "1    CBC  TSX and Dow make gains Thursday but coronaviru...  2020-03-19\n",
       "3    CBC  TSX and Dow plunge back into the red Friday, c...  2020-03-20\n",
       "5    CBC  TSX and Dow Jones bounce back somewhat after m...  2020-03-17\n",
       "6    CBC  TSX and Dow Jones lose another 10% as coronavi...  2020-03-16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing full articles' dataframe to get required format\n",
    "# Read article in json format and output as csv to process data easily as dataframes\n",
    "full_article_file_name = json_to_csv(file_name, list_of_json, \"convert\")\n",
    "full_df = pd.read_csv(full_article_file_name, sep=',', names=['title', 'description', 'publishedAt', 'source'], skiprows = 1)\n",
    "full_df[\"title_desc\"] = full_df ['title'] + \". \" + full_df['description']\n",
    "full_df = full_df.drop(columns = ['title', 'description'])\n",
    "full_df = full_df[['source','title_desc', 'publishedAt' ]]\n",
    "full_df = full_df.dropna(how='any',axis=0)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe type to datetime\n",
    "import pandas\n",
    "full_df['publishedAt'] =  pd.to_datetime(full_df['publishedAt'], format='%Y-%m-%d')\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to check if all the articles are from 2019-05-12 to 2020-05-12\n",
    "import pandas\n",
    "cond1 = full_df.publishedAt > pd.Timestamp(2019,5,12)\n",
    "x = full_df.loc[cond1, ]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"HBC shares up on news of likely takeover deal. Baker group poised to gain control of retailer after agreeing to Catalyst Capital's higher asking price\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing training dataframe to get required format\n",
    "training_df = pd.read_csv(\"./final_cbc_annotations/\" + economic_indicator_name+ \"_combined_annotations_CBC.csv\", names = ['title','description', 'publishedAt', 'title_desc_sent_1', 'source'], skiprows = 1)\n",
    "training_df[\"title_desc\"] = training_df ['title'] + \". \" + training_df['description']\n",
    "training_df = training_df.drop(columns = ['title', 'description','title_desc_sent_1'])\n",
    "training_df = training_df[['source','title_desc', 'publishedAt' ]]\n",
    "training_df.iloc[0]['title_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do a left join  between two dataframes\n",
    "final = pd.merge(full_df,training_df,on='title_desc',how='left', indicator=True)\n",
    "# final = final.dropna(how='any',axis=0)\n",
    "\n",
    "# Getting only (left_only) rows to make it left OUTER join\n",
    "final = final[final['_merge'] == 'left_only']\n",
    "final = final.drop(columns = ['source_y','publishedAt_y','_merge'])\n",
    "final.columns = ['source','title_desc', 'publishedAt']\n",
    "final.shape\n",
    "# final.ix[62]['title_desc'] == training_df.iloc[0]['title_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output final prediction file\n",
    "final.to_csv(file_name.split(\".\")[0] + \"_to_predict.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
