{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Two_stage_flair_training_GDP_error_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2b17a5518b049cab4e169387adf8713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd169a6c516d45079cec2ab0f4053888",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf9d6f3bf61d4e59985a49448718cb36",
              "IPY_MODEL_aaeac2af69484505baa84df9b3555280"
            ]
          }
        },
        "fd169a6c516d45079cec2ab0f4053888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf9d6f3bf61d4e59985a49448718cb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eafef99977544198a9e1c79286b9d37c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c98b6aea9d1428fa7ace547e92b7be8"
          }
        },
        "aaeac2af69484505baa84df9b3555280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_089c2b5fd530483696fb9db72229ad4c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 256kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7a01f8f103e4ccd959dfecd2502618d"
          }
        },
        "eafef99977544198a9e1c79286b9d37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c98b6aea9d1428fa7ace547e92b7be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "089c2b5fd530483696fb9db72229ad4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7a01f8f103e4ccd959dfecd2502618d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b758c33f090141d1b4afc6c366845205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a24cec165c6442bbaaad69b532255461",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20241c8b867942dc839860e8efd64eab",
              "IPY_MODEL_2c70bdce65454187a04bcce65d612454"
            ]
          }
        },
        "a24cec165c6442bbaaad69b532255461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20241c8b867942dc839860e8efd64eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e05438db216484da6e46bfd08836949",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46eced55c8ea4c2bab4d3f5929671314"
          }
        },
        "2c70bdce65454187a04bcce65d612454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6403132cb4c64351b4e793794f497ecc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:06&lt;00:00, 69.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d44c7d5149742b680b39c16bfe736f1"
          }
        },
        "5e05438db216484da6e46bfd08836949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46eced55c8ea4c2bab4d3f5929671314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6403132cb4c64351b4e793794f497ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d44c7d5149742b680b39c16bfe736f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2e784946b274fbdbd29db7818d2d3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83df17baa5f34301bba90b6aa96726fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf3adce215f142d5acae072afa99b797",
              "IPY_MODEL_a3ba4e6a3b144c079a97f51982a8cab4"
            ]
          }
        },
        "83df17baa5f34301bba90b6aa96726fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf3adce215f142d5acae072afa99b797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17659ffb16164784a1a84a1bec74547a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdf21fb7eb6d42c292b78fec0cf217e1"
          }
        },
        "a3ba4e6a3b144c079a97f51982a8cab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6d769ed52ab4cf7818d231b83168608",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:05&lt;00:00, 75.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d22f9de2869c4c18a129884e75f3322f"
          }
        },
        "17659ffb16164784a1a84a1bec74547a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdf21fb7eb6d42c292b78fec0cf217e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6d769ed52ab4cf7818d231b83168608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d22f9de2869c4c18a129884e75f3322f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybjXa4UJ3g7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVY0ZiGk38i_",
        "colab_type": "code",
        "outputId": "825c0e49-30b7-4039-fae7-879047607361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-tq1hwq6j\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-tq1hwq6j\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2019.12.20)\n",
            "Collecting transformers>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.22.2.post1)\n",
            "Collecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/f9/9f2b6c672c8f8bb87a4c1bd52c1b57213627b035305aad745d015b2a62ae/pytest-5.4.2-py3-none-any.whl (247kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.5.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.6.0)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.8.7)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 53.7MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.5) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.8.1)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (8.3.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair==0.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair==0.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.5) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.10.0->flair==0.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.13.13)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.16.13)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.5-cp36-none-any.whl size=148939 sha256=f4f0e1fe34502abebcce3a48f0b4492203af043f12c892e38b29b2a057080173\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e59q__h5/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Building wheels for collected packages: segtok, langdetect, sqlitedict, mpld3, sacremoses\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=cf85f2cd26474792aec3fb0b87f20416b8e1df148aebd7bd2c87ba4387fe50ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=0cf8333a899eb723d423a659c01774556a8d23a250d4a9c202d702cece13db0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=b8d83b60e605ba86801f8df69f85df534aa3d3ac9d59ec9666517f3ca80c1746\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=ee9a310102a4f04090f41eb0c96df0f4c398790710b2bbddaffa88e19a7e6136\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=383df9fa341b8c1d9bfc786e02786361274240893cf8d3791198c81b1b393a11\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built segtok langdetect sqlitedict mpld3 sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers, pluggy, pytest, segtok, deprecated, langdetect, bpemb, sqlitedict, mpld3, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.2 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0 tokenizers-0.7.0 transformers-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP7gl75D39dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "from flair.data import Corpus\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfpsjw8I4Si-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBdZ1L34XwO",
        "colab_type": "code",
        "outputId": "51f1aa72-4280-4b62-be81-3671f474abc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U90p69Xd5KIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_folder = \"./drive/My Drive/capstone/data/\"\n",
        "data_folder = \"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkUisuXz7tuK",
        "colab_type": "text"
      },
      "source": [
        "### First Stage (Train on benchmark dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-_Bmpa6gn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = pd.read_csv(data_folder + \"combined_benchmark.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVaSsyAn72AU",
        "colab_type": "code",
        "outputId": "aeadb323-a52f-4e41-b7df-53ebc770cd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "benchmark = benchmark[['label', 'text']]\n",
        "benchmark.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Why not subscribe to the magazine ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>Tornio Works employs 2,300 of whom more than 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>The move is aimed at boosting sales , cost-eff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>As a result of the merger , the largest profes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>18 March 2010 A leakage in the gypsum pond was...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0                Why not subscribe to the magazine ?\n",
              "1     -1  Tornio Works employs 2,300 of whom more than 1...\n",
              "2      1  The move is aimed at boosting sales , cost-eff...\n",
              "3      0  As a result of the merger , the largest profes...\n",
              "4     -1  18 March 2010 A leakage in the gypsum pond was..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_MVMXq8pvf",
        "colab_type": "text"
      },
      "source": [
        "#### Create train, dev and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUbbfcSC8ekr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = benchmark.sample(frac=1)\n",
        "benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', sep='\\t', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', sep='\\t', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', sep='\\t', index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjNxI9oDHFlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "90345aff-e800-4002-b182-636ed727e3a0"
      },
      "source": [
        "benchmark.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>0</td>\n",
              "      <td>At the moment , there are approximately 20 Via...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0</td>\n",
              "      <td>Among other industrial stocks , Metso added 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>-1</td>\n",
              "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>0</td>\n",
              "      <td>Sami Sepp+Ænen , CEO for Elisa Eesti , says th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1034</th>\n",
              "      <td>-1</td>\n",
              "      <td>Tesla settles in cash $920 million convertible...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text\n",
              "163       0  At the moment , there are approximately 20 Via...\n",
              "109       0  Among other industrial stocks , Metso added 0....\n",
              "252      -1  Net sales of the Paper segment decreased to EU...\n",
              "844       0  Sami Sepp+Ænen , CEO for Elisa Eesti , says th...\n",
              "1034     -1  Tesla settles in cash $920 million convertible..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U8LTIJ-H2fM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', index = False, header = False)\n",
        "# benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', index = False, header = False)\n",
        "# benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a91JSI9nI1Z-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "589efb20-3a3a-4b32-e9c7-49cc0306e34d"
      },
      "source": [
        "pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/dev.csv\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>- Cash flow from operating activities before investments was EUR 0.8 -1.2 million .</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Complex Mega-Companies Dominate South Korea's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>Dealers said the share was largely hit by inve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Industrial stocks: A big bet on economic growt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>Operating profit , excluding non-recurring ite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Net sales rose by 25.5 % year-on-year to EUR59...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>-1</td>\n",
              "      <td>Finnish Scanfil , a systems supplier and contr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>0</td>\n",
              "      <td>The repurchase of the bonds was executed in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1</td>\n",
              "      <td>Kosovo's Economy Still Struggling Five Years A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>-1</td>\n",
              "      <td>Will the Internet Destroy the Stock Market?. T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>1</td>\n",
              "      <td>The new agreement , which expands a long-estab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0 - Cash flow from operating activities before investments was EUR 0.8 -1.2 million .\n",
              "0    1  Complex Mega-Companies Dominate South Korea's ...                                 \n",
              "1   -1  Dealers said the share was largely hit by inve...                                 \n",
              "2    1  Industrial stocks: A big bet on economic growt...                                 \n",
              "3   -1  Operating profit , excluding non-recurring ite...                                 \n",
              "4    1  Net sales rose by 25.5 % year-on-year to EUR59...                                 \n",
              "..  ..                                                ...                                 \n",
              "141 -1  Finnish Scanfil , a systems supplier and contr...                                 \n",
              "142  0  The repurchase of the bonds was executed in th...                                 \n",
              "143  1  Kosovo's Economy Still Struggling Five Years A...                                 \n",
              "144 -1  Will the Internet Destroy the Stock Market?. T...                                 \n",
              "145  1  The new agreement , which expands a long-estab...                                 \n",
              "\n",
              "[146 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7QE3IS69txr",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz-2gNy58wDI",
        "colab_type": "code",
        "outputId": "fdb2f6f2-f3bd-481b-f763-14ee86c04087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "#corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_folder), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
        "column_name_map = {1: \"text\", 0: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                         column_name_map,\n",
        "                                         skip_header=False, #no header in kaggle data\n",
        "                                         delimiter='\\t',    # comma separated rows\n",
        "                                         train_file='train.csv', ## passing in file names manuelly when it can't auto detect\n",
        "                                         dev_file='dev.csv',\n",
        "                                         test_file='test.csv'\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-25 23:35:21,378 Reading data from /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training\n",
            "2020-05-25 23:35:21,385 Train: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/train.csv\n",
            "2020-05-25 23:35:21,387 Dev: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/dev.csv\n",
            "2020-05-25 23:35:21,388 Test: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCgaVpvzHSB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb1lynSQ98-z",
        "colab_type": "text"
      },
      "source": [
        "#### Create word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u9PFUze9_5y",
        "colab_type": "code",
        "outputId": "fc3d160c-d61d-43e4-94be-079f9b88b489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "e2b17a5518b049cab4e169387adf8713",
            "fd169a6c516d45079cec2ab0f4053888",
            "bf9d6f3bf61d4e59985a49448718cb36",
            "aaeac2af69484505baa84df9b3555280",
            "eafef99977544198a9e1c79286b9d37c",
            "2c98b6aea9d1428fa7ace547e92b7be8",
            "089c2b5fd530483696fb9db72229ad4c",
            "f7a01f8f103e4ccd959dfecd2502618d",
            "b758c33f090141d1b4afc6c366845205",
            "a24cec165c6442bbaaad69b532255461",
            "20241c8b867942dc839860e8efd64eab",
            "2c70bdce65454187a04bcce65d612454",
            "5e05438db216484da6e46bfd08836949",
            "46eced55c8ea4c2bab4d3f5929671314",
            "6403132cb4c64351b4e793794f497ecc",
            "8d44c7d5149742b680b39c16bfe736f1",
            "f2e784946b274fbdbd29db7818d2d3c5",
            "83df17baa5f34301bba90b6aa96726fa",
            "bf3adce215f142d5acae072afa99b797",
            "a3ba4e6a3b144c079a97f51982a8cab4",
            "17659ffb16164784a1a84a1bec74547a",
            "cdf21fb7eb6d42c292b78fec0cf217e1",
            "c6d769ed52ab4cf7818d231b83168608",
            "d22f9de2869c4c18a129884e75f3322f"
          ]
        }
      },
      "source": [
        "word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
        "\n",
        "# word_embeddings = [BertEmbeddings()]\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2b17a5518b049cab4e169387adf8713",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b758c33f090141d1b4afc6c366845205",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e784946b274fbdbd29db7818d2d3c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2020-05-25 23:21:12,931 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpxc7o3pm5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:04<00:00, 4773033.95B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-25 23:21:18,268 copying /tmp/tmpxc7o3pm5 to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2020-05-25 23:21:18,291 removing temp file /tmp/tmpxc7o3pm5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-25 23:21:36,154 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpo8i3uz3h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:04<00:00, 4711701.54B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-25 23:21:41,570 copying /tmp/tmpo8i3uz3h to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2020-05-25 23:21:41,593 removing temp file /tmp/tmpo8i3uz3h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HovCqFfSMjmJ",
        "colab_type": "text"
      },
      "source": [
        "#### First Stage Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wik8DDxm-DKy",
        "colab_type": "code",
        "outputId": "40902d80-bd5d-4061-a4bd-5bcd26a58f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train(data_folder, max_epochs=10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-25 23:35:34,627 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "100%|██████████| 1314/1314 [00:01<00:00, 1196.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-25 23:35:35,971 [b'0', b'-1', b'1']\n",
            "2020-05-25 23:35:35,985 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-25 23:35:35,992 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-25 23:35:35,998 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:35:36,002 Corpus: \"Corpus: 1168 train + 147 dev + 146 test sentences\"\n",
            "2020-05-25 23:35:36,005 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:35:36,008 Parameters:\n",
            "2020-05-25 23:35:36,010  - learning_rate: \"0.1\"\n",
            "2020-05-25 23:35:36,013  - mini_batch_size: \"32\"\n",
            "2020-05-25 23:35:36,019  - patience: \"3\"\n",
            "2020-05-25 23:35:36,021  - anneal_factor: \"0.5\"\n",
            "2020-05-25 23:35:36,023  - max_epochs: \"10\"\n",
            "2020-05-25 23:35:36,025  - shuffle: \"True\"\n",
            "2020-05-25 23:35:36,027  - train_with_dev: \"False\"\n",
            "2020-05-25 23:35:36,032  - batch_growth_annealing: \"False\"\n",
            "2020-05-25 23:35:36,036 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:35:36,038 Model training base path: \"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training\"\n",
            "2020-05-25 23:35:36,040 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:35:36,042 Device: cuda:0\n",
            "2020-05-25 23:35:36,044 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:35:36,046 Embeddings storage mode: cpu\n",
            "2020-05-25 23:35:36,057 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:35:38,502 epoch 1 - iter 3/37 - loss 1.36171524 - samples/sec: 44.76\n",
            "2020-05-25 23:35:51,565 epoch 1 - iter 6/37 - loss 1.28935059 - samples/sec: 49.81\n",
            "2020-05-25 23:36:03,993 epoch 1 - iter 9/37 - loss 1.22306042 - samples/sec: 60.41\n",
            "2020-05-25 23:36:16,620 epoch 1 - iter 12/37 - loss 1.17488136 - samples/sec: 62.67\n",
            "2020-05-25 23:36:29,659 epoch 1 - iter 15/37 - loss 1.20824669 - samples/sec: 59.39\n",
            "2020-05-25 23:36:42,591 epoch 1 - iter 18/37 - loss 1.20572050 - samples/sec: 53.13\n",
            "2020-05-25 23:36:55,512 epoch 1 - iter 21/37 - loss 1.18405629 - samples/sec: 55.11\n",
            "2020-05-25 23:37:10,468 epoch 1 - iter 24/37 - loss 1.18934056 - samples/sec: 59.71\n",
            "2020-05-25 23:37:23,363 epoch 1 - iter 27/37 - loss 1.17818738 - samples/sec: 58.77\n",
            "2020-05-25 23:37:36,686 epoch 1 - iter 30/37 - loss 1.17295639 - samples/sec: 56.19\n",
            "2020-05-25 23:37:49,448 epoch 1 - iter 33/37 - loss 1.14850820 - samples/sec: 62.14\n",
            "2020-05-25 23:38:02,146 epoch 1 - iter 36/37 - loss 1.12207616 - samples/sec: 61.18\n",
            "2020-05-25 23:38:13,696 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:38:13,702 EPOCH 1 done: loss 1.1206 - lr 0.1000000\n",
            "2020-05-25 23:38:16,748 DEV : loss 1.1823023557662964 - score 0.6689\n",
            "2020-05-25 23:38:16,892 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-25 23:38:18,796 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:38:20,867 epoch 2 - iter 3/37 - loss 1.16594394 - samples/sec: 53.33\n",
            "2020-05-25 23:38:34,681 epoch 2 - iter 6/37 - loss 0.92232124 - samples/sec: 61.60\n",
            "2020-05-25 23:38:47,705 epoch 2 - iter 9/37 - loss 0.93124416 - samples/sec: 56.35\n",
            "2020-05-25 23:39:00,256 epoch 2 - iter 12/37 - loss 0.94735250 - samples/sec: 58.84\n",
            "2020-05-25 23:39:13,096 epoch 2 - iter 15/37 - loss 0.92387487 - samples/sec: 65.71\n",
            "2020-05-25 23:39:25,904 epoch 2 - iter 18/37 - loss 0.95010928 - samples/sec: 53.71\n",
            "2020-05-25 23:39:38,656 epoch 2 - iter 21/37 - loss 0.92285477 - samples/sec: 56.45\n",
            "2020-05-25 23:39:51,272 epoch 2 - iter 24/37 - loss 0.89250467 - samples/sec: 56.89\n",
            "2020-05-25 23:40:03,889 epoch 2 - iter 27/37 - loss 0.87958208 - samples/sec: 62.22\n",
            "2020-05-25 23:40:16,429 epoch 2 - iter 30/37 - loss 0.89169100 - samples/sec: 55.80\n",
            "2020-05-25 23:40:28,919 epoch 2 - iter 33/37 - loss 0.88890937 - samples/sec: 57.75\n",
            "2020-05-25 23:40:41,660 epoch 2 - iter 36/37 - loss 0.90019929 - samples/sec: 56.06\n",
            "2020-05-25 23:40:53,521 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:40:53,526 EPOCH 2 done: loss 0.8993 - lr 0.1000000\n",
            "2020-05-25 23:40:56,581 DEV : loss 0.8175520300865173 - score 0.7415\n",
            "2020-05-25 23:40:56,920 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-25 23:40:58,930 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:41:01,241 epoch 3 - iter 3/37 - loss 0.71284646 - samples/sec: 49.17\n",
            "2020-05-25 23:41:14,918 epoch 3 - iter 6/37 - loss 0.80091997 - samples/sec: 58.23\n",
            "2020-05-25 23:41:27,771 epoch 3 - iter 9/37 - loss 0.79970966 - samples/sec: 62.42\n",
            "2020-05-25 23:41:40,562 epoch 3 - iter 12/37 - loss 0.89888872 - samples/sec: 54.29\n",
            "2020-05-25 23:41:53,195 epoch 3 - iter 15/37 - loss 0.87620972 - samples/sec: 59.00\n",
            "2020-05-25 23:42:05,609 epoch 3 - iter 18/37 - loss 0.83533796 - samples/sec: 56.75\n",
            "2020-05-25 23:42:19,627 epoch 3 - iter 21/37 - loss 0.82325606 - samples/sec: 57.09\n",
            "2020-05-25 23:42:31,958 epoch 3 - iter 24/37 - loss 0.82855570 - samples/sec: 59.82\n",
            "2020-05-25 23:42:44,572 epoch 3 - iter 27/37 - loss 0.83006151 - samples/sec: 54.03\n",
            "2020-05-25 23:42:57,698 epoch 3 - iter 30/37 - loss 0.81621499 - samples/sec: 57.28\n",
            "2020-05-25 23:43:10,401 epoch 3 - iter 33/37 - loss 0.80916172 - samples/sec: 60.87\n",
            "2020-05-25 23:43:22,719 epoch 3 - iter 36/37 - loss 0.81220875 - samples/sec: 60.82\n",
            "2020-05-25 23:43:34,281 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:43:34,286 EPOCH 3 done: loss 0.8086 - lr 0.1000000\n",
            "2020-05-25 23:43:37,484 DEV : loss 0.7285744547843933 - score 0.7732\n",
            "2020-05-25 23:43:37,620 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-25 23:43:39,563 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:43:41,627 epoch 4 - iter 3/37 - loss 0.74493611 - samples/sec: 54.97\n",
            "2020-05-25 23:43:55,253 epoch 4 - iter 6/37 - loss 0.67428226 - samples/sec: 55.61\n",
            "2020-05-25 23:44:08,216 epoch 4 - iter 9/37 - loss 0.69862054 - samples/sec: 52.73\n",
            "2020-05-25 23:44:21,172 epoch 4 - iter 12/37 - loss 0.71747190 - samples/sec: 55.98\n",
            "2020-05-25 23:44:34,094 epoch 4 - iter 15/37 - loss 0.74125898 - samples/sec: 57.20\n",
            "2020-05-25 23:44:46,754 epoch 4 - iter 18/37 - loss 0.72555959 - samples/sec: 59.83\n",
            "2020-05-25 23:44:59,694 epoch 4 - iter 21/37 - loss 0.73681991 - samples/sec: 55.73\n",
            "2020-05-25 23:45:12,441 epoch 4 - iter 24/37 - loss 0.77799178 - samples/sec: 59.08\n",
            "2020-05-25 23:45:24,897 epoch 4 - iter 27/37 - loss 0.76920718 - samples/sec: 62.17\n",
            "2020-05-25 23:45:37,737 epoch 4 - iter 30/37 - loss 0.75405204 - samples/sec: 60.78\n",
            "2020-05-25 23:45:50,245 epoch 4 - iter 33/37 - loss 0.74807194 - samples/sec: 61.33\n",
            "2020-05-25 23:46:03,210 epoch 4 - iter 36/37 - loss 0.74338530 - samples/sec: 54.60\n",
            "2020-05-25 23:46:14,705 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:46:14,706 EPOCH 4 done: loss 0.7352 - lr 0.1000000\n",
            "2020-05-25 23:46:17,686 DEV : loss 0.8591181039810181 - score 0.7642\n",
            "2020-05-25 23:46:17,822 BAD EPOCHS (no improvement): 1\n",
            "2020-05-25 23:46:17,828 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:46:20,064 epoch 5 - iter 3/37 - loss 0.75364872 - samples/sec: 51.10\n",
            "2020-05-25 23:46:32,812 epoch 5 - iter 6/37 - loss 0.70255929 - samples/sec: 58.81\n",
            "2020-05-25 23:46:45,377 epoch 5 - iter 9/37 - loss 0.77410267 - samples/sec: 58.39\n",
            "2020-05-25 23:46:57,940 epoch 5 - iter 12/37 - loss 0.75195116 - samples/sec: 62.73\n",
            "2020-05-25 23:47:10,142 epoch 5 - iter 15/37 - loss 0.78353564 - samples/sec: 57.42\n",
            "2020-05-25 23:47:23,973 epoch 5 - iter 18/37 - loss 0.76067534 - samples/sec: 53.58\n",
            "2020-05-25 23:47:37,385 epoch 5 - iter 21/37 - loss 0.75219296 - samples/sec: 56.44\n",
            "2020-05-25 23:47:49,964 epoch 5 - iter 24/37 - loss 0.74039573 - samples/sec: 58.00\n",
            "2020-05-25 23:48:02,946 epoch 5 - iter 27/37 - loss 0.74992917 - samples/sec: 57.75\n",
            "2020-05-25 23:48:15,697 epoch 5 - iter 30/37 - loss 0.77392703 - samples/sec: 55.26\n",
            "2020-05-25 23:48:28,483 epoch 5 - iter 33/37 - loss 0.74766081 - samples/sec: 59.53\n",
            "2020-05-25 23:48:40,973 epoch 5 - iter 36/37 - loss 0.75329077 - samples/sec: 61.37\n",
            "2020-05-25 23:48:52,783 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:48:52,789 EPOCH 5 done: loss 0.7516 - lr 0.1000000\n",
            "2020-05-25 23:48:55,830 DEV : loss 0.8208729028701782 - score 0.7551\n",
            "2020-05-25 23:48:56,173 BAD EPOCHS (no improvement): 2\n",
            "2020-05-25 23:48:56,184 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:48:58,193 epoch 6 - iter 3/37 - loss 0.62103728 - samples/sec: 55.51\n",
            "2020-05-25 23:49:10,764 epoch 6 - iter 6/37 - loss 0.70354287 - samples/sec: 53.12\n",
            "2020-05-25 23:49:23,781 epoch 6 - iter 9/37 - loss 0.63589489 - samples/sec: 58.61\n",
            "2020-05-25 23:49:37,177 epoch 6 - iter 12/37 - loss 0.65721260 - samples/sec: 55.57\n",
            "2020-05-25 23:49:49,610 epoch 6 - iter 15/37 - loss 0.65885122 - samples/sec: 56.17\n",
            "2020-05-25 23:50:02,206 epoch 6 - iter 18/37 - loss 0.68022750 - samples/sec: 58.64\n",
            "2020-05-25 23:50:15,100 epoch 6 - iter 21/37 - loss 0.71189883 - samples/sec: 56.92\n",
            "2020-05-25 23:50:27,963 epoch 6 - iter 24/37 - loss 0.69742622 - samples/sec: 59.80\n",
            "2020-05-25 23:50:40,866 epoch 6 - iter 27/37 - loss 0.68881707 - samples/sec: 60.23\n",
            "2020-05-25 23:50:53,505 epoch 6 - iter 30/37 - loss 0.68022618 - samples/sec: 56.61\n",
            "2020-05-25 23:51:05,894 epoch 6 - iter 33/37 - loss 0.67303746 - samples/sec: 57.84\n",
            "2020-05-25 23:51:19,117 epoch 6 - iter 36/37 - loss 0.68698044 - samples/sec: 57.84\n",
            "2020-05-25 23:51:30,807 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:51:30,809 EPOCH 6 done: loss 0.6912 - lr 0.1000000\n",
            "2020-05-25 23:51:33,830 DEV : loss 0.9078011512756348 - score 0.7098\n",
            "2020-05-25 23:51:33,969 BAD EPOCHS (no improvement): 3\n",
            "2020-05-25 23:51:33,974 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:51:36,186 epoch 7 - iter 3/37 - loss 0.59313581 - samples/sec: 50.27\n",
            "2020-05-25 23:51:49,049 epoch 7 - iter 6/37 - loss 0.57595274 - samples/sec: 57.57\n",
            "2020-05-25 23:52:01,743 epoch 7 - iter 9/37 - loss 0.53736328 - samples/sec: 58.75\n",
            "2020-05-25 23:52:14,363 epoch 7 - iter 12/37 - loss 0.51507434 - samples/sec: 57.64\n",
            "2020-05-25 23:52:26,934 epoch 7 - iter 15/37 - loss 0.53815504 - samples/sec: 59.33\n",
            "2020-05-25 23:52:41,006 epoch 7 - iter 18/37 - loss 0.60881628 - samples/sec: 55.01\n",
            "2020-05-25 23:52:53,758 epoch 7 - iter 21/37 - loss 0.60333137 - samples/sec: 56.36\n",
            "2020-05-25 23:53:07,195 epoch 7 - iter 24/37 - loss 0.62009123 - samples/sec: 60.86\n",
            "2020-05-25 23:53:19,883 epoch 7 - iter 27/37 - loss 0.62784821 - samples/sec: 58.72\n",
            "2020-05-25 23:53:32,454 epoch 7 - iter 30/37 - loss 0.62829026 - samples/sec: 58.66\n",
            "2020-05-25 23:53:45,305 epoch 7 - iter 33/37 - loss 0.63970146 - samples/sec: 61.92\n",
            "2020-05-25 23:53:58,153 epoch 7 - iter 36/37 - loss 0.63753951 - samples/sec: 58.59\n",
            "2020-05-25 23:54:09,723 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:54:09,727 EPOCH 7 done: loss 0.6461 - lr 0.1000000\n",
            "2020-05-25 23:54:12,805 DEV : loss 1.0128289461135864 - score 0.7596\n",
            "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-05-25 23:54:12,939 BAD EPOCHS (no improvement): 4\n",
            "2020-05-25 23:54:12,943 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:54:15,145 epoch 8 - iter 3/37 - loss 0.59519177 - samples/sec: 57.78\n",
            "2020-05-25 23:54:27,965 epoch 8 - iter 6/37 - loss 0.56146221 - samples/sec: 57.06\n",
            "2020-05-25 23:54:40,873 epoch 8 - iter 9/37 - loss 0.53251822 - samples/sec: 56.91\n",
            "2020-05-25 23:54:53,598 epoch 8 - iter 12/37 - loss 0.52144061 - samples/sec: 57.27\n",
            "2020-05-25 23:55:06,290 epoch 8 - iter 15/37 - loss 0.50676822 - samples/sec: 54.86\n",
            "2020-05-25 23:55:18,947 epoch 8 - iter 18/37 - loss 0.49570993 - samples/sec: 59.62\n",
            "2020-05-25 23:55:31,759 epoch 8 - iter 21/37 - loss 0.49487308 - samples/sec: 61.34\n",
            "2020-05-25 23:55:44,495 epoch 8 - iter 24/37 - loss 0.49211373 - samples/sec: 55.93\n",
            "2020-05-25 23:55:57,075 epoch 8 - iter 27/37 - loss 0.48394323 - samples/sec: 59.73\n",
            "2020-05-25 23:56:10,121 epoch 8 - iter 30/37 - loss 0.48709289 - samples/sec: 58.19\n",
            "2020-05-25 23:56:22,695 epoch 8 - iter 33/37 - loss 0.48917871 - samples/sec: 61.73\n",
            "2020-05-25 23:56:35,264 epoch 8 - iter 36/37 - loss 0.48860286 - samples/sec: 58.14\n",
            "2020-05-25 23:56:46,781 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:56:46,786 EPOCH 8 done: loss 0.4887 - lr 0.0500000\n",
            "2020-05-25 23:56:49,761 DEV : loss 0.8733577728271484 - score 0.7823\n",
            "2020-05-25 23:56:49,894 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-25 23:56:51,999 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:56:53,948 epoch 9 - iter 3/37 - loss 0.55272586 - samples/sec: 60.78\n",
            "2020-05-25 23:57:08,217 epoch 9 - iter 6/37 - loss 0.51839646 - samples/sec: 55.81\n",
            "2020-05-25 23:57:20,763 epoch 9 - iter 9/37 - loss 0.50139145 - samples/sec: 60.20\n",
            "2020-05-25 23:57:33,452 epoch 9 - iter 12/37 - loss 0.52351913 - samples/sec: 52.04\n",
            "2020-05-25 23:57:48,719 epoch 9 - iter 15/37 - loss 0.50962270 - samples/sec: 56.17\n",
            "2020-05-25 23:58:01,323 epoch 9 - iter 18/37 - loss 0.52380215 - samples/sec: 62.09\n",
            "2020-05-25 23:58:14,433 epoch 9 - iter 21/37 - loss 0.50611382 - samples/sec: 56.57\n",
            "2020-05-25 23:58:26,883 epoch 9 - iter 24/37 - loss 0.50356797 - samples/sec: 63.37\n",
            "2020-05-25 23:58:39,490 epoch 9 - iter 27/37 - loss 0.49163638 - samples/sec: 54.53\n",
            "2020-05-25 23:58:52,215 epoch 9 - iter 30/37 - loss 0.48599266 - samples/sec: 54.08\n",
            "2020-05-25 23:59:05,219 epoch 9 - iter 33/37 - loss 0.48071994 - samples/sec: 56.71\n",
            "2020-05-25 23:59:18,121 epoch 9 - iter 36/37 - loss 0.46729152 - samples/sec: 60.54\n",
            "2020-05-25 23:59:29,656 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:59:29,662 EPOCH 9 done: loss 0.4667 - lr 0.0500000\n",
            "2020-05-25 23:59:32,819 DEV : loss 0.8282421231269836 - score 0.7778\n",
            "2020-05-25 23:59:32,959 BAD EPOCHS (no improvement): 1\n",
            "2020-05-25 23:59:32,965 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-25 23:59:35,109 epoch 10 - iter 3/37 - loss 0.42749175 - samples/sec: 52.69\n",
            "2020-05-25 23:59:47,482 epoch 10 - iter 6/37 - loss 0.41712197 - samples/sec: 59.86\n",
            "2020-05-26 00:00:00,956 epoch 10 - iter 9/37 - loss 0.42737157 - samples/sec: 57.18\n",
            "2020-05-26 00:00:13,596 epoch 10 - iter 12/37 - loss 0.46586875 - samples/sec: 56.44\n",
            "2020-05-26 00:00:26,468 epoch 10 - iter 15/37 - loss 0.44738035 - samples/sec: 55.36\n",
            "2020-05-26 00:00:39,269 epoch 10 - iter 18/37 - loss 0.46308542 - samples/sec: 58.22\n",
            "2020-05-26 00:00:52,210 epoch 10 - iter 21/37 - loss 0.47228163 - samples/sec: 59.85\n",
            "2020-05-26 00:01:05,180 epoch 10 - iter 24/37 - loss 0.48663432 - samples/sec: 61.83\n",
            "2020-05-26 00:01:18,054 epoch 10 - iter 27/37 - loss 0.48788813 - samples/sec: 59.52\n",
            "2020-05-26 00:01:30,693 epoch 10 - iter 30/37 - loss 0.47319345 - samples/sec: 60.99\n",
            "2020-05-26 00:01:43,454 epoch 10 - iter 33/37 - loss 0.48750629 - samples/sec: 55.48\n",
            "2020-05-26 00:01:56,395 epoch 10 - iter 36/37 - loss 0.50268737 - samples/sec: 59.22\n",
            "2020-05-26 00:02:08,042 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:02:08,048 EPOCH 10 done: loss 0.5006 - lr 0.0500000\n",
            "2020-05-26 00:02:11,105 DEV : loss 0.8999382257461548 - score 0.7914\n",
            "2020-05-26 00:02:11,242 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 00:02:15,191 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:02:15,196 Testing using best model ...\n",
            "2020-05-26 00:02:15,204 loading file /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/best-model.pt\n",
            "2020-05-26 00:02:19,853 0.589041095890411\t0.589041095890411\t0.589041095890411\n",
            "2020-05-26 00:02:19,860 \n",
            "MICRO_AVG: acc 0.726027397260274 - f1-score 0.589041095890411\n",
            "MACRO_AVG: acc 0.7260273972602739 - f1-score 0.5739219483960016\n",
            "-1         tp: 30 - fp: 24 - fn: 9 - tn: 83 - precision: 0.5556 - recall: 0.7692 - accuracy: 0.7740 - f1-score: 0.6452\n",
            "0          tp: 40 - fp: 27 - fn: 8 - tn: 71 - precision: 0.5970 - recall: 0.8333 - accuracy: 0.7603 - f1-score: 0.6957\n",
            "1          tp: 16 - fp: 9 - fn: 43 - tn: 78 - precision: 0.6400 - recall: 0.2712 - accuracy: 0.6438 - f1-score: 0.3810\n",
            "2020-05-26 00:02:19,863 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [1.1823023557662964,\n",
              "  0.8175520300865173,\n",
              "  0.7285744547843933,\n",
              "  0.8591181039810181,\n",
              "  0.8208729028701782,\n",
              "  0.9078011512756348,\n",
              "  1.0128289461135864,\n",
              "  0.8733577728271484,\n",
              "  0.8282421231269836,\n",
              "  0.8999382257461548],\n",
              " 'dev_score_history': [0.6689342403628118,\n",
              "  0.7414965986394558,\n",
              "  0.7732426303854876,\n",
              "  0.764172335600907,\n",
              "  0.7551020408163265,\n",
              "  0.7097505668934241,\n",
              "  0.7596371882086168,\n",
              "  0.782312925170068,\n",
              "  0.7777777777777778,\n",
              "  0.7913832199546486],\n",
              " 'test_score': 0.726027397260274,\n",
              " 'train_loss_history': [1.1205680032034178,\n",
              "  0.899281778851071,\n",
              "  0.8085721360670554,\n",
              "  0.7352465584471419,\n",
              "  0.7515609385194005,\n",
              "  0.6912054330916018,\n",
              "  0.6460504217727764,\n",
              "  0.48869013544675466,\n",
              "  0.4667409747033506,\n",
              "  0.5006147099507822]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2JikhOEZFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1586299c-52db-45d4-9b85-5ceccc69f6d1"
      },
      "source": [
        "from flair.data import Sentence\n",
        "# create example sentence\n",
        "sentence = Sentence(\"Canada's growth weakens as investment drops, consumers fade\")\n",
        "\n",
        "# predict class and print\n",
        "classifier.predict(sentence)\n",
        "\n",
        "print(sentence.labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1 (0.9964)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwSElzt2Qkai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cd2f683-f170-4870-fc56-df1b72b8d29d"
      },
      "source": [
        "#  access the Sentence objects in each split directly\n",
        "print(corpus.test[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"Profit before taxes was EUR 5.4 mn , up from EUR 3.6 mn a year earlier .\"   [− Tokens: 17  − Sentence-Labels: {'class': [1 (1.0)]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIrjzZOQQn2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fb1c996d-7b0c-4154-f96e-b8114e411f10"
      },
      "source": [
        "print(corpus.train[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"At the moment , there are approximately 20 Vianor sales offices in Russia .\"   [− Tokens: 14  − Sentence-Labels: {'class': [0 (1.0)]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lWLmyn0RTwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "b38c0a3c-6023-4344-912f-ee5dc3fd70b7"
      },
      "source": [
        "#outputs detailed information on the dataset, each split, and the distribution of class labels.\n",
        "stats = corpus.obtain_statistics()\n",
        "print(stats)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"TRAIN\": {\n",
            "        \"dataset\": \"TRAIN\",\n",
            "        \"total_number_of_documents\": 1168,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"0\": 389,\n",
            "            \"-1\": 399,\n",
            "            \"1\": 380\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 36665,\n",
            "            \"min\": 4,\n",
            "            \"max\": 68,\n",
            "            \"avg\": 31.391267123287673\n",
            "        }\n",
            "    },\n",
            "    \"TEST\": {\n",
            "        \"dataset\": \"TEST\",\n",
            "        \"total_number_of_documents\": 146,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"1\": 59,\n",
            "            \"0\": 48,\n",
            "            \"-1\": 39\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 4522,\n",
            "            \"min\": 8,\n",
            "            \"max\": 69,\n",
            "            \"avg\": 30.972602739726028\n",
            "        }\n",
            "    },\n",
            "    \"DEV\": {\n",
            "        \"dataset\": \"DEV\",\n",
            "        \"total_number_of_documents\": 147,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"-1\": 56,\n",
            "            \"1\": 46,\n",
            "            \"0\": 45\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 4956,\n",
            "            \"min\": 7,\n",
            "            \"max\": 67,\n",
            "            \"avg\": 33.714285714285715\n",
            "        }\n",
            "    }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5maM-7gQWqJ",
        "colab_type": "text"
      },
      "source": [
        "### Second Stage (train on hand annotated datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbrXhSRlnCR3",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0E6iEy9UgYP",
        "colab_type": "code",
        "outputId": "1cd081d6-527c-42fd-cc09-9694ff8ecce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#new_data_folder = './drive/My Drive/capstone/data/second_stage/'\n",
        "new_data_folder = '/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/'\n",
        "new_column_name_map = {5: \"text\", 4: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(new_data_folder,\n",
        "                                         new_column_name_map,\n",
        "                                         skip_header=True, #no header in kaggle data\n",
        "                                         delimiter=',',    # comma separated rows\n",
        "                                         train_file='GDP_train_df_oversampled.csv',\n",
        "                                         dev_file = 'GDP_eva_df_oversampled.csv',\n",
        "                                         test_file = 'GDP_eva_df_oversampled.csv'\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 00:09:22,214 Reading data from /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled\n",
            "2020-05-26 00:09:22,216 Train: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/GDP_train_df_oversampled.csv\n",
            "2020-05-26 00:09:22,218 Dev: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/GDP_eva_df_oversampled.csv\n",
            "2020-05-26 00:09:22,220 Test: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/GDP_eva_df_oversampled.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGDir71nHb6",
        "colab_type": "text"
      },
      "source": [
        "#### Second Stage fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWg4fjqNYMKa",
        "colab_type": "code",
        "outputId": "5764b152-eced-4a42-b241-6d08b685b713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# benchmark_embeddings = FlairEmbeddings(data_folder + 'best-model.pt')\n",
        "benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 00:09:30,492 loading file /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1XWYH6QZGl",
        "colab_type": "code",
        "outputId": "d256e944-6d27-4d14-ba9b-6c5823e60521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer = ModelTrainer(benchmark_classifier, corpus)\n",
        "trainer.train(new_data_folder, max_epochs=10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 00:09:35,817 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:09:35,822 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-26 00:09:35,824 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:09:35,826 Corpus: \"Corpus: 132 train + 33 dev + 33 test sentences\"\n",
            "2020-05-26 00:09:35,827 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:09:35,828 Parameters:\n",
            "2020-05-26 00:09:35,831  - learning_rate: \"0.1\"\n",
            "2020-05-26 00:09:35,833  - mini_batch_size: \"32\"\n",
            "2020-05-26 00:09:35,835  - patience: \"3\"\n",
            "2020-05-26 00:09:35,836  - anneal_factor: \"0.5\"\n",
            "2020-05-26 00:09:35,838  - max_epochs: \"10\"\n",
            "2020-05-26 00:09:35,840  - shuffle: \"True\"\n",
            "2020-05-26 00:09:35,842  - train_with_dev: \"False\"\n",
            "2020-05-26 00:09:35,843  - batch_growth_annealing: \"False\"\n",
            "2020-05-26 00:09:35,846 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:09:35,847 Model training base path: \"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled\"\n",
            "2020-05-26 00:09:35,849 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:09:35,851 Device: cuda:0\n",
            "2020-05-26 00:09:35,853 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:09:35,854 Embeddings storage mode: cpu\n",
            "2020-05-26 00:09:35,862 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:09:36,711 epoch 1 - iter 1/5 - loss 1.89299655 - samples/sec: 54.27\n",
            "2020-05-26 00:09:48,150 epoch 1 - iter 2/5 - loss 1.60034215 - samples/sec: 53.30\n",
            "2020-05-26 00:10:00,364 epoch 1 - iter 3/5 - loss 1.43790968 - samples/sec: 54.49\n",
            "2020-05-26 00:10:11,786 epoch 1 - iter 4/5 - loss 1.37371907 - samples/sec: 56.84\n",
            "2020-05-26 00:10:22,792 epoch 1 - iter 5/5 - loss 1.24847941 - samples/sec: 170.99\n",
            "2020-05-26 00:10:33,655 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:10:33,660 EPOCH 1 done: loss 1.2485 - lr 0.1000000\n",
            "2020-05-26 00:10:34,667 DEV : loss 0.676527202129364 - score 0.697\n",
            "2020-05-26 00:10:34,711 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 00:10:36,611 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:10:37,511 epoch 2 - iter 1/5 - loss 1.26200259 - samples/sec: 48.86\n",
            "2020-05-26 00:10:50,350 epoch 2 - iter 2/5 - loss 1.55057395 - samples/sec: 57.28\n",
            "2020-05-26 00:11:01,419 epoch 2 - iter 3/5 - loss 1.24787066 - samples/sec: 59.29\n",
            "2020-05-26 00:11:13,142 epoch 2 - iter 4/5 - loss 1.08912160 - samples/sec: 57.35\n",
            "2020-05-26 00:11:24,146 epoch 2 - iter 5/5 - loss 0.99385616 - samples/sec: 237.26\n",
            "2020-05-26 00:11:35,105 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:11:35,110 EPOCH 2 done: loss 0.9939 - lr 0.1000000\n",
            "2020-05-26 00:11:36,034 DEV : loss 0.9050557613372803 - score 0.7172\n",
            "2020-05-26 00:11:36,079 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 00:11:37,952 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:11:38,863 epoch 3 - iter 1/5 - loss 1.09196424 - samples/sec: 53.79\n",
            "2020-05-26 00:11:51,296 epoch 3 - iter 2/5 - loss 0.84660608 - samples/sec: 53.73\n",
            "2020-05-26 00:12:02,851 epoch 3 - iter 3/5 - loss 0.73547693 - samples/sec: 54.16\n",
            "2020-05-26 00:12:14,282 epoch 3 - iter 4/5 - loss 0.65045546 - samples/sec: 54.09\n",
            "2020-05-26 00:12:25,231 epoch 3 - iter 5/5 - loss 0.67823702 - samples/sec: 275.48\n",
            "2020-05-26 00:12:35,927 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:12:35,931 EPOCH 3 done: loss 0.6782 - lr 0.1000000\n",
            "2020-05-26 00:12:36,925 DEV : loss 0.3569127917289734 - score 0.7778\n",
            "2020-05-26 00:12:36,968 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 00:12:38,863 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:12:39,737 epoch 4 - iter 1/5 - loss 0.79693323 - samples/sec: 52.98\n",
            "2020-05-26 00:12:51,561 epoch 4 - iter 2/5 - loss 0.86934203 - samples/sec: 47.28\n",
            "2020-05-26 00:13:03,118 epoch 4 - iter 3/5 - loss 0.82124865 - samples/sec: 53.60\n",
            "2020-05-26 00:13:16,162 epoch 4 - iter 4/5 - loss 0.70458170 - samples/sec: 55.54\n",
            "2020-05-26 00:13:28,252 epoch 4 - iter 5/5 - loss 0.69853843 - samples/sec: 213.92\n",
            "2020-05-26 00:13:39,106 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:13:39,111 EPOCH 4 done: loss 0.6985 - lr 0.1000000\n",
            "2020-05-26 00:13:40,287 DEV : loss 0.48473626375198364 - score 0.7576\n",
            "2020-05-26 00:13:40,328 BAD EPOCHS (no improvement): 1\n",
            "2020-05-26 00:13:40,332 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:13:41,158 epoch 5 - iter 1/5 - loss 0.61155581 - samples/sec: 59.54\n",
            "2020-05-26 00:13:53,136 epoch 5 - iter 2/5 - loss 0.47965446 - samples/sec: 52.23\n",
            "2020-05-26 00:14:04,457 epoch 5 - iter 3/5 - loss 0.45875039 - samples/sec: 53.94\n",
            "2020-05-26 00:14:16,323 epoch 5 - iter 4/5 - loss 0.44243322 - samples/sec: 51.31\n",
            "2020-05-26 00:14:27,535 epoch 5 - iter 5/5 - loss 0.45320078 - samples/sec: 232.32\n",
            "2020-05-26 00:14:38,698 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:14:38,702 EPOCH 5 done: loss 0.4532 - lr 0.1000000\n",
            "2020-05-26 00:14:39,633 DEV : loss 0.9527653455734253 - score 0.6364\n",
            "2020-05-26 00:14:39,678 BAD EPOCHS (no improvement): 2\n",
            "2020-05-26 00:14:39,683 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:14:40,520 epoch 6 - iter 1/5 - loss 1.07772231 - samples/sec: 56.41\n",
            "2020-05-26 00:14:51,798 epoch 6 - iter 2/5 - loss 0.93229294 - samples/sec: 57.84\n",
            "2020-05-26 00:15:03,056 epoch 6 - iter 3/5 - loss 0.98150202 - samples/sec: 54.72\n",
            "2020-05-26 00:15:14,651 epoch 6 - iter 4/5 - loss 0.88090521 - samples/sec: 56.89\n",
            "2020-05-26 00:15:25,939 epoch 6 - iter 5/5 - loss 0.78028133 - samples/sec: 205.89\n",
            "2020-05-26 00:15:37,152 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:15:37,157 EPOCH 6 done: loss 0.7803 - lr 0.1000000\n",
            "2020-05-26 00:15:38,393 DEV : loss 0.5228034257888794 - score 0.7778\n",
            "2020-05-26 00:15:38,443 BAD EPOCHS (no improvement): 3\n",
            "2020-05-26 00:15:38,448 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:15:39,291 epoch 7 - iter 1/5 - loss 0.40490055 - samples/sec: 55.32\n",
            "2020-05-26 00:15:50,907 epoch 7 - iter 2/5 - loss 0.40592289 - samples/sec: 56.11\n",
            "2020-05-26 00:16:02,308 epoch 7 - iter 3/5 - loss 0.42398155 - samples/sec: 56.71\n",
            "2020-05-26 00:16:13,960 epoch 7 - iter 4/5 - loss 0.39031719 - samples/sec: 54.83\n",
            "2020-05-26 00:16:24,930 epoch 7 - iter 5/5 - loss 0.33975548 - samples/sec: 226.53\n",
            "2020-05-26 00:16:35,978 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:16:35,983 EPOCH 7 done: loss 0.3398 - lr 0.1000000\n",
            "2020-05-26 00:16:36,943 DEV : loss 0.33797508478164673 - score 0.8586\n",
            "2020-05-26 00:16:36,985 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 00:16:38,927 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:16:39,778 epoch 8 - iter 1/5 - loss 0.33209836 - samples/sec: 54.00\n",
            "2020-05-26 00:16:52,574 epoch 8 - iter 2/5 - loss 0.32589161 - samples/sec: 52.08\n",
            "2020-05-26 00:17:04,563 epoch 8 - iter 3/5 - loss 0.30438416 - samples/sec: 58.29\n",
            "2020-05-26 00:17:16,166 epoch 8 - iter 4/5 - loss 0.27659336 - samples/sec: 56.36\n",
            "2020-05-26 00:17:27,459 epoch 8 - iter 5/5 - loss 0.34925173 - samples/sec: 240.39\n",
            "2020-05-26 00:17:39,343 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:17:39,348 EPOCH 8 done: loss 0.3493 - lr 0.1000000\n",
            "2020-05-26 00:17:40,858 DEV : loss 0.5376145243644714 - score 0.7172\n",
            "2020-05-26 00:17:40,901 BAD EPOCHS (no improvement): 1\n",
            "2020-05-26 00:17:40,908 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:17:41,793 epoch 9 - iter 1/5 - loss 0.67205840 - samples/sec: 50.98\n",
            "2020-05-26 00:17:53,579 epoch 9 - iter 2/5 - loss 0.70954761 - samples/sec: 57.24\n",
            "2020-05-26 00:18:05,640 epoch 9 - iter 3/5 - loss 0.57412595 - samples/sec: 55.09\n",
            "2020-05-26 00:18:17,511 epoch 9 - iter 4/5 - loss 0.45785057 - samples/sec: 59.57\n",
            "2020-05-26 00:18:30,778 epoch 9 - iter 5/5 - loss 0.39396707 - samples/sec: 243.49\n",
            "2020-05-26 00:18:42,377 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:18:42,382 EPOCH 9 done: loss 0.3940 - lr 0.1000000\n",
            "2020-05-26 00:18:43,337 DEV : loss 0.24866335093975067 - score 0.8788\n",
            "2020-05-26 00:18:43,380 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 00:18:45,357 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:18:46,275 epoch 10 - iter 1/5 - loss 0.28626704 - samples/sec: 53.91\n",
            "2020-05-26 00:18:58,563 epoch 10 - iter 2/5 - loss 0.41659242 - samples/sec: 57.80\n",
            "2020-05-26 00:19:10,071 epoch 10 - iter 3/5 - loss 0.44222223 - samples/sec: 55.10\n",
            "2020-05-26 00:19:21,207 epoch 10 - iter 4/5 - loss 0.38050617 - samples/sec: 55.60\n",
            "2020-05-26 00:19:32,275 epoch 10 - iter 5/5 - loss 0.35632000 - samples/sec: 214.88\n",
            "2020-05-26 00:19:43,142 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:19:43,148 EPOCH 10 done: loss 0.3563 - lr 0.1000000\n",
            "2020-05-26 00:19:44,677 DEV : loss 0.6115724444389343 - score 0.7778\n",
            "2020-05-26 00:19:44,720 BAD EPOCHS (no improvement): 1\n",
            "2020-05-26 00:19:46,623 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 00:19:46,628 Testing using best model ...\n",
            "2020-05-26 00:19:46,634 loading file /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/best-model.pt\n",
            "2020-05-26 00:19:48,584 0.8181818181818182\t0.8181818181818182\t0.8181818181818182\n",
            "2020-05-26 00:19:48,590 \n",
            "MICRO_AVG: acc 0.8787878787878788 - f1-score 0.8181818181818182\n",
            "MACRO_AVG: acc 0.8787878787878788 - f1-score 0.8233082706766918\n",
            "-1         tp: 11 - fp: 6 - fn: 0 - tn: 16 - precision: 0.6471 - recall: 1.0000 - accuracy: 0.8182 - f1-score: 0.7857\n",
            "0          tp: 8 - fp: 0 - fn: 3 - tn: 22 - precision: 1.0000 - recall: 0.7273 - accuracy: 0.9091 - f1-score: 0.8421\n",
            "1          tp: 8 - fp: 0 - fn: 3 - tn: 22 - precision: 1.0000 - recall: 0.7273 - accuracy: 0.9091 - f1-score: 0.8421\n",
            "2020-05-26 00:19:48,595 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.676527202129364,\n",
              "  0.9050557613372803,\n",
              "  0.3569127917289734,\n",
              "  0.48473626375198364,\n",
              "  0.9527653455734253,\n",
              "  0.5228034257888794,\n",
              "  0.33797508478164673,\n",
              "  0.5376145243644714,\n",
              "  0.24866335093975067,\n",
              "  0.6115724444389343],\n",
              " 'dev_score_history': [0.696969696969697,\n",
              "  0.7171717171717171,\n",
              "  0.7777777777777778,\n",
              "  0.7575757575757576,\n",
              "  0.6363636363636364,\n",
              "  0.7777777777777778,\n",
              "  0.8585858585858586,\n",
              "  0.7171717171717171,\n",
              "  0.8787878787878788,\n",
              "  0.7777777777777778],\n",
              " 'test_score': 0.8787878787878788,\n",
              " 'train_loss_history': [1.248479413986206,\n",
              "  0.993856155872345,\n",
              "  0.6782370209693909,\n",
              "  0.6985384285449981,\n",
              "  0.45320078134536745,\n",
              "  0.7802813291549683,\n",
              "  0.33975547552108765,\n",
              "  0.349251726269722,\n",
              "  0.393967068195343,\n",
              "  0.3563199996948242]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKyyw1CSZFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MACRO_AVG: acc 0.8787878787878788 - f1-score 0.8233082706766918"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArPepPU3mIqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "279d2fee-4193-4c11-9bd9-1b24e8a5957e"
      },
      "source": [
        "## load the 2nd-stage finetuned model:\n",
        "\n",
        "finetuned_classifier = TextClassifier.load(new_data_folder + 'best-model.pt')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 01:29:23,110 loading file /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0cksDjXc_rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb816f50-4cd7-4c8b-bf9a-5c51a618e9f3"
      },
      "source": [
        "# predict same sentence from above:\n",
        "\n",
        "sentence = Sentence(\"Canada's growth weakens as investment drops, consumers fade\")\n",
        "\n",
        "finetuned_classifier.predict(sentence)\n",
        "\n",
        "print(sentence.labels) ## correct"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1 (0.885)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NECOcOhnh4Se",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "006f9064-f916-4170-f0d0-45bb4f458858"
      },
      "source": [
        "dir(sentence.labels)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__imul__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'append',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'count',\n",
              " 'extend',\n",
              " 'index',\n",
              " 'insert',\n",
              " 'pop',\n",
              " 'remove',\n",
              " 'reverse',\n",
              " 'sort']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwNDl0gziMz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "180a2ce7-3513-48a3-eb1f-4b670687e939"
      },
      "source": [
        "dir(sentence.labels[0])\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_score',\n",
              " '_value',\n",
              " 'score',\n",
              " 'to_dict',\n",
              " 'value']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpR-w18zi9Xr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5391fd08-0433-45bb-8c02-68ac7e2c2929"
      },
      "source": [
        "sentence.labels[0].value"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gl9mmmVi_pG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e20d5f9e-a482-4072-d8e6-da329496c3f6"
      },
      "source": [
        "sentence.labels[0].score"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9955407977104187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzPahERUdG4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8a0fd7c2-93b6-4322-ea2e-47936f1058db"
      },
      "source": [
        "## error analysis\n",
        "\n",
        "# get gold labels\n",
        "#print(corpus.test[0])\n",
        "print(corpus.test[0])\n",
        "print(corpus.test[0].labels)\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"Trump claims victory as GDP grows at fastest pace since 2014 . President Donald Trump said the U.S. economy is on track to reach an annual growth rate of more than 3 per cent , as he celebrated a report Friday that the economy expanded in the second quarter at the fastest pace in four years .\"   [− Tokens: 57  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (1.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_roihowwdy4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f26440c-47d1-4122-85f9-135cc33e2ffc"
      },
      "source": [
        "len(corpus.test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMQq2bGTgGOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdp_test_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/GDP_eva_df_oversampled.csv\",usecols=['title_desc_sent_1','title_desc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJqJpE8jgmuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4cac96f2-dd47-4421-8c01-2bc200f1e762"
      },
      "source": [
        "gdp_test_df.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title_desc_sent_1</th>\n",
              "      <th>title_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Trump claims victory as GDP grows at fastest p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Canada's economy grew 0.1% in August, Statisti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Canada’s economy grows faster than expected. F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Why the Canadian economy seems divorced from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>The candidates: Great Slave. Patrick Scott, Ka...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   title_desc_sent_1                                         title_desc\n",
              "0                  1  Trump claims victory as GDP grows at fastest p...\n",
              "1                  1  Canada's economy grew 0.1% in August, Statisti...\n",
              "2                  1  Canada’s economy grows faster than expected. F...\n",
              "3                  0  Why the Canadian economy seems divorced from t...\n",
              "4                  0  The candidates: Great Slave. Patrick Scott, Ka..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTdgTHtJhEQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f8f8cbcf-bdd0-4120-c3c2-bf1a34d77c20"
      },
      "source": [
        "gdp_test_df['title_desc'].iloc[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Trump claims victory as GDP grows at fastest pace since 2014. President Donald Trump said the U.S. economy is on track to reach an annual growth rate of more than 3 per cent, as he celebrated a report Friday that the economy expanded in the second quarter at the fastest pace in four years.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPm2w8npeSsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eaf05caf-10de-4bd0-9c96-54febc18d0a3"
      },
      "source": [
        "correct = 0\n",
        "\n",
        "for i in range(len(corpus.test)):\n",
        "  print(corpus.test[i])\n",
        "  \n",
        "\n",
        "  #get predictions\n",
        "  #print(gdp_test_df['title_desc'].iloc[i])\n",
        "  sentence = Sentence(gdp_test_df['title_desc'].iloc[i])\n",
        "\n",
        "  finetuned_classifier.predict(sentence)\n",
        "\n",
        "  print(sentence.labels)\n",
        "\n",
        "  #get gold label\n",
        "  print(corpus.test[i].labels)\n",
        "\n",
        "  #calculate correct guesses\n",
        "  if sentence.labels[0].value == corpus.test[i].labels[0].value:\n",
        "    correct += 1\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"Trump claims victory as GDP grows at fastest pace since 2014 . President Donald Trump said the U.S. economy is on track to reach an annual growth rate of more than 3 per cent , as he celebrated a report Friday that the economy expanded in the second quarter at the fastest pace in four years .\"   [− Tokens: 57  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.9621)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Canada 's economy grew 0.1 % in August , Statistics Canada reports . Gross domestic product edged up slightly , but fell short of expectations\"   [− Tokens: 25  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.6064)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Canada ’s economy grows faster than expected . Factories lead fastest economic growth in five months\"   [− Tokens: 16  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.9683)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Why the Canadian economy seems divorced from traditional signals : Don Pittis . With housing and oil off the boil , why has n't the Canadian economy gone into free fall ?\"   [− Tokens: 32  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[-1 (0.9096)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"The candidates : Great Slave . Patrick Scott , Katrina Nokleby face off for seat vacated by former minister Glen Abernethy\"   [− Tokens: 21  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.9984)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"China 's economic growth sinks to lowest level in decades . Weak consumer demand and U.S. tariffs being blamed\"   [− Tokens: 19  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.979)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Trump claims victory as GDP grows at fastest pace since 2014 . President Donald Trump said the U.S. economy is on track to reach an annual growth rate of more than 3 per cent , as he celebrated a report Friday that the economy expanded in the second quarter at the fastest pace in four years .\"   [− Tokens: 57  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.9621)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Setback to Montreal retail reopening shows rocky path to getting economy running again . The high number of COVID-19 cases in Montreal hospitals caused Premier Francois Legault to postpone store openings by a week\"   [− Tokens: 34  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9631)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Ambrose disagrees with Scheer 's assertion that Trudeau caved to Trump on NAFTA . Former Tory interim-leader says Canada made sacrifices to secure gains in NAFTA negotiation\"   [− Tokens: 27  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.9521)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Trump predicts data will show U.S. economy in ‘ terrific’ shape . U.S. President Donald Trump predicted data on Friday will show the U.S. economy is in “ terrific ” shape amid forecasts that growth topped 4 per cent in the second quarter , the fastest since 2014 .\"   [− Tokens: 49  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.9361)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"U.S. first-quarter GDP growth revised down to 2 % on services . The U.S. economy expanded in the first quarter at a slower pace than previously estimated , reflecting downward revisions to spending on services and to inventory investment , according to Commerce Department data released Thursday .\"   [− Tokens: 48  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.953)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Carbon tax must hit $ 210 per tonne by 2030 to meet Paris targets , report concludes . The tax remains the most cost-effective tool for fighting climate change , says Ecofiscal Commission\"   [− Tokens: 33  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.5682)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Bank of Canada ’s Stephen Poloz gets chance today to put rate cut speculation on ice . Investors now see a strong chance of a cut by the Bank of Canada over the next 12 months\"   [− Tokens: 36  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.7183)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Where are Thomas Cook travellers stranded ? Here 's how 17 countries are responding . About 600,000 people affected around world by travel company 's bankruptcy\"   [− Tokens: 26  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.9522)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Canada 's yield curve inverts the most in 12 years on Trump 's Mexico tariffs threat . Investors are worried the tariffs will derail the revised NAFTA\"   [− Tokens: 27  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9725)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Month-late GDP data to detail where the U.S. economy is losing steam . After a monthlong delay due to the federal shutdown , data out Thursday will show just how much steam the U.S. economy lost in the fourth quarter -- and what it all means for 2019 .\"   [− Tokens: 49  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9907)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"China 's economy grew 6 % in fourth quarter as demand stabilized . China ’s economy stabilized last quarter after slowing to the weakest pace in almost three decades , with the first acceleration in investment since June signaling that a firmer recovery could be underway .\"   [− Tokens: 47  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[-1 (0.5108)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Vancouver needs 10,000 affordable housing units a year to address rental ' backlog ,' report advises . There ‚ Äôs a mismatch between what ‚ Äôs being built and what renters need , says economist Mark Lee\"   [− Tokens: 37  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.9917)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Canadian economy rebounds as oil and auto production ramps up . Canada ’s economy rebounded more than economists forecast in February , as idled oil and auto production came back on line .\"   [− Tokens: 33  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.9702)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Canada 's economy shrinks in October from auto strike spillover . Canada ’s economy contracted in October for the first time in eight months , as the United Auto Workers strike in the U.S. weighed on plant production .\"   [− Tokens: 39  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9987)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"The Bank of Canada has learned a few things about targeting inflation , and it 's sharing lessons with the Fed . The bar to change is high\"   [− Tokens: 28  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.7714)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"China 's economic growth sinks to lowest level in decades . Weak consumer demand and U.S. tariffs being blamed\"   [− Tokens: 19  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.979)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Canada 's economy shrinks in October from auto strike spillover . Canada ’s economy contracted in October for the first time in eight months , as the United Auto Workers strike in the U.S. weighed on plant production .\"   [− Tokens: 39  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9987)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Canada 's economy shrinks 0.1 % in October , StatsCan reports . UAW strike weighted down manufacturing sector which declined for the 4th time in 5 months\"   [− Tokens: 27  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.8813)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Canada 's economy slows even as business investment perks up . Canada ’s economy slowed sharply in the third quarter , as a drop in exports and draw down in business inventories masked a rebound in domestic demand .\"   [− Tokens: 39  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.991)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Mining boom to drive economic growth in territories beyond rest of Canada : report . The Conference Board of Canada says outlook rosy for Nunavut and Yukon , but N.W.T. in for a bumpy ride\"   [− Tokens: 35  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[-1 (0.5803)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"If you thought August was bad , get ready for the worst month for Canadian stocks . In the past 10 years , the TSX has dropped an average 1.5 % in September\"   [− Tokens: 33  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[-1 (0.5721)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Hamilton hits $ 1B in building permits in just 8 months . It 's the fastest the city has ever hit $ 1B , according to officials\"   [− Tokens: 27  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.4806)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"The Toronto Raptors' NBA playoff run helped boost retail sales in Canada in June . Canadian retail sales beat forecasts in June , keeping the economy on track for what 's anticipated to have been a strong second quarter of growth\"   [− Tokens: 41  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.9605)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Trump claims victory as GDP grows at fastest pace since 2014 . President Donald Trump said the U.S. economy is on track to reach an annual growth rate of more than 3 per cent , as he celebrated a report Friday that the economy expanded in the second quarter at the fastest pace in four years .\"   [− Tokens: 57  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.9621)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Oil drives Canada 's fastest economic growth spurt in a year . Canada ’s economy grew at the fastest pace in a year , further evidence of a solid expansion even as trade tensions with the U.S. remain a threat .\"   [− Tokens: 41  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[-1 (0.6974)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Trump is threatening Iran with more sanctions — but what 's left to target ? . Current sanctions have already sent the country spiralling into a deep recession\"   [− Tokens: 28  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[-1 (0.9762)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"The candidates for Regina ‚ ÄíLewvan and where they stand on the issues . Candidates gathered for panel discussion Friday\"   [− Tokens: 20  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.9997)]\n",
            "[0 (1.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL29Ak69ebux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f388568-1f98-4ff8-d939-9b7fbc337b55"
      },
      "source": [
        " correct #27/33 = 82% accuracy\n",
        "\n",
        " #reasonable wrongs\n",
        "\n",
        "## words in negative sense but meaning is neutral\n",
        "# Sentence: \"Why the Canadian economy seems divorced from traditional signals : Don Pittis . With housing and oil off the boil , why has n't the Canadian economy gone into free fall ?\"   [− Tokens: 32  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
        "# [-1 (0.9096)]\n",
        "# [0 (1.0)]\n",
        "\n",
        "## not learning enough that sentiment should be Canada-specific\n",
        "# Sentence: \"Trump is threatening Iran with more sanctions — but what 's left to target ? . Current sanctions have already sent the country spiralling into a deep recession\"   [− Tokens: 28  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
        "# [-1 (0.9762)]\n",
        "# [0 (1.0)]\n",
        "\n",
        "## not learning enough that sentiment should be GDP-specific\n",
        "# Sentence: \"If you thought August was bad , get ready for the worst month for Canadian stocks . In the past 10 years , the TSX has dropped an average 1.5 % in September\"   [− Tokens: 33  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
        "# [-1 (0.5721)]\n",
        "# [0 (1.0)]\n",
        "\n",
        "## not that reasonable wrongs -- all predicted to the opposite extreme... problematic!\n",
        "\n",
        "## 'stabilized' overshadowed by 'slowing' and 'weakest'? -- quite inconfident prediction\n",
        "# Sentence: \"China 's economy grew 6 % in fourth quarter as demand stabilized . China ’s economy stabilized last quarter after slowing to the weakest pace in almost three decades , with the first acceleration in investment since June signaling that a firmer recovery could be underway .\"   [− Tokens: 47  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
        "# [-1 (0.5108)]\n",
        "# [1 (1.0)]\n",
        "\n",
        "## 'fastest growth' vs \"trade tension\"/ \"threat\"\n",
        "# Sentence: \"Oil drives Canada 's fastest economic growth spurt in a year . Canada ’s economy grew at the fastest pace in a year , further evidence of a solid expansion even as trade tensions with the U.S. remain a threat .\"   [− Tokens: 41  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
        "# [-1 (0.6974)]\n",
        "# [1 (1.0)]\n",
        "\n",
        "## 'boom','rosy' vs 'bumpy ride' -- description balanced out but positive headline should have more weight.\n",
        "# Sentence: \"Mining boom to drive economic growth in territories beyond rest of Canada : report . The Conference Board of Canada says outlook rosy for Nunavut and Yukon , but N.W.T. in for a bumpy ride\"   [− Tokens: 35  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
        "# [-1 (0.5803)]\n",
        "# [1 (1.0)]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJLlgMV4jWPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## check accuracy if only count confident predictions(condifence score > 0.7?)\n",
        "confident_total = 0\n",
        "confident_correct = 0\n",
        "\n",
        "for i in range(len(corpus.test)):\n",
        "  #print(corpus.test[i])\n",
        "  \n",
        "\n",
        "  #get predictions\n",
        "  #print(gdp_test_df['title_desc'].iloc[i])\n",
        "  sentence = Sentence(gdp_test_df['title_desc'].iloc[i])\n",
        "\n",
        "  finetuned_classifier.predict(sentence)\n",
        "\n",
        "  #print(sentence.labels)\n",
        "\n",
        "  #get gold label\n",
        "  #print(corpus.test[i].labels)\n",
        "\n",
        "  #calculate correct guesses\n",
        "  if sentence.labels[0].score > 0.7:\n",
        "    confident_total += 1\n",
        "    if sentence.labels[0].value == corpus.test[i].labels[0].value:\n",
        "      confident_correct += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBIUuPVupWc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4742b820-e52d-4d73-fbc8-65d048c20f58"
      },
      "source": [
        "confident_correct"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uaIXLevpj-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "904242b9-62ba-4e9b-ec1a-d6d94a87cbd4"
      },
      "source": [
        "confident_total"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnQz3cTGpmcS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e87888cf-d314-4e00-95d1-ade5a7f8aa72"
      },
      "source": [
        "confident_correct/confident_total ## higher accuracy, pick only confident predictions for good visualization! also for correlation calculation?"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9230769230769231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNda2ah3prLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}