{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V2 Two_stage_flair_training_GDP_error_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybjXa4UJ3g7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVY0ZiGk38i_",
        "colab_type": "code",
        "outputId": "5bac0072-f84b-4966-8486-68e299e25684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-d5c6wfoe\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-d5c6wfoe\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: langdetect in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (5.4.2)\n",
            "Requirement already satisfied, skipping upgrade: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.5.10)\n",
            "Requirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: transformers>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.5.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.2.10)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from langdetect->flair==0.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.5) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (0.13.1)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (8.3.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.5) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.13.13)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.10.0->flair==0.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.16.13)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.5-cp36-none-any.whl size=148939 sha256=087edd58e35d7473036a5c667cab9327ec2dc86dee5289506c689f8934f84ad2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4wzk3ps9/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Installing collected packages: flair\n",
            "  Found existing installation: flair 0.5\n",
            "    Uninstalling flair-0.5:\n",
            "      Successfully uninstalled flair-0.5\n",
            "Successfully installed flair-0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP7gl75D39dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "from flair.data import Corpus\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfpsjw8I4Si-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBdZ1L34XwO",
        "colab_type": "code",
        "outputId": "1b9d25a8-9f0a-48b3-e3ba-cdb93ba1c7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U90p69Xd5KIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_folder = \"./drive/My Drive/capstone/data/\"\n",
        "data_folder = \"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkUisuXz7tuK",
        "colab_type": "text"
      },
      "source": [
        "### First Stage (Train on benchmark dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-_Bmpa6gn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = pd.read_csv(data_folder + \"combined_benchmark.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVaSsyAn72AU",
        "colab_type": "code",
        "outputId": "877b28fd-f5c6-4d83-f09d-84925c5a1743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "benchmark = benchmark[['label', 'text']]\n",
        "benchmark.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Why not subscribe to the magazine ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>Tornio Works employs 2,300 of whom more than 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>The move is aimed at boosting sales , cost-eff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>As a result of the merger , the largest profes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>18 March 2010 A leakage in the gypsum pond was...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0                Why not subscribe to the magazine ?\n",
              "1     -1  Tornio Works employs 2,300 of whom more than 1...\n",
              "2      1  The move is aimed at boosting sales , cost-eff...\n",
              "3      0  As a result of the merger , the largest profes...\n",
              "4     -1  18 March 2010 A leakage in the gypsum pond was..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_MVMXq8pvf",
        "colab_type": "text"
      },
      "source": [
        "#### Create train, dev and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUbbfcSC8ekr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#benchmark = benchmark.sample(frac=1) # if not set random state, everytime has different training result\n",
        "\n",
        "benchmark = benchmark.sample(frac=1, random_state=42)\n",
        "\n",
        "\n",
        "benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', sep='\\t', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', sep='\\t', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', sep='\\t', index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjNxI9oDHFlN",
        "colab_type": "code",
        "outputId": "4123a041-cc0e-4405-95a2-33bc052733de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "benchmark.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>1</td>\n",
              "      <td>About Elcoteq Elcoteq SE is a leading electron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1105</th>\n",
              "      <td>-1</td>\n",
              "      <td>U.S. goods trade deficit deteriorates; factory...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>0</td>\n",
              "      <td>Product coverage : baked goods ; biscuits ; br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>0</td>\n",
              "      <td>Tyrv+Æinen is of the opinion that the airline ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>-1</td>\n",
              "      <td>Wall St. Week Ahead: U.S. stock reign may not ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text\n",
              "892       1  About Elcoteq Elcoteq SE is a leading electron...\n",
              "1105     -1  U.S. goods trade deficit deteriorates; factory...\n",
              "413       0  Product coverage : baked goods ; biscuits ; br...\n",
              "522       0  Tyrv+Æinen is of the opinion that the airline ...\n",
              "1036     -1  Wall St. Week Ahead: U.S. stock reign may not ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U8LTIJ-H2fM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', index = False, header = False)\n",
        "# benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', index = False, header = False)\n",
        "# benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a91JSI9nI1Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/dev.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7QE3IS69txr",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz-2gNy58wDI",
        "colab_type": "code",
        "outputId": "bd8bd1ef-9e3f-42d7-d553-cbf58cee1bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "#corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_folder), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
        "column_name_map = {1: \"text\", 0: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                         column_name_map,\n",
        "                                         skip_header=False, #no header in kaggle data\n",
        "                                         delimiter='\\t',    # comma separated rows\n",
        "                                         train_file='train.csv', ## passing in file names manuelly when it can't auto detect\n",
        "                                         dev_file='dev.csv',\n",
        "                                         test_file='test.csv'\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 23:19:52,182 Reading data from /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training\n",
            "2020-05-26 23:19:52,183 Train: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/train.csv\n",
            "2020-05-26 23:19:52,184 Dev: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/dev.csv\n",
            "2020-05-26 23:19:52,186 Test: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCgaVpvzHSB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb1lynSQ98-z",
        "colab_type": "text"
      },
      "source": [
        "#### Create word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u9PFUze9_5y",
        "colab_type": "code",
        "outputId": "c8d059ea-211a-4219-a99c-511f860cd3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
        "\n",
        "#word_embeddings = [BertEmbeddings()]\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HovCqFfSMjmJ",
        "colab_type": "text"
      },
      "source": [
        "#### First Stage Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wik8DDxm-DKy",
        "colab_type": "code",
        "outputId": "f7da32db-2738-472c-fc49-7bd2708b80a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train(data_folder, max_epochs=10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 23:19:59,869 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "100%|██████████| 1314/1314 [00:01<00:00, 1169.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 23:20:01,318 [b'1', b'-1', b'0']\n",
            "2020-05-26 23:20:01,332 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:20:01,336 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-26 23:20:01,341 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:20:01,343 Corpus: \"Corpus: 1168 train + 147 dev + 146 test sentences\"\n",
            "2020-05-26 23:20:01,345 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:20:01,347 Parameters:\n",
            "2020-05-26 23:20:01,348  - learning_rate: \"0.1\"\n",
            "2020-05-26 23:20:01,349  - mini_batch_size: \"32\"\n",
            "2020-05-26 23:20:01,352  - patience: \"3\"\n",
            "2020-05-26 23:20:01,352  - anneal_factor: \"0.5\"\n",
            "2020-05-26 23:20:01,354  - max_epochs: \"10\"\n",
            "2020-05-26 23:20:01,356  - shuffle: \"True\"\n",
            "2020-05-26 23:20:01,357  - train_with_dev: \"False\"\n",
            "2020-05-26 23:20:01,359  - batch_growth_annealing: \"False\"\n",
            "2020-05-26 23:20:01,359 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:20:01,361 Model training base path: \"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training\"\n",
            "2020-05-26 23:20:01,362 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:20:01,364 Device: cuda:0\n",
            "2020-05-26 23:20:01,365 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:20:01,367 Embeddings storage mode: cpu\n",
            "2020-05-26 23:20:01,381 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 23:20:04,100 epoch 1 - iter 3/37 - loss 1.44395936 - samples/sec: 68.68\n",
            "2020-05-26 23:20:18,138 epoch 1 - iter 6/37 - loss 1.39971318 - samples/sec: 75.61\n",
            "2020-05-26 23:20:30,443 epoch 1 - iter 9/37 - loss 1.26294792 - samples/sec: 75.18\n",
            "2020-05-26 23:20:44,189 epoch 1 - iter 12/37 - loss 1.32099261 - samples/sec: 72.24\n",
            "2020-05-26 23:20:56,804 epoch 1 - iter 15/37 - loss 1.32809993 - samples/sec: 74.58\n",
            "2020-05-26 23:21:08,920 epoch 1 - iter 18/37 - loss 1.26090499 - samples/sec: 77.14\n",
            "2020-05-26 23:21:21,621 epoch 1 - iter 21/37 - loss 1.25372351 - samples/sec: 76.97\n",
            "2020-05-26 23:21:34,145 epoch 1 - iter 24/37 - loss 1.22728333 - samples/sec: 72.79\n",
            "2020-05-26 23:21:46,480 epoch 1 - iter 27/37 - loss 1.18865638 - samples/sec: 78.49\n",
            "2020-05-26 23:21:58,849 epoch 1 - iter 30/37 - loss 1.16654052 - samples/sec: 84.33\n",
            "2020-05-26 23:22:11,401 epoch 1 - iter 33/37 - loss 1.15726749 - samples/sec: 81.30\n",
            "2020-05-26 23:22:23,828 epoch 1 - iter 36/37 - loss 1.16265203 - samples/sec: 86.34\n",
            "2020-05-26 23:22:35,265 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:22:35,266 EPOCH 1 done: loss 1.1567 - lr 0.1000000\n",
            "2020-05-26 23:22:37,935 DEV : loss 0.9083929061889648 - score 0.7415\n",
            "2020-05-26 23:22:38,067 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:22:40,121 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:22:41,861 epoch 2 - iter 3/37 - loss 0.88714860 - samples/sec: 67.59\n",
            "2020-05-26 23:22:56,704 epoch 2 - iter 6/37 - loss 0.87935636 - samples/sec: 78.47\n",
            "2020-05-26 23:23:09,110 epoch 2 - iter 9/37 - loss 0.87905351 - samples/sec: 75.54\n",
            "2020-05-26 23:23:21,629 epoch 2 - iter 12/37 - loss 0.90964886 - samples/sec: 67.04\n",
            "2020-05-26 23:23:33,929 epoch 2 - iter 15/37 - loss 0.90216315 - samples/sec: 76.75\n",
            "2020-05-26 23:23:46,325 epoch 2 - iter 18/37 - loss 0.93670799 - samples/sec: 81.17\n",
            "2020-05-26 23:23:58,471 epoch 2 - iter 21/37 - loss 0.94135414 - samples/sec: 79.49\n",
            "2020-05-26 23:24:10,915 epoch 2 - iter 24/37 - loss 0.91381725 - samples/sec: 78.58\n",
            "2020-05-26 23:24:24,650 epoch 2 - iter 27/37 - loss 0.90530881 - samples/sec: 77.22\n",
            "2020-05-26 23:24:37,555 epoch 2 - iter 30/37 - loss 0.92158333 - samples/sec: 82.10\n",
            "2020-05-26 23:24:49,956 epoch 2 - iter 33/37 - loss 0.93165499 - samples/sec: 81.44\n",
            "2020-05-26 23:25:02,349 epoch 2 - iter 36/37 - loss 0.91608392 - samples/sec: 69.66\n",
            "2020-05-26 23:25:13,806 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:25:13,813 EPOCH 2 done: loss 0.9109 - lr 0.1000000\n",
            "2020-05-26 23:25:16,153 DEV : loss 0.8781045079231262 - score 0.7415\n",
            "2020-05-26 23:25:16,281 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:25:18,293 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:25:19,980 epoch 3 - iter 3/37 - loss 0.94053282 - samples/sec: 69.61\n",
            "2020-05-26 23:25:34,492 epoch 3 - iter 6/37 - loss 0.89394749 - samples/sec: 76.46\n",
            "2020-05-26 23:25:47,833 epoch 3 - iter 9/37 - loss 0.94412769 - samples/sec: 76.72\n",
            "2020-05-26 23:26:00,594 epoch 3 - iter 12/37 - loss 0.89273273 - samples/sec: 80.74\n",
            "2020-05-26 23:26:13,234 epoch 3 - iter 15/37 - loss 0.84584700 - samples/sec: 80.05\n",
            "2020-05-26 23:26:25,409 epoch 3 - iter 18/37 - loss 0.81751818 - samples/sec: 78.28\n",
            "2020-05-26 23:26:38,001 epoch 3 - iter 21/37 - loss 0.82713660 - samples/sec: 82.36\n",
            "2020-05-26 23:26:50,467 epoch 3 - iter 24/37 - loss 0.84505539 - samples/sec: 80.56\n",
            "2020-05-26 23:27:02,887 epoch 3 - iter 27/37 - loss 0.82622165 - samples/sec: 80.56\n",
            "2020-05-26 23:27:15,445 epoch 3 - iter 30/37 - loss 0.82358029 - samples/sec: 73.22\n",
            "2020-05-26 23:27:27,742 epoch 3 - iter 33/37 - loss 0.83380846 - samples/sec: 70.49\n",
            "2020-05-26 23:27:39,949 epoch 3 - iter 36/37 - loss 0.82347145 - samples/sec: 84.65\n",
            "2020-05-26 23:27:51,669 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:27:51,672 EPOCH 3 done: loss 0.8434 - lr 0.1000000\n",
            "2020-05-26 23:27:54,010 DEV : loss 0.8748133778572083 - score 0.7279\n",
            "2020-05-26 23:27:54,143 BAD EPOCHS (no improvement): 1\n",
            "2020-05-26 23:27:54,149 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:27:56,042 epoch 4 - iter 3/37 - loss 0.70581605 - samples/sec: 71.79\n",
            "2020-05-26 23:28:08,141 epoch 4 - iter 6/37 - loss 0.65591272 - samples/sec: 76.16\n",
            "2020-05-26 23:28:33,065 epoch 4 - iter 12/37 - loss 0.69358273 - samples/sec: 78.97\n",
            "2020-05-26 23:28:45,528 epoch 4 - iter 15/37 - loss 0.69693477 - samples/sec: 77.49\n",
            "2020-05-26 23:28:57,862 epoch 4 - iter 18/37 - loss 0.73196056 - samples/sec: 78.68\n",
            "2020-05-26 23:29:10,663 epoch 4 - iter 21/37 - loss 0.72606274 - samples/sec: 75.68\n",
            "2020-05-26 23:29:23,211 epoch 4 - iter 24/37 - loss 0.75789785 - samples/sec: 73.96\n",
            "2020-05-26 23:29:37,514 epoch 4 - iter 27/37 - loss 0.80032461 - samples/sec: 69.84\n",
            "2020-05-26 23:29:50,384 epoch 4 - iter 30/37 - loss 0.77824765 - samples/sec: 83.81\n",
            "2020-05-26 23:30:02,731 epoch 4 - iter 33/37 - loss 0.77559304 - samples/sec: 87.63\n",
            "2020-05-26 23:30:15,218 epoch 4 - iter 36/37 - loss 0.77378779 - samples/sec: 82.08\n",
            "2020-05-26 23:30:26,929 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:30:26,933 EPOCH 4 done: loss 0.7690 - lr 0.1000000\n",
            "2020-05-26 23:30:29,522 DEV : loss 0.9871878623962402 - score 0.7234\n",
            "2020-05-26 23:30:29,650 BAD EPOCHS (no improvement): 2\n",
            "2020-05-26 23:30:29,655 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:30:31,271 epoch 5 - iter 3/37 - loss 0.60354151 - samples/sec: 76.43\n",
            "2020-05-26 23:30:43,564 epoch 5 - iter 6/37 - loss 0.65017339 - samples/sec: 72.84\n",
            "2020-05-26 23:30:56,698 epoch 5 - iter 9/37 - loss 0.75776027 - samples/sec: 78.67\n",
            "2020-05-26 23:31:09,249 epoch 5 - iter 12/37 - loss 0.81244554 - samples/sec: 83.36\n",
            "2020-05-26 23:31:21,832 epoch 5 - iter 15/37 - loss 0.77342111 - samples/sec: 72.79\n",
            "2020-05-26 23:31:33,991 epoch 5 - iter 18/37 - loss 0.73737712 - samples/sec: 85.07\n",
            "2020-05-26 23:31:46,659 epoch 5 - iter 21/37 - loss 0.72243546 - samples/sec: 77.38\n",
            "2020-05-26 23:31:59,377 epoch 5 - iter 24/37 - loss 0.71206390 - samples/sec: 70.77\n",
            "2020-05-26 23:32:11,632 epoch 5 - iter 27/37 - loss 0.70656656 - samples/sec: 88.27\n",
            "2020-05-26 23:32:23,910 epoch 5 - iter 30/37 - loss 0.73064396 - samples/sec: 83.89\n",
            "2020-05-26 23:32:35,977 epoch 5 - iter 33/37 - loss 0.71747242 - samples/sec: 77.01\n",
            "2020-05-26 23:32:48,166 epoch 5 - iter 36/37 - loss 0.70267837 - samples/sec: 82.87\n",
            "2020-05-26 23:32:59,683 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:32:59,687 EPOCH 5 done: loss 0.6996 - lr 0.1000000\n",
            "2020-05-26 23:33:02,268 DEV : loss 0.9453868865966797 - score 0.737\n",
            "2020-05-26 23:33:02,398 BAD EPOCHS (no improvement): 3\n",
            "2020-05-26 23:33:02,401 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:33:03,995 epoch 6 - iter 3/37 - loss 0.63511080 - samples/sec: 73.48\n",
            "2020-05-26 23:33:16,500 epoch 6 - iter 6/37 - loss 0.71829202 - samples/sec: 71.36\n",
            "2020-05-26 23:33:29,388 epoch 6 - iter 9/37 - loss 0.67378115 - samples/sec: 67.89\n",
            "2020-05-26 23:33:41,367 epoch 6 - iter 12/37 - loss 0.65253732 - samples/sec: 84.03\n",
            "2020-05-26 23:33:53,857 epoch 6 - iter 15/37 - loss 0.65008324 - samples/sec: 79.19\n",
            "2020-05-26 23:34:05,986 epoch 6 - iter 18/37 - loss 0.70899155 - samples/sec: 79.65\n",
            "2020-05-26 23:34:18,441 epoch 6 - iter 21/37 - loss 0.71776926 - samples/sec: 78.03\n",
            "2020-05-26 23:34:30,989 epoch 6 - iter 24/37 - loss 0.69138786 - samples/sec: 78.57\n",
            "2020-05-26 23:34:44,180 epoch 6 - iter 27/37 - loss 0.68731334 - samples/sec: 85.00\n",
            "2020-05-26 23:34:57,242 epoch 6 - iter 30/37 - loss 0.68497333 - samples/sec: 80.36\n",
            "2020-05-26 23:35:09,714 epoch 6 - iter 33/37 - loss 0.67524911 - samples/sec: 66.24\n",
            "2020-05-26 23:35:22,335 epoch 6 - iter 36/37 - loss 0.68375722 - samples/sec: 80.44\n",
            "2020-05-26 23:35:33,876 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:35:33,880 EPOCH 6 done: loss 0.6830 - lr 0.1000000\n",
            "2020-05-26 23:35:36,212 DEV : loss 1.224395751953125 - score 0.7098\n",
            "Epoch     6: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-05-26 23:35:36,340 BAD EPOCHS (no improvement): 4\n",
            "2020-05-26 23:35:36,346 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:35:37,974 epoch 7 - iter 3/37 - loss 0.54363604 - samples/sec: 76.53\n",
            "2020-05-26 23:35:50,555 epoch 7 - iter 6/37 - loss 0.54114694 - samples/sec: 78.39\n",
            "2020-05-26 23:36:04,121 epoch 7 - iter 9/37 - loss 0.52960357 - samples/sec: 78.07\n",
            "2020-05-26 23:36:16,423 epoch 7 - iter 12/37 - loss 0.52591478 - samples/sec: 75.87\n",
            "2020-05-26 23:36:28,903 epoch 7 - iter 15/37 - loss 0.51291020 - samples/sec: 77.57\n",
            "2020-05-26 23:36:41,097 epoch 7 - iter 18/37 - loss 0.50568380 - samples/sec: 73.21\n",
            "2020-05-26 23:36:53,527 epoch 7 - iter 21/37 - loss 0.51457020 - samples/sec: 80.50\n",
            "2020-05-26 23:37:05,942 epoch 7 - iter 24/37 - loss 0.51306254 - samples/sec: 75.39\n",
            "2020-05-26 23:37:18,035 epoch 7 - iter 27/37 - loss 0.52020875 - samples/sec: 82.87\n",
            "2020-05-26 23:37:30,416 epoch 7 - iter 30/37 - loss 0.52755712 - samples/sec: 80.04\n",
            "2020-05-26 23:37:43,026 epoch 7 - iter 33/37 - loss 0.53187741 - samples/sec: 79.86\n",
            "2020-05-26 23:37:55,687 epoch 7 - iter 36/37 - loss 0.52401738 - samples/sec: 78.67\n",
            "2020-05-26 23:38:07,301 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:38:07,304 EPOCH 7 done: loss 0.5233 - lr 0.0500000\n",
            "2020-05-26 23:38:09,629 DEV : loss 0.9033380746841431 - score 0.7551\n",
            "2020-05-26 23:38:09,981 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:38:12,019 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:38:13,739 epoch 8 - iter 3/37 - loss 0.37489011 - samples/sec: 71.45\n",
            "2020-05-26 23:38:28,625 epoch 8 - iter 6/37 - loss 0.57038009 - samples/sec: 78.87\n",
            "2020-05-26 23:38:41,261 epoch 8 - iter 9/37 - loss 0.55250365 - samples/sec: 74.23\n",
            "2020-05-26 23:38:53,521 epoch 8 - iter 12/37 - loss 0.52498575 - samples/sec: 77.85\n",
            "2020-05-26 23:39:05,975 epoch 8 - iter 15/37 - loss 0.51779133 - samples/sec: 68.02\n",
            "2020-05-26 23:39:18,618 epoch 8 - iter 18/37 - loss 0.52174985 - samples/sec: 73.51\n",
            "2020-05-26 23:39:31,096 epoch 8 - iter 21/37 - loss 0.51658726 - samples/sec: 80.81\n",
            "2020-05-26 23:39:43,458 epoch 8 - iter 24/37 - loss 0.52079753 - samples/sec: 79.54\n",
            "2020-05-26 23:39:57,406 epoch 8 - iter 27/37 - loss 0.52020445 - samples/sec: 72.44\n",
            "2020-05-26 23:40:09,970 epoch 8 - iter 30/37 - loss 0.51533819 - samples/sec: 85.45\n",
            "2020-05-26 23:40:22,303 epoch 8 - iter 33/37 - loss 0.50964546 - samples/sec: 82.64\n",
            "2020-05-26 23:40:35,177 epoch 8 - iter 36/37 - loss 0.52154927 - samples/sec: 76.27\n",
            "2020-05-26 23:40:46,902 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:40:46,903 EPOCH 8 done: loss 0.5122 - lr 0.0500000\n",
            "2020-05-26 23:40:49,531 DEV : loss 0.8314997553825378 - score 0.7642\n",
            "2020-05-26 23:40:49,653 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:40:51,652 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:40:53,391 epoch 9 - iter 3/37 - loss 0.43535863 - samples/sec: 70.36\n",
            "2020-05-26 23:41:08,515 epoch 9 - iter 6/37 - loss 0.48195168 - samples/sec: 79.96\n",
            "2020-05-26 23:41:20,742 epoch 9 - iter 9/37 - loss 0.48119799 - samples/sec: 82.12\n",
            "2020-05-26 23:41:33,000 epoch 9 - iter 12/37 - loss 0.47535571 - samples/sec: 81.05\n",
            "2020-05-26 23:41:45,279 epoch 9 - iter 15/37 - loss 0.48751104 - samples/sec: 78.20\n",
            "2020-05-26 23:41:57,773 epoch 9 - iter 18/37 - loss 0.49744134 - samples/sec: 76.89\n",
            "2020-05-26 23:42:10,841 epoch 9 - iter 21/37 - loss 0.48804739 - samples/sec: 78.18\n",
            "2020-05-26 23:42:23,524 epoch 9 - iter 24/37 - loss 0.49080171 - samples/sec: 72.15\n",
            "2020-05-26 23:42:35,995 epoch 9 - iter 27/37 - loss 0.48509922 - samples/sec: 88.19\n",
            "2020-05-26 23:42:48,328 epoch 9 - iter 30/37 - loss 0.49723852 - samples/sec: 79.97\n",
            "2020-05-26 23:43:00,763 epoch 9 - iter 33/37 - loss 0.49376273 - samples/sec: 80.09\n",
            "2020-05-26 23:43:13,160 epoch 9 - iter 36/37 - loss 0.48298334 - samples/sec: 81.49\n",
            "2020-05-26 23:43:26,401 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:43:26,402 EPOCH 9 done: loss 0.4775 - lr 0.0500000\n",
            "2020-05-26 23:43:29,069 DEV : loss 0.859683632850647 - score 0.7778\n",
            "2020-05-26 23:43:29,203 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:43:31,280 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:43:33,064 epoch 10 - iter 3/37 - loss 0.48130654 - samples/sec: 76.11\n",
            "2020-05-26 23:43:47,823 epoch 10 - iter 6/37 - loss 0.49015734 - samples/sec: 76.96\n",
            "2020-05-26 23:44:00,290 epoch 10 - iter 9/37 - loss 0.44398206 - samples/sec: 77.81\n",
            "2020-05-26 23:44:12,776 epoch 10 - iter 12/37 - loss 0.46569706 - samples/sec: 65.73\n",
            "2020-05-26 23:44:25,244 epoch 10 - iter 15/37 - loss 0.46422411 - samples/sec: 79.91\n",
            "2020-05-26 23:44:37,545 epoch 10 - iter 18/37 - loss 0.44609738 - samples/sec: 77.11\n",
            "2020-05-26 23:44:49,767 epoch 10 - iter 21/37 - loss 0.46117238 - samples/sec: 80.14\n",
            "2020-05-26 23:45:02,626 epoch 10 - iter 24/37 - loss 0.45318689 - samples/sec: 77.84\n",
            "2020-05-26 23:45:16,784 epoch 10 - iter 27/37 - loss 0.45018114 - samples/sec: 79.41\n",
            "2020-05-26 23:45:28,927 epoch 10 - iter 30/37 - loss 0.45913476 - samples/sec: 85.27\n",
            "2020-05-26 23:45:41,412 epoch 10 - iter 33/37 - loss 0.45367753 - samples/sec: 78.95\n",
            "2020-05-26 23:45:53,753 epoch 10 - iter 36/37 - loss 0.44731460 - samples/sec: 79.44\n",
            "2020-05-26 23:46:05,843 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:05,851 EPOCH 10 done: loss 0.4500 - lr 0.0500000\n",
            "2020-05-26 23:46:08,222 DEV : loss 0.9503604769706726 - score 0.7687\n",
            "2020-05-26 23:46:08,346 BAD EPOCHS (no improvement): 1\n",
            "2020-05-26 23:46:10,301 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:10,306 Testing using best model ...\n",
            "2020-05-26 23:46:10,312 loading file /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/best-model.pt\n",
            "2020-05-26 23:46:13,507 0.6095890410958904\t0.6095890410958904\t0.6095890410958904\n",
            "2020-05-26 23:46:13,511 \n",
            "MICRO_AVG: acc 0.7397260273972602 - f1-score 0.6095890410958904\n",
            "MACRO_AVG: acc 0.7397260273972602 - f1-score 0.6067561226652136\n",
            "-1         tp: 41 - fp: 27 - fn: 12 - tn: 66 - precision: 0.6029 - recall: 0.7736 - accuracy: 0.7329 - f1-score: 0.6777\n",
            "0          tp: 29 - fp: 13 - fn: 9 - tn: 95 - precision: 0.6905 - recall: 0.7632 - accuracy: 0.8493 - f1-score: 0.7250\n",
            "1          tp: 19 - fp: 17 - fn: 36 - tn: 74 - precision: 0.5278 - recall: 0.3455 - accuracy: 0.6370 - f1-score: 0.4176\n",
            "2020-05-26 23:46:13,515 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.9083929061889648,\n",
              "  0.8781045079231262,\n",
              "  0.8748133778572083,\n",
              "  0.9871878623962402,\n",
              "  0.9453868865966797,\n",
              "  1.224395751953125,\n",
              "  0.9033380746841431,\n",
              "  0.8314997553825378,\n",
              "  0.859683632850647,\n",
              "  0.9503604769706726],\n",
              " 'dev_score_history': [0.7414965986394558,\n",
              "  0.7414965986394558,\n",
              "  0.7278911564625851,\n",
              "  0.7233560090702947,\n",
              "  0.7369614512471655,\n",
              "  0.7097505668934241,\n",
              "  0.7551020408163265,\n",
              "  0.764172335600907,\n",
              "  0.7777777777777778,\n",
              "  0.7687074829931972],\n",
              " 'test_score': 0.7397260273972602,\n",
              " 'train_loss_history': [1.1566761973741893,\n",
              "  0.9108730457924508,\n",
              "  0.8433868740056012,\n",
              "  0.769005719068888,\n",
              "  0.699600669983271,\n",
              "  0.6829892888262465,\n",
              "  0.5233222890544582,\n",
              "  0.5122124190266067,\n",
              "  0.4774902181045429,\n",
              "  0.44998007328123657]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EHmdhl6qYoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finetune phase1 result with Bert+Flair embeddings\n",
        "#MACRO_AVG: acc 0.7260273972602739 - f1-score 0.5739219483960016\n",
        "\n",
        "## another run -- finetune phase1 result with Bert+Flair -- 4pm\n",
        "# MACRO_AVG: acc 0.8493150684931506 - f1-score 0.7757725232278944"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXjpL_PZ2kj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# phase1 result with Bert embeddings only . May26 2pm\n",
        "\n",
        "#MACRO_AVG: acc 0.8036529680365296 - f1-score 0.6885983753954866"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2JikhOEZFW",
        "colab_type": "code",
        "outputId": "bc44d24d-5f16-40da-9582-0ddb419c69a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from flair.data import Sentence\n",
        "# create example sentence\n",
        "sentence = Sentence(\"Canada's growth weakens as investment drops, consumers fade\")\n",
        "\n",
        "# predict class and print\n",
        "classifier.predict(sentence)\n",
        "\n",
        "print(sentence.labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1 (0.988)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwSElzt2Qkai",
        "colab_type": "code",
        "outputId": "109bd42d-ddec-4a43-b31f-5c2faa4b5e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#  access the Sentence objects in each split directly\n",
        "print(corpus.test[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"Finnish metal products company Componenta Oyj net profit went slightly down to 25.1 mln euro ( $ 40.2 mln ) for the first half of 2008 from 25.4 mln euro ( $ 40.7 mln ) for the same period of 2007 .\"   [− Tokens: 42  − Sentence-Labels: {'class': [-1 (1.0)]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIrjzZOQQn2F",
        "colab_type": "code",
        "outputId": "61a7d38c-2ede-4f2f-bcc6-b72082e4649f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(corpus.train[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"About Elcoteq Elcoteq SE is a leading electronics manufacturing services ( EMS ) company in the communications technology field .\"   [− Tokens: 20  − Sentence-Labels: {'class': [1 (1.0)]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lWLmyn0RTwT",
        "colab_type": "code",
        "outputId": "39887916-cd82-4ef1-e044-4893585c6e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "#outputs detailed information on the dataset, each split, and the distribution of class labels.\n",
        "stats = corpus.obtain_statistics()\n",
        "print(stats)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"TRAIN\": {\n",
            "        \"dataset\": \"TRAIN\",\n",
            "        \"total_number_of_documents\": 1168,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"1\": 376,\n",
            "            \"-1\": 400,\n",
            "            \"0\": 392\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 36583,\n",
            "            \"min\": 4,\n",
            "            \"max\": 69,\n",
            "            \"avg\": 31.321061643835616\n",
            "        }\n",
            "    },\n",
            "    \"TEST\": {\n",
            "        \"dataset\": \"TEST\",\n",
            "        \"total_number_of_documents\": 146,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"-1\": 53,\n",
            "            \"1\": 55,\n",
            "            \"0\": 38\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 4807,\n",
            "            \"min\": 6,\n",
            "            \"max\": 61,\n",
            "            \"avg\": 32.92465753424658\n",
            "        }\n",
            "    },\n",
            "    \"DEV\": {\n",
            "        \"dataset\": \"DEV\",\n",
            "        \"total_number_of_documents\": 147,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"-1\": 41,\n",
            "            \"0\": 52,\n",
            "            \"1\": 54\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 4753,\n",
            "            \"min\": 9,\n",
            "            \"max\": 65,\n",
            "            \"avg\": 32.333333333333336\n",
            "        }\n",
            "    }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5maM-7gQWqJ",
        "colab_type": "text"
      },
      "source": [
        "### Second Stage (train on hand annotated datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbrXhSRlnCR3",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0E6iEy9UgYP",
        "colab_type": "code",
        "outputId": "3893e2ce-98ff-4cdb-8dfc-080fd15570b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#new_data_folder = './drive/My Drive/capstone/data/second_stage/'\n",
        "new_data_folder = '/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/'\n",
        "new_column_name_map = {5: \"text\", 4: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(new_data_folder,\n",
        "                                         new_column_name_map,\n",
        "                                         skip_header=True, #no header in kaggle data\n",
        "                                         delimiter=',',    # comma separated rows\n",
        "                                         train_file='GDP_train_df_oversampled.csv',\n",
        "                                         dev_file = 'GDP_eva_df.csv',\n",
        "                                         test_file = 'GDP_eva_df.csv'\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 23:46:15,380 Reading data from /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled\n",
            "2020-05-26 23:46:15,381 Train: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/GDP_train_df_oversampled.csv\n",
            "2020-05-26 23:46:15,381 Dev: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/GDP_eva_df.csv\n",
            "2020-05-26 23:46:15,382 Test: /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/GDP_eva_df.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGDir71nHb6",
        "colab_type": "text"
      },
      "source": [
        "#### Second Stage fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWg4fjqNYMKa",
        "colab_type": "code",
        "outputId": "d940ea3d-5541-4197-b028-a04a41899838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# benchmark_embeddings = FlairEmbeddings(data_folder + 'best-model.pt')\n",
        "benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 23:46:15,397 loading file /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotated_sample_for_training/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1XWYH6QZGl",
        "colab_type": "code",
        "outputId": "8204742b-ba65-4341-aa34-b80280c004a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer = ModelTrainer(benchmark_classifier, corpus)\n",
        "trainer.train(new_data_folder, max_epochs=10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 23:46:16,723 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:16,729 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-26 23:46:16,730 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:16,731 Corpus: \"Corpus: 129 train + 26 dev + 26 test sentences\"\n",
            "2020-05-26 23:46:16,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:16,735 Parameters:\n",
            "2020-05-26 23:46:16,736  - learning_rate: \"0.1\"\n",
            "2020-05-26 23:46:16,737  - mini_batch_size: \"32\"\n",
            "2020-05-26 23:46:16,738  - patience: \"3\"\n",
            "2020-05-26 23:46:16,739  - anneal_factor: \"0.5\"\n",
            "2020-05-26 23:46:16,740  - max_epochs: \"10\"\n",
            "2020-05-26 23:46:16,741  - shuffle: \"True\"\n",
            "2020-05-26 23:46:16,742  - train_with_dev: \"False\"\n",
            "2020-05-26 23:46:16,743  - batch_growth_annealing: \"False\"\n",
            "2020-05-26 23:46:16,744 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:16,745 Model training base path: \"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled\"\n",
            "2020-05-26 23:46:16,746 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:16,748 Device: cuda:0\n",
            "2020-05-26 23:46:16,751 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:16,752 Embeddings storage mode: cpu\n",
            "2020-05-26 23:46:16,765 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:46:17,596 epoch 1 - iter 1/5 - loss 2.62053037 - samples/sec: 57.94\n",
            "2020-05-26 23:46:30,707 epoch 1 - iter 2/5 - loss 2.04153234 - samples/sec: 73.62\n",
            "2020-05-26 23:46:42,318 epoch 1 - iter 3/5 - loss 2.05220036 - samples/sec: 82.16\n",
            "2020-05-26 23:46:54,087 epoch 1 - iter 4/5 - loss 1.88513008 - samples/sec: 73.32\n",
            "2020-05-26 23:47:05,200 epoch 1 - iter 5/5 - loss 1.56072257 - samples/sec: 588.88\n",
            "2020-05-26 23:47:16,222 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:47:16,227 EPOCH 1 done: loss 1.5607 - lr 0.1000000\n",
            "2020-05-26 23:47:16,979 DEV : loss 3.112643003463745 - score 0.5128\n",
            "2020-05-26 23:47:17,014 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:47:19,064 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:47:19,872 epoch 2 - iter 1/5 - loss 2.44646835 - samples/sec: 70.80\n",
            "2020-05-26 23:47:32,742 epoch 2 - iter 2/5 - loss 1.62540182 - samples/sec: 59.50\n",
            "2020-05-26 23:47:44,380 epoch 2 - iter 3/5 - loss 1.31533533 - samples/sec: 78.85\n",
            "2020-05-26 23:47:56,114 epoch 2 - iter 4/5 - loss 1.28454842 - samples/sec: 68.71\n",
            "2020-05-26 23:48:07,196 epoch 2 - iter 5/5 - loss 1.17354877 - samples/sec: 649.22\n",
            "2020-05-26 23:48:18,564 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:48:18,568 EPOCH 2 done: loss 1.1735 - lr 0.1000000\n",
            "2020-05-26 23:48:19,296 DEV : loss 2.512822151184082 - score 0.4872\n",
            "2020-05-26 23:48:19,332 BAD EPOCHS (no improvement): 1\n",
            "2020-05-26 23:48:19,338 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:48:20,094 epoch 3 - iter 1/5 - loss 1.49937856 - samples/sec: 64.51\n",
            "2020-05-26 23:48:31,652 epoch 3 - iter 2/5 - loss 1.07817277 - samples/sec: 74.83\n",
            "2020-05-26 23:48:43,509 epoch 3 - iter 3/5 - loss 1.02655373 - samples/sec: 78.59\n",
            "2020-05-26 23:48:54,887 epoch 3 - iter 4/5 - loss 0.98687799 - samples/sec: 71.36\n",
            "2020-05-26 23:49:05,955 epoch 3 - iter 5/5 - loss 0.95797492 - samples/sec: 636.85\n",
            "2020-05-26 23:49:17,354 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:49:17,358 EPOCH 3 done: loss 0.9580 - lr 0.1000000\n",
            "2020-05-26 23:49:18,095 DEV : loss 1.371814489364624 - score 0.641\n",
            "2020-05-26 23:49:18,129 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:49:20,675 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:49:21,470 epoch 4 - iter 1/5 - loss 1.22913241 - samples/sec: 67.31\n",
            "2020-05-26 23:49:34,396 epoch 4 - iter 2/5 - loss 0.98964739 - samples/sec: 79.75\n",
            "2020-05-26 23:49:45,676 epoch 4 - iter 3/5 - loss 0.82060624 - samples/sec: 70.79\n",
            "2020-05-26 23:49:57,254 epoch 4 - iter 4/5 - loss 0.74220292 - samples/sec: 73.62\n",
            "2020-05-26 23:50:08,274 epoch 4 - iter 5/5 - loss 0.65598620 - samples/sec: 601.19\n",
            "2020-05-26 23:50:21,901 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:50:21,902 EPOCH 4 done: loss 0.6560 - lr 0.1000000\n",
            "2020-05-26 23:50:22,633 DEV : loss 1.2588231563568115 - score 0.6923\n",
            "2020-05-26 23:50:22,665 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:50:24,587 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:50:25,397 epoch 5 - iter 1/5 - loss 1.05352008 - samples/sec: 67.00\n",
            "2020-05-26 23:50:38,155 epoch 5 - iter 2/5 - loss 0.90691859 - samples/sec: 73.45\n",
            "2020-05-26 23:50:49,872 epoch 5 - iter 3/5 - loss 0.81393353 - samples/sec: 74.13\n",
            "2020-05-26 23:51:01,443 epoch 5 - iter 4/5 - loss 0.73791416 - samples/sec: 78.62\n",
            "2020-05-26 23:51:13,338 epoch 5 - iter 5/5 - loss 0.64868201 - samples/sec: 469.33\n",
            "2020-05-26 23:51:24,819 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:51:24,821 EPOCH 5 done: loss 0.6487 - lr 0.1000000\n",
            "2020-05-26 23:51:25,564 DEV : loss 1.554335117340088 - score 0.7179\n",
            "2020-05-26 23:51:25,599 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:51:27,581 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:51:28,344 epoch 6 - iter 1/5 - loss 1.47043729 - samples/sec: 64.71\n",
            "2020-05-26 23:51:41,030 epoch 6 - iter 2/5 - loss 0.93723431 - samples/sec: 60.54\n",
            "2020-05-26 23:51:52,657 epoch 6 - iter 3/5 - loss 0.74452020 - samples/sec: 71.40\n",
            "2020-05-26 23:52:03,925 epoch 6 - iter 4/5 - loss 0.65936888 - samples/sec: 72.69\n",
            "2020-05-26 23:52:14,910 epoch 6 - iter 5/5 - loss 0.53303028 - samples/sec: 632.46\n",
            "2020-05-26 23:52:26,075 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:52:26,076 EPOCH 6 done: loss 0.5330 - lr 0.1000000\n",
            "2020-05-26 23:52:26,795 DEV : loss 1.1148098707199097 - score 0.641\n",
            "2020-05-26 23:52:26,828 BAD EPOCHS (no improvement): 1\n",
            "2020-05-26 23:52:26,832 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:52:27,592 epoch 7 - iter 1/5 - loss 0.32710725 - samples/sec: 68.58\n",
            "2020-05-26 23:52:39,201 epoch 7 - iter 2/5 - loss 0.38147442 - samples/sec: 72.92\n",
            "2020-05-26 23:52:51,111 epoch 7 - iter 3/5 - loss 0.32324427 - samples/sec: 47.10\n",
            "2020-05-26 23:53:02,452 epoch 7 - iter 4/5 - loss 0.33383200 - samples/sec: 75.12\n",
            "2020-05-26 23:53:13,730 epoch 7 - iter 5/5 - loss 0.31992963 - samples/sec: 613.56\n",
            "2020-05-26 23:53:24,933 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:53:24,937 EPOCH 7 done: loss 0.3199 - lr 0.1000000\n",
            "2020-05-26 23:53:25,677 DEV : loss 0.8492201566696167 - score 0.7949\n",
            "2020-05-26 23:53:25,712 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-26 23:53:27,682 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:53:28,443 epoch 8 - iter 1/5 - loss 0.19272275 - samples/sec: 65.60\n",
            "2020-05-26 23:53:40,987 epoch 8 - iter 2/5 - loss 0.29377373 - samples/sec: 62.20\n",
            "2020-05-26 23:53:52,767 epoch 8 - iter 3/5 - loss 0.29015033 - samples/sec: 73.78\n",
            "2020-05-26 23:54:04,443 epoch 8 - iter 4/5 - loss 0.28442037 - samples/sec: 71.07\n",
            "2020-05-26 23:54:16,255 epoch 8 - iter 5/5 - loss 0.22764244 - samples/sec: 630.62\n",
            "2020-05-26 23:54:27,662 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:54:27,664 EPOCH 8 done: loss 0.2276 - lr 0.1000000\n",
            "2020-05-26 23:54:28,401 DEV : loss 0.9722784757614136 - score 0.7436\n",
            "2020-05-26 23:54:28,440 BAD EPOCHS (no improvement): 1\n",
            "2020-05-26 23:54:28,446 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:54:29,202 epoch 9 - iter 1/5 - loss 0.26859930 - samples/sec: 66.45\n",
            "2020-05-26 23:54:40,980 epoch 9 - iter 2/5 - loss 0.29736428 - samples/sec: 71.19\n",
            "2020-05-26 23:54:52,917 epoch 9 - iter 3/5 - loss 0.34098740 - samples/sec: 46.67\n",
            "2020-05-26 23:55:04,579 epoch 9 - iter 4/5 - loss 0.37224068 - samples/sec: 78.36\n",
            "2020-05-26 23:55:15,853 epoch 9 - iter 5/5 - loss 0.63775641 - samples/sec: 638.38\n",
            "2020-05-26 23:55:29,057 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:55:29,061 EPOCH 9 done: loss 0.6378 - lr 0.1000000\n",
            "2020-05-26 23:55:29,823 DEV : loss 2.056586980819702 - score 0.641\n",
            "2020-05-26 23:55:29,860 BAD EPOCHS (no improvement): 2\n",
            "2020-05-26 23:55:29,865 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:55:30,647 epoch 10 - iter 1/5 - loss 0.57518721 - samples/sec: 64.06\n",
            "2020-05-26 23:55:43,128 epoch 10 - iter 2/5 - loss 0.38039766 - samples/sec: 71.74\n",
            "2020-05-26 23:55:54,927 epoch 10 - iter 3/5 - loss 0.37467378 - samples/sec: 74.08\n",
            "2020-05-26 23:56:06,393 epoch 10 - iter 4/5 - loss 0.33308147 - samples/sec: 73.68\n",
            "2020-05-26 23:56:19,061 epoch 10 - iter 5/5 - loss 0.26783226 - samples/sec: 622.18\n",
            "2020-05-26 23:56:30,472 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:56:30,474 EPOCH 10 done: loss 0.2678 - lr 0.1000000\n",
            "2020-05-26 23:56:31,199 DEV : loss 0.9651959538459778 - score 0.7949\n",
            "2020-05-26 23:56:31,232 BAD EPOCHS (no improvement): 3\n",
            "2020-05-26 23:56:33,313 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-26 23:56:33,317 Testing using best model ...\n",
            "2020-05-26 23:56:33,324 loading file /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/best-model.pt\n",
            "2020-05-26 23:56:35,097 0.6923076923076923\t0.6923076923076923\t0.6923076923076923\n",
            "2020-05-26 23:56:35,101 \n",
            "MICRO_AVG: acc 0.7948717948717948 - f1-score 0.6923076923076923\n",
            "MACRO_AVG: acc 0.7948717948717948 - f1-score 0.6691358024691358\n",
            "-1         tp: 10 - fp: 5 - fn: 2 - tn: 9 - precision: 0.6667 - recall: 0.8333 - accuracy: 0.7308 - f1-score: 0.7407\n",
            "0          tp: 5 - fp: 2 - fn: 3 - tn: 16 - precision: 0.7143 - recall: 0.6250 - accuracy: 0.8077 - f1-score: 0.6667\n",
            "1          tp: 3 - fp: 1 - fn: 3 - tn: 19 - precision: 0.7500 - recall: 0.5000 - accuracy: 0.8462 - f1-score: 0.6000\n",
            "2020-05-26 23:56:35,104 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [3.112643003463745,\n",
              "  2.512822151184082,\n",
              "  1.371814489364624,\n",
              "  1.2588231563568115,\n",
              "  1.554335117340088,\n",
              "  1.1148098707199097,\n",
              "  0.8492201566696167,\n",
              "  0.9722784757614136,\n",
              "  2.056586980819702,\n",
              "  0.9651959538459778],\n",
              " 'dev_score_history': [0.5128205128205128,\n",
              "  0.48717948717948717,\n",
              "  0.6410256410256411,\n",
              "  0.6923076923076923,\n",
              "  0.717948717948718,\n",
              "  0.6410256410256411,\n",
              "  0.7948717948717948,\n",
              "  0.7435897435897436,\n",
              "  0.6410256410256411,\n",
              "  0.7948717948717948],\n",
              " 'test_score': 0.7948717948717948,\n",
              " 'train_loss_history': [1.56072256565094,\n",
              "  1.1735487699508667,\n",
              "  0.9579749226570129,\n",
              "  0.6559861958026886,\n",
              "  0.6486820101737976,\n",
              "  0.5330302774906158,\n",
              "  0.3199296295642853,\n",
              "  0.2276424437761307,\n",
              "  0.6377564072608948,\n",
              "  0.26783226430416107]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKyyw1CSZFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MACRO_AVG: acc 0.8787878787878788 - f1-score 0.8233082706766918\n",
        "\n",
        "## after fixing oversampling to be on train-only\n",
        "\n",
        "#MACRO_AVG: acc 0.9191919191919192 - f1-score 0.8770653907496012\n",
        "\n",
        "## trying to reproduce -- (by loading best-model.pt from annotated_sample_for_training folder. did it use Bert or Bert+Flair embedding?)\n",
        "#MACRO_AVG: acc 0.7692307692307692 - f1-score 0.6489878542510121\n",
        "\n",
        "#Aaron's score: The f1 score for GDP is 0.69\n",
        "\n",
        "##another run-- worse -- stored in another folder?\n",
        "# MACRO_AVG: acc 0.7435897435897436 - f1-score 0.6001380262249828\n",
        "\n",
        "## another run -- Bert+Flair embedding\n",
        "# MACRO_AVG: acc 0.7692307692307693 - f1-score 0.6313131313131312\n",
        "#another run May26 5pm after setting random state to 42. best so far except errorneour first try\n",
        "# MACRO_AVG: acc 0.7948717948717948 - f1-score 0.6691358024691358"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArPepPU3mIqv",
        "colab_type": "code",
        "outputId": "2386c9aa-2578-4055-8112-ed1f747394e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "## load the 2nd-stage finetuned model:\n",
        "\n",
        "finetuned_classifier = TextClassifier.load(new_data_folder + 'best-model.pt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-26 23:56:35,125 loading file /content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0cksDjXc_rm",
        "colab_type": "code",
        "outputId": "3ceda83d-cd39-4e14-8894-9bdf8c682a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# predict same sentence from above:\n",
        "\n",
        "sentence = Sentence(\"Canada's growth weakens as investment drops, consumers fade\")\n",
        "\n",
        "finetuned_classifier.predict(sentence)\n",
        "\n",
        "print(sentence.labels) ## correct"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1 (0.873)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NECOcOhnh4Se",
        "colab_type": "code",
        "outputId": "4a3615d4-54ac-4b94-97a0-9a5759796ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "dir(sentence.labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__imul__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'append',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'count',\n",
              " 'extend',\n",
              " 'index',\n",
              " 'insert',\n",
              " 'pop',\n",
              " 'remove',\n",
              " 'reverse',\n",
              " 'sort']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwNDl0gziMz5",
        "colab_type": "code",
        "outputId": "41b525f1-5faf-4b49-985d-79b7bf4b3e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "dir(sentence.labels[0])\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_score',\n",
              " '_value',\n",
              " 'score',\n",
              " 'to_dict',\n",
              " 'value']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpR-w18zi9Xr",
        "colab_type": "code",
        "outputId": "5b627a0a-fd73-4527-d42b-6411dba964a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence.labels[0].value"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gl9mmmVi_pG",
        "colab_type": "code",
        "outputId": "d723f069-6b0c-4d57-fddc-a9cc090822b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence.labels[0].score"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8729730844497681"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzPahERUdG4S",
        "colab_type": "code",
        "outputId": "cd35907b-affc-4a0f-fccf-9add9d6f501c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "## error analysis\n",
        "\n",
        "# get gold labels\n",
        "#print(corpus.test[0])\n",
        "print(corpus.test[0])\n",
        "print(corpus.test[0].labels)\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"S & P 500 just hit another record high — and everything ’s flashing Risk On . Optimism over trade deal with China\"   [− Tokens: 23  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (1.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_roihowwdy4I",
        "colab_type": "code",
        "outputId": "ae0525b4-aee2-435b-94e4-a45a1215d7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(corpus.test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMQq2bGTgGOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdp_test_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/GDP_eva_df.csv\",usecols=['title_desc_sent_1','title_desc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf09VixzPb5a",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJqJpE8jgmuv",
        "colab_type": "code",
        "outputId": "3fb5f864-dd2b-4db0-ab4c-f2e12af0a930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "gdp_test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title_desc_sent_1</th>\n",
              "      <th>title_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>S&amp;P 500 just hit another record high — and eve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Forget interest rate decisions. Loonie traders...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>With little to say on coronavirus, is Quebec's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Statistics are great unless they measure the w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>What to watch in China's GDP report: Trade, au...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   title_desc_sent_1                                         title_desc\n",
              "0                  1  S&P 500 just hit another record high — and eve...\n",
              "1                  1  Forget interest rate decisions. Loonie traders...\n",
              "2                  0  With little to say on coronavirus, is Quebec's...\n",
              "3                  0  Statistics are great unless they measure the w...\n",
              "4                 -1  What to watch in China's GDP report: Trade, au..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTdgTHtJhEQY",
        "colab_type": "code",
        "outputId": "95e36c1c-0518-4d90-d9c9-e344356f6e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gdp_test_df['title_desc'].iloc[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'S&P 500 just hit another record high — and everything’s flashing Risk On. Optimism over trade deal with China'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPm2w8npeSsJ",
        "colab_type": "code",
        "outputId": "53848d5b-092e-454b-fc1f-129cb967f7c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "correct = 0\n",
        "\n",
        "for i in range(len(corpus.test)):\n",
        "  print(corpus.test[i])\n",
        "  \n",
        "\n",
        "  #get predictions\n",
        "  #print(gdp_test_df['title_desc'].iloc[i])\n",
        "  sentence = Sentence(gdp_test_df['title_desc'].iloc[i])\n",
        "\n",
        "  finetuned_classifier.predict(sentence)\n",
        "\n",
        "  print(sentence.labels)\n",
        "\n",
        "  #get gold label\n",
        "  print(corpus.test[i].labels)\n",
        "\n",
        "  #calculate correct guesses\n",
        "  if sentence.labels[0].value == corpus.test[i].labels[0].value:\n",
        "    correct += 1\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"S & P 500 just hit another record high — and everything ’s flashing Risk On . Optimism over trade deal with China\"   [− Tokens: 23  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[-1 (0.3915)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Forget interest rate decisions . Loonie traders are banking on immigration to Canada . Flood of immigrants and non-permanent residents to levels not seen in a century a main driver supporting Canada 's economic expansion\"   [− Tokens: 35  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.4258)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"With little to say on coronavirus , is Quebec 's budget ' of the future ' out of sync with the present ? . Finance minister ‚ Äôs budget bets outbreak is more public health than economic problem\"   [− Tokens: 38  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[-1 (0.926)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Statistics are great unless they measure the wrong things : Don Pittis . Statistics Canada looks to Big Data to size up Canadians , but are the numbers biased ?\"   [− Tokens: 30  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.7916)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"What to watch in China 's GDP report : Trade , autos , manufacturing . With China ’s economic expansion expected to slow as trade wars heat up , a closer look at the data may offer a better look at what ’s really happening in the world ’s second-largest economy .\"   [− Tokens: 52  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.7978)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"OPINION | Yes , Alberta 's budget raises taxes . Yes , it cuts AISH . No , it 's not ' austerity. ' . Trevor Tombe cuts through the spin and extracts the facts from ' the most consequential budget in years'\"   [− Tokens: 43  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[-1 (0.5587)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Consumer worries cloud best Canadian output gain in two years . Canada ’s economy recorded a stronger-than-expected rebound in the second quarter as exports recovered , but surprisingly weak consumption and business investment will cast doubts on the expansion ’s sustainability .\"   [− Tokens: 42  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[-1 (0.8999)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Forget about getting fresh trade data — the U.S. shutdown is now hitting Canada . Canada 's statistics agency will stop releasing monthly merchandise trade data indefinitely because of the U.S. government shutdown\"   [− Tokens: 33  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9898)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"China 's growth slides to weakest pace in almost three decades . China ’s economy slowed to the weakest pace since quarterly data began in 1992 amid the ongoing trade standoff with the U.S. , while monthly indicators provided signs that a stabilization is emerging .\"   [− Tokens: 46  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9215)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Rail blockades causing containers to pile up at Canadian ports . Containers sitting idle at major import hubs of Vancouver , Montreal and Halifax\"   [− Tokens: 24  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.8364)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Fed signals patience on rate moves ‘ for some time’ . No strong case to move in either direction\"   [− Tokens: 19  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.5319)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"British immigration overhaul takes aim at ' cheap labour from Europe ' . Changes likely to impact service , farming and health-care industries , among others\"   [− Tokens: 26  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.945)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Trudeau 's big ‚ Äî and underfunded ‚ Äî health care promises . Liberals' pledge to ' fix ' gaps in health care system would cost billions more\"   [− Tokens: 28  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
            "[0 (0.5775)]\n",
            "[0 (1.0)]\n",
            "Sentence: \"Setback to Montreal retail reopening shows rocky path to getting economy running again . The high number of COVID-19 cases in Montreal hospitals caused Premier Francois Legault to postpone store openings by a week\"   [− Tokens: 34  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9888)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Bank of Canada ’s Stephen Poloz gets chance today to put rate cut speculation on ice . Investors now see a strong chance of a cut by the Bank of Canada over the next 12 months\"   [− Tokens: 36  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.8389)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Weak Canadian GDP data opens door for stimulus budget : Scotiabank . Canada ’s sluggish economic data opens the door for Finance Minister Bill Morneau to spend more in his pre-election budget , according to Bank of Nova Scotia .\"   [− Tokens: 40  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[1 (0.4849)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Edmonton economy to improve only slightly in 2020 , city 's chief economist says . Capital city can expect ‚ Äòvery modest ‚ Äô growth , John Rose says\"   [− Tokens: 29  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[0 (0.9786)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Companies look to cash in on out-of-this-world profits in new space economy . Canadian firms among many investing billions in extraterrestrial ventures\"   [− Tokens: 22  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.799)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"Canada 's yield curve inverts the most in 12 years on Trump 's Mexico tariffs threat . Investors are worried the tariffs will derail the revised NAFTA\"   [− Tokens: 27  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9965)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Oil rebound drives Canada 's best two-month GDP gain since 2017 . Canada recorded a second strong month of growth in April , driven by rebounding oil output that is returning the nation ’s economy to a more solid footing .\"   [− Tokens: 41  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[1 (0.79)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"IMF ready to mobilize $ 1 trillion in loans to help countries counter coronavirus outbreak . ' As the virus spreads , the case for a coordinated and synchronized global fiscal stimulus is becoming stronger by the hour '\"   [− Tokens: 39  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.7336)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Wage reductions , more layoffs for City of Winnipeg workers part of worst-case COVID-19 scenarios . City comes up with action plans for 3 possible outcomes of coronavirus pandemic\"   [− Tokens: 29  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9339)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"U.S. second-quarter growth revised up to 4.2 % on software , trade . The U.S. economy expanded in the second quarter at a slightly faster pace than previously estimated on revisions to imports and software spending , bolstering the strongest period of growth since 2014 , according to Commerce Department data released Wednesday .\"   [− Tokens: 54  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
            "[-1 (0.934)]\n",
            "[1 (1.0)]\n",
            "Sentence: \"‘ Crisis like no other’ : IMF warns ‘ Great Lockdown’ recession will be worst in almost 100 years . In a further sign of pessimism , the IMF sketched out three alternative scenarios in which the virus lasted longer than expected , returned in 2021 or both\"   [− Tokens: 48  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.7156)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"U.S. first-quarter GDP growth revised down to 2 % on services . The U.S. economy expanded in the first quarter at a slower pace than previously estimated , reflecting downward revisions to spending on services and to inventory investment , according to Commerce Department data released Thursday .\"   [− Tokens: 48  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.974)]\n",
            "[-1 (1.0)]\n",
            "Sentence: \"Canada 's economy slows even as business investment perks up . Canada ’s economy slowed sharply in the third quarter , as a drop in exports and draw down in business inventories masked a rebound in domestic demand .\"   [− Tokens: 39  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
            "[-1 (0.9931)]\n",
            "[-1 (1.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1s2hW88WyyF",
        "colab_type": "code",
        "outputId": "64b9e946-46e1-48be-d239-0211191d5120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(corpus.test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlCXaV3cX74p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4509f3b0-f73d-48fe-d1f3-7f4c06634aad"
      },
      "source": [
        "correct #after train-only oversampling : 21/26 = 81% accuracy (Bert-only embedding)\n",
        "\n",
        "# Error analysis\n",
        "\n",
        "#reasonable wrongs\n",
        "\n",
        "## tricky one -- econ 'stronger-than-expected\". arguable golden label\n",
        "# Sentence: \"Consumer worries cloud best Canadian output gain in two years . Canada ’s economy recorded a stronger-than-expected rebound in the second quarter as exports recovered , but surprisingly weak consumption and business investment will cast doubts on the expansion ’s sustainability .\"   [− Tokens: 42  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
        "# [1 (0.7199)]\n",
        "# [0 (1.0)]\n",
        "\n",
        "## doubt over golden label... not related to econ but related to interest rate\n",
        "# Sentence: \"Bank of Canada ’s Stephen Poloz gets chance today to put rate cut speculation on ice . Investors now see a strong chance of a cut by the Bank of Canada over the next 12 months\"   [− Tokens: 36  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
        "# [1 (0.8212)]\n",
        "# [-1 (1.0)]\n",
        "\n",
        "## also doubt over golden label. \"improve only slightly\" -- signals lower-than-expectation?\n",
        "# Sentence: \"Edmonton economy to improve only slightly in 2020 , city 's chief economist says . Capital city can expect ‚ Äòvery modest ‚ Äô growth , John Rose says\"   [− Tokens: 29  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
        "# [0 (0.8225)]\n",
        "# [1 (1.0)]\n",
        "\n",
        "#unreasonable wrongs\n",
        "\n",
        "## more related to stock market but 'optimism over trade deal' bodes well for economy. a tricky one? low confidence score\n",
        "# Sentence: \"S & P 500 just hit another record high — and everything ’s flashing Risk On . Optimism over trade deal with China\"   [− Tokens: 23  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
        "# [0 (0.5386)]\n",
        "# [1 (1.0)]\n",
        "\n",
        "## recession, crisis are very negative words. how come?\n",
        "# Sentence: \"‘ Crisis like no other’ : IMF warns ‘ Great Lockdown’ recession will be worst in almost 100 years . In a further sign of pessimism , the IMF sketched out three alternative scenarios in which the virus lasted longer than expected , returned in 2021 or both\"   [− Tokens: 48  − Sentence-Labels: {'class': [-1 (1.0)]}]\n",
        "# [0 (0.9687)]\n",
        "# [-1 (1.0)]\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL29Ak69ebux",
        "colab_type": "code",
        "outputId": "01948e5c-ff37-4795-9028-d06476ba6ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " correct #27/33 = 82% accuracy with Bert+Flair embeddings\n",
        "\n",
        "\n",
        " #before phase2 finetuning, only 66% accuracy with 1500 training examples of less GDP-specific sentiment (vs 77% acc with oversampling Kaggle dataset)\n",
        "\n",
        " #reasonable wrongs\n",
        "\n",
        "## words in negative sense but meaning is neutral\n",
        "# Sentence: \"Why the Canadian economy seems divorced from traditional signals : Don Pittis . With housing and oil off the boil , why has n't the Canadian economy gone into free fall ?\"   [− Tokens: 32  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
        "# [-1 (0.9096)]\n",
        "# [0 (1.0)]\n",
        "\n",
        "## not learning enough that sentiment should be Canada-specific\n",
        "# Sentence: \"Trump is threatening Iran with more sanctions — but what 's left to target ? . Current sanctions have already sent the country spiralling into a deep recession\"   [− Tokens: 28  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
        "# [-1 (0.9762)]\n",
        "# [0 (1.0)]\n",
        "\n",
        "## not learning enough that sentiment should be GDP-specific\n",
        "# Sentence: \"If you thought August was bad , get ready for the worst month for Canadian stocks . In the past 10 years , the TSX has dropped an average 1.5 % in September\"   [− Tokens: 33  − Sentence-Labels: {'class': [0 (1.0)]}]\n",
        "# [-1 (0.5721)]\n",
        "# [0 (1.0)]\n",
        "\n",
        "## not that reasonable wrongs -- all predicted to the opposite extreme... problematic!\n",
        "\n",
        "## 'stabilized' overshadowed by 'slowing' and 'weakest'? -- quite inconfident prediction\n",
        "# Sentence: \"China 's economy grew 6 % in fourth quarter as demand stabilized . China ’s economy stabilized last quarter after slowing to the weakest pace in almost three decades , with the first acceleration in investment since June signaling that a firmer recovery could be underway .\"   [− Tokens: 47  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
        "# [-1 (0.5108)]\n",
        "# [1 (1.0)]\n",
        "\n",
        "## 'fastest growth' vs \"trade tension\"/ \"threat\"\n",
        "# Sentence: \"Oil drives Canada 's fastest economic growth spurt in a year . Canada ’s economy grew at the fastest pace in a year , further evidence of a solid expansion even as trade tensions with the U.S. remain a threat .\"   [− Tokens: 41  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
        "# [-1 (0.6974)]\n",
        "# [1 (1.0)]\n",
        "\n",
        "## 'boom','rosy' vs 'bumpy ride' -- description balanced out but positive headline should have more weight.\n",
        "# Sentence: \"Mining boom to drive economic growth in territories beyond rest of Canada : report . The Conference Board of Canada says outlook rosy for Nunavut and Yukon , but N.W.T. in for a bumpy ride\"   [− Tokens: 35  − Sentence-Labels: {'class': [1 (1.0)]}]\n",
        "# [-1 (0.5803)]\n",
        "# [1 (1.0)]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJLlgMV4jWPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## check accuracy if only count confident predictions(condifence score > 0.7?)\n",
        "confident_total = 0\n",
        "confident_correct = 0\n",
        "\n",
        "for i in range(len(corpus.test)):\n",
        "  #print(corpus.test[i])\n",
        "  \n",
        "\n",
        "  #get predictions\n",
        "  #print(gdp_test_df['title_desc'].iloc[i])\n",
        "  sentence = Sentence(gdp_test_df['title_desc'].iloc[i])\n",
        "\n",
        "  finetuned_classifier.predict(sentence)\n",
        "\n",
        "  #print(sentence.labels)\n",
        "\n",
        "  #get gold label\n",
        "  #print(corpus.test[i].labels)\n",
        "\n",
        "  #calculate correct guesses\n",
        "  if sentence.labels[0].score > 0.7:\n",
        "    confident_total += 1\n",
        "    if sentence.labels[0].value == corpus.test[i].labels[0].value:\n",
        "      confident_correct += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBIUuPVupWc8",
        "colab_type": "code",
        "outputId": "1d2455b6-43e0-4d46-e2fe-247fc86cd883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "confident_correct"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uaIXLevpj-f",
        "colab_type": "code",
        "outputId": "8acf6020-fcef-4c0b-dc0c-0bf01cb5d322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "confident_total"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnQz3cTGpmcS",
        "colab_type": "code",
        "outputId": "ed034bea-cf52-4cd9-f7df-377bcff2401b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "confident_correct/confident_total ## higher accuracy at 0.8, pick only confident predictions for good visualization! also for correlation calculation?"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwP2tQAmfAuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epXHdrsofBWI",
        "colab_type": "text"
      },
      "source": [
        "Make Sentiment Predictions on unannotated data points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5pxAOGLfJhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## get the phase2 finetuned classifier\n",
        "\n",
        "finetuned_classifier = TextClassifier.load(new_data_folder + 'best-model.pt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6u_hAIihxut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a2e84b45-f946-4108-90e3-fc77c5d57b25"
      },
      "source": [
        "unannotated_gdp_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/unannotated_for_predictions/predictions_dataset_GDP_Bloomberg.csv')\n",
        "\n",
        "unannotated_gdp_df.head() # 43 rows"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>title_desc</th>\n",
              "      <th>publishedAt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Bloomberg News</td>\n",
              "      <td>Economic growth stalled in February ahead of v...</td>\n",
              "      <td>2020-04-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>America’s longest economic expansion is over —...</td>\n",
              "      <td>2020-04-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>Once seen as safer than gold, Canadian real es...</td>\n",
              "      <td>2020-04-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Bloomberg News</td>\n",
              "      <td>China won't be able to bail us out this time. ...</td>\n",
              "      <td>2020-04-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>Michael Burry of 'The Big Short' slams coronav...</td>\n",
              "      <td>2020-04-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... publishedAt\n",
              "0           0  ...  2020-04-30\n",
              "1          67  ...  2020-04-29\n",
              "2          69  ...  2020-04-16\n",
              "3           1  ...  2020-04-16\n",
              "4          71  ...  2020-04-07\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb3L3h2KjO4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3a2dd448-1d48-459a-f1ff-8e9bdcd62d98"
      },
      "source": [
        "unannotated_gdp_df['title_desc'].iloc[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Economic growth stalled in February ahead of virus downturn. Canada’s economy slid to a halt in February as the COVID-19 outbreak abroad dampened global growth.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oprg0ogUk58i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "98e94b7f-cb0c-4b60-97bb-bdae3c723f26"
      },
      "source": [
        "## add two new columns to export predictions\n",
        "unannotated_gdp_df['pred_label'] = None\n",
        "unannotated_gdp_df['confidence'] = None\n",
        "unannotated_gdp_df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>title_desc</th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Bloomberg News</td>\n",
              "      <td>Economic growth stalled in February ahead of v...</td>\n",
              "      <td>2020-04-30</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>America’s longest economic expansion is over —...</td>\n",
              "      <td>2020-04-29</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>Once seen as safer than gold, Canadian real es...</td>\n",
              "      <td>2020-04-16</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Bloomberg News</td>\n",
              "      <td>China won't be able to bail us out this time. ...</td>\n",
              "      <td>2020-04-16</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>Michael Burry of 'The Big Short' slams coronav...</td>\n",
              "      <td>2020-04-07</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... confidence\n",
              "0           0  ...       None\n",
              "1          67  ...       None\n",
              "2          69  ...       None\n",
              "3           1  ...       None\n",
              "4          71  ...       None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBZRlQXvkE0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2cce408-b3e6-4ad6-b48c-22bc06a03b70"
      },
      "source": [
        "for i in range(len(unannotated_gdp_df)):\n",
        "\n",
        "  print(unannotated_gdp_df['title_desc'].iloc[i])\n",
        "  sentence = Sentence(unannotated_gdp_df['title_desc'].iloc[i])\n",
        "\n",
        "  finetuned_classifier.predict(sentence)\n",
        "\n",
        "  print(sentence.labels)\n",
        "  print(sentence.labels[0].value)\n",
        "  print(sentence.labels[0].score)\n",
        "\n",
        "  unannotated_gdp_df['pred_label'].iloc[i] = sentence.labels[0].value\n",
        "  unannotated_gdp_df['confidence'].iloc[i] = sentence.labels[0].score\n",
        "\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Economic growth stalled in February ahead of virus downturn. Canada’s economy slid to a halt in February as the COVID-19 outbreak abroad dampened global growth.\n",
            "[-1 (0.9984)]\n",
            "-1\n",
            "0.9983717799186707\n",
            "America’s longest economic expansion is over — and the deepest recession in at least eight decades has begun. GPD falls 4.8%, consumer spending down most since 1980, business investment plummets to 11-year low\n",
            "[-1 (0.9985)]\n",
            "-1\n",
            "0.9984745383262634\n",
            "Once seen as safer than gold, Canadian real estate braces for the 'Great Reckoning'. The real estate industry is now in a state of paralysis with households among the world's most indebted, poorly placed to weather the storm\n",
            "[-1 (0.9846)]\n",
            "-1\n",
            "0.9846396446228027\n",
            "China won't be able to bail us out this time. As bad as China's economic dive is, the slump is even more perilous for the rest of Asia. The region stands to lose its growth patron.\n",
            "[-1 (0.944)]\n",
            "-1\n",
            "0.9439796209335327\n",
            "Michael Burry of 'The Big Short' slams coronavirus lockdowns in tweetstorm. Burry says lockdowns intended to contain the pandemic are worse than the disease itself\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-1 (0.8865)]\n",
            "-1\n",
            "0.8864774107933044\n",
            "Canada ekes out meager growth in January before pandemic. Canada’s economy expanded less than expected in January even before the pandemic caused a virtual shutdown, reinforcing views the first quarter will be weak.\n",
            "[-1 (0.999)]\n",
            "-1\n",
            "0.9990338087081909\n",
            "Canada ekes out meagre growth in January before COVID-19 pandemic shut down economy. Gross domestic product rose 0.1 per cent from December, missing economist estimates for a 0.2 per cent gain\n",
            "[-1 (0.9959)]\n",
            "-1\n",
            "0.9958828687667847\n",
            "White House, senators strike deal on America's biggest rescue package ever — $2 trillion in spending and tax breaks. Spending, including direct payments to individuals, dwarfs the $800 billion Obama stimulus that passed five months after the 2008 financial crash\n",
            "[-1 (0.9959)]\n",
            "-1\n",
            "0.9958914518356323\n",
            "Stock losses deepen after latest U.S. stimulus deal fails. The S&P is down almost 35 per cent from its Feb. 19 record and marked its lowest close of Donald Trump’s presidency\n",
            "[-1 (0.6805)]\n",
            "-1\n",
            "0.6805106997489929\n",
            "Searching for a bottom, Canada's stock managers eye 2016 support. Money managers are gingerly stepping back into the market in the hope that a four-year low is the bottom\n",
            "[-1 (0.9284)]\n",
            "-1\n",
            "0.9283983111381531\n",
            "Canadian recession is likely without fiscal stimulus: Scotiabank. First of the Big Six banks to say so, but believes Ottawa would move quickly\n",
            "[-1 (0.6952)]\n",
            "-1\n",
            "0.6952224373817444\n",
            "Economists start forecasting negative U.S. GDP numbers on virus. Economists are lowering their estimates for second-quarter growth in the U.S. as the coronavirus crimps demand and spending, in some cases penciling in what would be the first contraction since 2014.\n",
            "[-1 (0.9828)]\n",
            "-1\n",
            "0.9827632904052734\n",
            "Oil price plunge stokes fears of a recession in Canada. The oil crisis could be the last straw for the Canadian economy\n",
            "[-1 (0.9845)]\n",
            "-1\n",
            "0.9845286011695862\n",
            "Power-hungry Canada ekes out surprise November GDP growth. Canada’s economy unexpectedly expanded in November as cold weather drove a sharp increase in power usage, though the pick up won’t be enough to salvage what is likely to be a weak end to the year.\n",
            "[-1 (0.9994)]\n",
            "-1\n",
            "0.9994213581085205\n",
            "U.S. seeks biggest change to economic-data releases in decades. The Trump administration plans to restrict the news media’s ability to prepare advance stories on market-moving economic data, according to people familiar with the matter, in a move that could create a logjam in accessing figures such as the monthly jobs report.\n",
            "[-1 (0.9907)]\n",
            "-1\n",
            "0.9907331466674805\n",
            "U.S.-China pact signals global trade progress, but Poloz says it’s uncertain if Canada will benefit. Bank of Canada Governor Stephen Poloz said losses from the trade conflict are likely to be permanent even if growth picks up\n",
            "[-1 (0.9523)]\n",
            "-1\n",
            "0.9523299336433411\n",
            "Consumer spending bump offset by inventories in revised U.S. GDP. Americans’ spending grew by more than previously reported in the third quarter, a change offset by a drag in inventories that left economic growth at a still-healthy but unrevised 2.1 per cent.\n",
            "[-1 (0.911)]\n",
            "-1\n",
            "0.9109734296798706\n",
            "Forget interest rate decisions. Loonie traders are banking on immigration to Canada. Flood of immigrants and non-permanent residents to levels not seen in a century a main driver supporting Canada's economic expansion\n",
            "[1 (0.4258)]\n",
            "1\n",
            "0.42580753564834595\n",
            "Canadian economy faces a prolonged period of sluggish growth. Canada's growth engines are sputtering, from investment and exports to weakening consumption as households cope with high debt levels\n",
            "[-1 (0.9975)]\n",
            "-1\n",
            "0.9974533915519714\n",
            "Baby boomers are thriving on an 'unprecedented' $9-trillion inheritance. Inheritances are part of a dynamic that's widening the wealth gap between generations\n",
            "[0 (0.839)]\n",
            "0\n",
            "0.838999330997467\n",
            "Canada's economy grew at a slower-than-expected pace in August. Canada’s economy grew slower than forecast in August after a lull in the prior month, reinforcing the view the nation’s economy is showing signs of decelerating into the second half of the year.\n",
            "[-1 (0.999)]\n",
            "-1\n",
            "0.9990025162696838\n",
            "Canadian economy stalls in July amid oil and gas slowdown. Canada’s economy unexpectedly stalled in July, a result that could raise concern the nation isn’t immune to the broader global slowdown.\n",
            "[-1 (0.9992)]\n",
            "-1\n",
            "0.9991952776908875\n",
            "Liberal promises will lead to four more years of deficits, each above $20 billion. That’s despite new revenues including 3% tax on digital giants and luxury tax on $100,000 plus cars and boats\n",
            "[1 (0.9324)]\n",
            "1\n",
            "0.9323819875717163\n",
            "Liberal promises would lead to four more years of deficits — each above $20 billion. That’s despite new revenues including 3% tax on digital giants and luxury tax on $100,000 plus cars and boats\n",
            "[1 (0.9349)]\n",
            "1\n",
            "0.9348831176757812\n",
            "GM strike in U.S. could lead to thousands of auto layoffs in Canada. Two of GM Canada's plants — Oshawa and St. Catharines — rely on parts from the U.S. and could see jobs being hit as early as this week\n",
            "[-1 (0.4886)]\n",
            "-1\n",
            "0.4886206388473511\n",
            "It's getting harder for the Bank of Canada to ignore the trade war. In a policy statement due at 10 a.m., economists expect Poloz to underline his unease with the global trade outlook and signal a willingness to cut rates\n",
            "[-1 (0.9933)]\n",
            "-1\n",
            "0.9933028221130371\n",
            "What sewage screening suggests about cannabis use and the black market in Canada. When it comes to cannabis, the proof is in the peeing — and the results are surprising\n",
            "[0 (0.9834)]\n",
            "0\n",
            "0.9833613038063049\n",
            "If you thought August was bad, get ready for the worst month for Canadian stocks. In the past 10 years, the TSX has dropped an average 1.5% in September\n",
            "[-1 (0.982)]\n",
            "-1\n",
            "0.9819709658622742\n",
            "Canadian stocks have lost $97 billion in August, a month in which they normally rise. The S&P/TSX Composite Index slumped more than 2.2 per cent as of Aug. 23, amid worsening trade tensions between the U.S. and China\n",
            "[-1 (0.9468)]\n",
            "-1\n",
            "0.946785032749176\n",
            "Wake up Canada: There's still plenty of news to watch for in the last days of summer. Four of the six major Canadian banks report fiscal third-quarter results, and economic growth figures for Canada are due Friday\n",
            "[-1 (0.8925)]\n",
            "-1\n",
            "0.8925175070762634\n",
            "U.S. growth slows to 2.1% as trade tensions weigh on businesses. U.S. economic growth slowed in the second quarter by less than forecast as consumer spending topped estimates, though weaker business investment and exports underscored the risks spurring the Federal Reserve toward an interest-rate cut next week.\n",
            "[-1 (0.9996)]\n",
            "-1\n",
            "0.9996139407157898\n",
            "China's growth slides to weakest pace in almost three decades. China’s economy slowed to the weakest pace since quarterly data began in 1992 amid the ongoing trade standoff with the U.S., while monthly indicators provided signs that a stabilization is emerging.\n",
            "[-1 (0.9215)]\n",
            "-1\n",
            "0.9214620590209961\n",
            "Oil rebound drives Canada's best two-month GDP gain since 2017. Canada recorded a second strong month of growth in April, driven by rebounding oil output that is returning the nation’s economy to a more solid footing.\n",
            "[1 (0.79)]\n",
            "1\n",
            "0.7899568676948547\n",
            "Three reasons Canadians will feel the pain of the next recession more than Americans. Signs that financial strains are higher here in Canada\n",
            "[-1 (0.7591)]\n",
            "-1\n",
            "0.7590624094009399\n",
            "Canada's yield curve inverts the most in 12 years on Trump's Mexico tariffs threat. Investors are worried the tariffs will derail the revised NAFTA\n",
            "[-1 (0.9965)]\n",
            "-1\n",
            "0.9965071082115173\n",
            "Canadians' insolvency problems might not be as bad as everyone thinks, C.D. Howe says. Released figures don't distinguish between cash flow and balance sheet insolvencies and one is worse than the other\n",
            "[1 (0.8776)]\n",
            "1\n",
            "0.8775954246520996\n",
            "Canadian wholesalers post fastest growth in 17 months in sign economy is bouncing back. Augurs well for GDP numbers next week\n",
            "[-1 (0.8766)]\n",
            "-1\n",
            "0.8765995502471924\n",
            "Fed signals patience on rate moves ‘for some time’. No strong case to move in either direction\n",
            "[0 (0.5319)]\n",
            "0\n",
            "0.5319133400917053\n",
            "Canadian economy shrinks with poor weather adding to oil woes. Canada’s economy returned to its sluggish ways in February, with a drop in output that will reinforce expectations of a slow start to the year.\n",
            "[-1 (0.9994)]\n",
            "-1\n",
            "0.9994372725486755\n",
            "Why are economists so bad at forecasting recessions?. In 1966, four years before securing the Nobel Prize for economics, Paul Samuelson quipped that declines in U.S. stock prices had correctly predicted nine of the last five American recessions. His profession would kill for such accuracy.\n",
            "[0 (0.7756)]\n",
            "0\n",
            "0.7755774855613708\n",
            "Trump is slamming the Fed again, saying stocks should be 5,000-10,000 higher. Policy makers gathered for IMF meeting worry about central bank independence ‘in the most important jurisdiction in the world’\n",
            "[1 (0.7258)]\n",
            "1\n",
            "0.7258031368255615\n",
            "Trump is slamming the Fed again, saying stocks should be 5,000-10,000 higher. Policy makers gathered for IMF meeting worry about central bank independence ‘in the most important jurisdiction in the world’\n",
            "[1 (0.7258)]\n",
            "1\n",
            "0.7258031368255615\n",
            "WTO says tariff war will hammer global trade growth this year. Worst case scenario of a global trade war would lead to a reduction in world GDP in 2022 of about 2%\n",
            "[-1 (0.9943)]\n",
            "-1\n",
            "0.9942964911460876\n",
            "Stephen Poloz confident slowdown is temporary, but low rates still needed. Governor’s speech suggests Bank of Canada rates won’t be moving up or down any time soon\n",
            "[-1 (0.5948)]\n",
            "-1\n",
            "0.5948020219802856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF-Zm5SkkhUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "30703c9f-6d1a-4dff-abf3-f294a9f46bc2"
      },
      "source": [
        "unannotated_gdp_df.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>title_desc</th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Bloomberg News</td>\n",
              "      <td>Economic growth stalled in February ahead of v...</td>\n",
              "      <td>2020-04-30</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.998372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>America’s longest economic expansion is over —...</td>\n",
              "      <td>2020-04-29</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.998475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>Once seen as safer than gold, Canadian real es...</td>\n",
              "      <td>2020-04-16</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.98464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Bloomberg News</td>\n",
              "      <td>China won't be able to bail us out this time. ...</td>\n",
              "      <td>2020-04-16</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.94398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71</td>\n",
              "      <td>{'id': 'fp-bloomberg-news', 'name': 'Bloomberg...</td>\n",
              "      <td>Michael Burry of 'The Big Short' slams coronav...</td>\n",
              "      <td>2020-04-07</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.886477</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... confidence\n",
              "0           0  ...   0.998372\n",
              "1          67  ...   0.998475\n",
              "2          69  ...    0.98464\n",
              "3           1  ...    0.94398\n",
              "4          71  ...   0.886477\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zapa4KOslpfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unannotated_gdp_df.to_csv(\"/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/unannotated_for_predictions/unannotated_GDP_Bloomberg_predictions.csv\",index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWpWCmSuySK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## github master branch commit comment\n",
        "\n",
        "#Predictions on GDP-associated Bloomberg articles\n",
        "\n",
        "#Predictions on un-annotated GDP-associated Bloomberg articles from a model finetuned on BERT+FLAIR embeddings with devset results (MACRO_AVG: acc 0.795 and f1-score 0.669). I think the predicted labels are pretty accurate/reasonable."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}