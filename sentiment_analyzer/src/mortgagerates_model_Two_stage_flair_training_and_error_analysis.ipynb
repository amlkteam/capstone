{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mortgagerates_model_Two_stage_flair_training_and_error_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVY0ZiGk38i_",
        "colab_type": "code",
        "outputId": "8a91b646-f335-43da-8077-e01c79f18d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-y4wy9jnw\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-y4wy9jnw\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.5.10)\n",
            "Requirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: transformers>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2.11.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (5.4.3)\n",
            "Requirement already satisfied, skipping upgrade: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.2.10)\n",
            "Requirement already satisfied, skipping upgrade: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.5.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: langdetect in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (0.13.1)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (0.2.3)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (8.3.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.5) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair==0.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.5) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.13.23)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.10.0->flair==0.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.23 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.16.23)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.23->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.5-cp36-none-any.whl size=152787 sha256=5adcde0a87ca8aa74ed0c719ac3674b61439fe8c87139a0a895da9c25a515a88\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-66hsv8we/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Installing collected packages: flair\n",
            "  Found existing installation: flair 0.5\n",
            "    Uninstalling flair-0.5:\n",
            "      Successfully uninstalled flair-0.5\n",
            "Successfully installed flair-0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flair"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP7gl75D39dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "from flair.data import Corpus\n",
        "import pandas as pd\n",
        "\n",
        "from flair.data import Sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfpsjw8I4Si-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBdZ1L34XwO",
        "colab_type": "code",
        "outputId": "3b1e5842-d4a0-4654-d82c-66d8642eaa36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U90p69Xd5KIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_folder = \"./drive/My Drive/Colab Notebooks/capstone/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkUisuXz7tuK",
        "colab_type": "text"
      },
      "source": [
        "### First Stage (Train on benchmark dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-_Bmpa6gn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = pd.read_csv(data_folder + \"combined_benchmark.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVaSsyAn72AU",
        "colab_type": "code",
        "outputId": "09901316-1d0a-4523-82fa-4eff20c12bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "benchmark = benchmark[['label', 'text']]\n",
        "benchmark.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Why not subscribe to the magazine ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>Tornio Works employs 2,300 of whom more than 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>The move is aimed at boosting sales , cost-eff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>As a result of the merger , the largest profes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>18 March 2010 A leakage in the gypsum pond was...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0                Why not subscribe to the magazine ?\n",
              "1     -1  Tornio Works employs 2,300 of whom more than 1...\n",
              "2      1  The move is aimed at boosting sales , cost-eff...\n",
              "3      0  As a result of the merger , the largest profes...\n",
              "4     -1  18 March 2010 A leakage in the gypsum pond was..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_MVMXq8pvf",
        "colab_type": "text"
      },
      "source": [
        "#### Create train, dev and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11yOd2woIalW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUbbfcSC8ekr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = benchmark.sample(frac=1, random_state=42)\n",
        "\n",
        "\n",
        "benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', sep=',', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', sep=',', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', sep=',', index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewcNTUT7l8tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_df = pd.read_csv(data_folder + \"train.csv\", header = None)\n",
        "# train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7QE3IS69txr",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz-2gNy58wDI",
        "colab_type": "code",
        "outputId": "74e23315-9aa2-42bb-981c-93d1492eedfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_folder), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
        "column_name_map = {1: \"text\", 0: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                         column_name_map,\n",
        "                                         skip_header=False, #no header in kaggle data\n",
        "                                         delimiter=',',    # comma separated rows\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-11 20:46:21,815 Reading data from drive/My Drive/Colab Notebooks/capstone/data\n",
            "2020-06-11 20:46:21,816 Train: drive/My Drive/Colab Notebooks/capstone/data/train.csv\n",
            "2020-06-11 20:46:21,819 Dev: drive/My Drive/Colab Notebooks/capstone/data/dev.csv\n",
            "2020-06-11 20:46:21,819 Test: drive/My Drive/Colab Notebooks/capstone/data/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb1lynSQ98-z",
        "colab_type": "text"
      },
      "source": [
        "#### Create word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u9PFUze9_5y",
        "colab_type": "code",
        "outputId": "92d4a072-7ae0-4f19-eb52-c5a15b790d90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HovCqFfSMjmJ",
        "colab_type": "text"
      },
      "source": [
        "#### First Stage Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wik8DDxm-DKy",
        "colab_type": "code",
        "outputId": "ebdb4ca5-11fb-43a0-a63d-397d10d31a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train(data_folder, max_epochs=10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-11 20:46:32,348 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "100%|██████████| 1314/1314 [00:01<00:00, 807.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-06-11 20:46:34,241 [b'0', b'1', b'-1']\n",
            "2020-06-11 20:46:34,263 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:46:34,267 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-06-11 20:46:34,269 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:46:34,271 Corpus: \"Corpus: 1168 train + 147 dev + 146 test sentences\"\n",
            "2020-06-11 20:46:34,275 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:46:34,276 Parameters:\n",
            "2020-06-11 20:46:34,277  - learning_rate: \"0.1\"\n",
            "2020-06-11 20:46:34,278  - mini_batch_size: \"32\"\n",
            "2020-06-11 20:46:34,279  - patience: \"3\"\n",
            "2020-06-11 20:46:34,280  - anneal_factor: \"0.5\"\n",
            "2020-06-11 20:46:34,281  - max_epochs: \"10\"\n",
            "2020-06-11 20:46:34,282  - shuffle: \"True\"\n",
            "2020-06-11 20:46:34,283  - train_with_dev: \"False\"\n",
            "2020-06-11 20:46:34,284  - batch_growth_annealing: \"False\"\n",
            "2020-06-11 20:46:34,285 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:46:34,288 Model training base path: \"drive/My Drive/Colab Notebooks/capstone/data\"\n",
            "2020-06-11 20:46:34,296 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:46:34,298 Device: cuda:0\n",
            "2020-06-11 20:46:34,299 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:46:34,300 Embeddings storage mode: cpu\n",
            "2020-06-11 20:46:34,307 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-06-11 20:46:35,936 epoch 1 - iter 3/37 - loss 1.72542675 - samples/sec: 71.55\n",
            "2020-06-11 20:46:50,470 epoch 1 - iter 6/37 - loss 1.41298331 - samples/sec: 78.78\n",
            "2020-06-11 20:47:02,726 epoch 1 - iter 9/37 - loss 1.38017842 - samples/sec: 77.69\n",
            "2020-06-11 20:47:15,016 epoch 1 - iter 12/37 - loss 1.36771390 - samples/sec: 75.43\n",
            "2020-06-11 20:47:28,746 epoch 1 - iter 15/37 - loss 1.29182448 - samples/sec: 70.53\n",
            "2020-06-11 20:47:41,178 epoch 1 - iter 18/37 - loss 1.26792369 - samples/sec: 74.70\n",
            "2020-06-11 20:47:53,446 epoch 1 - iter 21/37 - loss 1.27641764 - samples/sec: 76.76\n",
            "2020-06-11 20:48:05,801 epoch 1 - iter 24/37 - loss 1.25897953 - samples/sec: 79.21\n",
            "2020-06-11 20:48:17,829 epoch 1 - iter 27/37 - loss 1.22091764 - samples/sec: 81.07\n",
            "2020-06-11 20:48:30,202 epoch 1 - iter 30/37 - loss 1.20964215 - samples/sec: 79.54\n",
            "2020-06-11 20:48:42,165 epoch 1 - iter 33/37 - loss 1.19802785 - samples/sec: 84.35\n",
            "2020-06-11 20:48:54,258 epoch 1 - iter 36/37 - loss 1.20336205 - samples/sec: 81.35\n",
            "2020-06-11 20:49:05,800 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:49:05,805 EPOCH 1 done: loss 1.2003 - lr 0.1000000\n",
            "2020-06-11 20:49:08,087 DEV : loss 0.8829440474510193 - score 0.7989\n",
            "2020-06-11 20:49:08,236 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-06-11 20:49:10,037 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:49:11,775 epoch 2 - iter 3/37 - loss 0.90887034 - samples/sec: 66.99\n",
            "2020-06-11 20:49:25,016 epoch 2 - iter 6/37 - loss 1.03925870 - samples/sec: 82.34\n",
            "2020-06-11 20:49:37,589 epoch 2 - iter 9/37 - loss 1.02437143 - samples/sec: 81.73\n",
            "2020-06-11 20:49:49,458 epoch 2 - iter 12/37 - loss 0.99591639 - samples/sec: 77.32\n",
            "2020-06-11 20:50:01,693 epoch 2 - iter 15/37 - loss 0.95620933 - samples/sec: 75.88\n",
            "2020-06-11 20:50:13,718 epoch 2 - iter 18/37 - loss 0.94403253 - samples/sec: 78.93\n",
            "2020-06-11 20:50:26,584 epoch 2 - iter 21/37 - loss 0.93855359 - samples/sec: 69.45\n",
            "2020-06-11 20:50:39,209 epoch 2 - iter 24/37 - loss 0.97418526 - samples/sec: 73.19\n",
            "2020-06-11 20:50:51,291 epoch 2 - iter 27/37 - loss 0.95275840 - samples/sec: 84.98\n",
            "2020-06-11 20:51:03,436 epoch 2 - iter 30/37 - loss 0.95092893 - samples/sec: 88.37\n",
            "2020-06-11 20:51:15,855 epoch 2 - iter 33/37 - loss 0.94985231 - samples/sec: 80.65\n",
            "2020-06-11 20:51:28,783 epoch 2 - iter 36/37 - loss 0.94269818 - samples/sec: 74.46\n",
            "2020-06-11 20:51:40,016 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:51:40,018 EPOCH 2 done: loss 0.9350 - lr 0.1000000\n",
            "2020-06-11 20:51:42,351 DEV : loss 0.7203056216239929 - score 0.8622\n",
            "2020-06-11 20:51:42,494 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-06-11 20:51:44,310 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:51:46,008 epoch 3 - iter 3/37 - loss 0.94962273 - samples/sec: 68.40\n",
            "2020-06-11 20:51:59,451 epoch 3 - iter 6/37 - loss 0.94261883 - samples/sec: 79.34\n",
            "2020-06-11 20:52:11,895 epoch 3 - iter 9/37 - loss 0.89741484 - samples/sec: 79.94\n",
            "2020-06-11 20:52:24,413 epoch 3 - iter 12/37 - loss 0.87437736 - samples/sec: 73.85\n",
            "2020-06-11 20:52:37,697 epoch 3 - iter 15/37 - loss 0.86046940 - samples/sec: 78.70\n",
            "2020-06-11 20:52:50,524 epoch 3 - iter 18/37 - loss 0.86075116 - samples/sec: 65.39\n",
            "2020-06-11 20:53:03,019 epoch 3 - iter 21/37 - loss 0.84112248 - samples/sec: 81.52\n",
            "2020-06-11 20:53:15,511 epoch 3 - iter 24/37 - loss 0.83289729 - samples/sec: 75.97\n",
            "2020-06-11 20:53:28,120 epoch 3 - iter 27/37 - loss 0.81732231 - samples/sec: 77.46\n",
            "2020-06-11 20:53:40,445 epoch 3 - iter 30/37 - loss 0.80730750 - samples/sec: 75.61\n",
            "2020-06-11 20:53:52,953 epoch 3 - iter 33/37 - loss 0.82057300 - samples/sec: 81.06\n",
            "2020-06-11 20:54:05,169 epoch 3 - iter 36/37 - loss 0.82138568 - samples/sec: 80.02\n",
            "2020-06-11 20:54:16,745 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:54:16,749 EPOCH 3 done: loss 0.8268 - lr 0.1000000\n",
            "2020-06-11 20:54:19,110 DEV : loss 0.9014942049980164 - score 0.8077\n",
            "2020-06-11 20:54:19,249 BAD EPOCHS (no improvement): 1\n",
            "2020-06-11 20:54:19,253 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:54:21,099 epoch 4 - iter 3/37 - loss 1.07435352 - samples/sec: 74.63\n",
            "2020-06-11 20:54:33,675 epoch 4 - iter 6/37 - loss 0.93609938 - samples/sec: 73.83\n",
            "2020-06-11 20:54:47,951 epoch 4 - iter 9/37 - loss 0.83967798 - samples/sec: 77.49\n",
            "2020-06-11 20:55:00,099 epoch 4 - iter 12/37 - loss 0.77731113 - samples/sec: 78.28\n",
            "2020-06-11 20:55:12,450 epoch 4 - iter 15/37 - loss 0.76245692 - samples/sec: 68.44\n",
            "2020-06-11 20:55:24,703 epoch 4 - iter 18/37 - loss 0.76792856 - samples/sec: 79.89\n",
            "2020-06-11 20:55:37,160 epoch 4 - iter 21/37 - loss 0.79436934 - samples/sec: 78.91\n",
            "2020-06-11 20:55:49,429 epoch 4 - iter 24/37 - loss 0.78106242 - samples/sec: 76.99\n",
            "2020-06-11 20:56:01,912 epoch 4 - iter 27/37 - loss 0.80083378 - samples/sec: 81.82\n",
            "2020-06-11 20:56:14,165 epoch 4 - iter 30/37 - loss 0.79871442 - samples/sec: 81.90\n",
            "2020-06-11 20:56:26,288 epoch 4 - iter 33/37 - loss 0.78262931 - samples/sec: 87.37\n",
            "2020-06-11 20:56:38,327 epoch 4 - iter 36/37 - loss 0.79967453 - samples/sec: 78.88\n",
            "2020-06-11 20:56:49,665 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:56:49,666 EPOCH 4 done: loss 0.8040 - lr 0.1000000\n",
            "2020-06-11 20:56:52,311 DEV : loss 0.7286069393157959 - score 0.8522\n",
            "2020-06-11 20:56:52,456 BAD EPOCHS (no improvement): 2\n",
            "2020-06-11 20:56:52,460 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:56:54,084 epoch 5 - iter 3/37 - loss 0.79442519 - samples/sec: 76.79\n",
            "2020-06-11 20:57:06,372 epoch 5 - iter 6/37 - loss 0.73214732 - samples/sec: 80.37\n",
            "2020-06-11 20:57:18,461 epoch 5 - iter 9/37 - loss 0.68696768 - samples/sec: 84.20\n",
            "2020-06-11 20:57:30,572 epoch 5 - iter 12/37 - loss 0.67062658 - samples/sec: 81.02\n",
            "2020-06-11 20:57:43,635 epoch 5 - iter 15/37 - loss 0.76013670 - samples/sec: 75.82\n",
            "2020-06-11 20:57:55,920 epoch 5 - iter 18/37 - loss 0.74021924 - samples/sec: 75.04\n",
            "2020-06-11 20:58:08,092 epoch 5 - iter 21/37 - loss 0.78182386 - samples/sec: 74.67\n",
            "2020-06-11 20:58:20,735 epoch 5 - iter 24/37 - loss 0.77038178 - samples/sec: 67.00\n",
            "2020-06-11 20:58:33,009 epoch 5 - iter 27/37 - loss 0.76175796 - samples/sec: 82.47\n",
            "2020-06-11 20:58:45,285 epoch 5 - iter 30/37 - loss 0.75730461 - samples/sec: 76.62\n",
            "2020-06-11 20:58:57,397 epoch 5 - iter 33/37 - loss 0.74117300 - samples/sec: 84.02\n",
            "2020-06-11 20:59:09,385 epoch 5 - iter 36/37 - loss 0.74730363 - samples/sec: 88.94\n",
            "2020-06-11 20:59:20,771 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:59:20,772 EPOCH 5 done: loss 0.7501 - lr 0.1000000\n",
            "2020-06-11 20:59:23,377 DEV : loss 0.8807229995727539 - score 0.8099\n",
            "2020-06-11 20:59:23,514 BAD EPOCHS (no improvement): 3\n",
            "2020-06-11 20:59:23,519 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 20:59:25,225 epoch 6 - iter 3/37 - loss 0.77824561 - samples/sec: 69.34\n",
            "2020-06-11 20:59:37,540 epoch 6 - iter 6/37 - loss 0.67224420 - samples/sec: 81.13\n",
            "2020-06-11 20:59:50,390 epoch 6 - iter 9/37 - loss 0.69959146 - samples/sec: 79.57\n",
            "2020-06-11 21:00:04,131 epoch 6 - iter 12/37 - loss 0.66642883 - samples/sec: 77.23\n",
            "2020-06-11 21:00:16,350 epoch 6 - iter 15/37 - loss 0.66038410 - samples/sec: 80.36\n",
            "2020-06-11 21:00:28,664 epoch 6 - iter 18/37 - loss 0.64657450 - samples/sec: 71.19\n",
            "2020-06-11 21:00:40,585 epoch 6 - iter 21/37 - loss 0.65278919 - samples/sec: 83.61\n",
            "2020-06-11 21:00:53,025 epoch 6 - iter 24/37 - loss 0.69217741 - samples/sec: 68.28\n",
            "2020-06-11 21:01:05,049 epoch 6 - iter 27/37 - loss 0.70123459 - samples/sec: 81.21\n",
            "2020-06-11 21:01:17,191 epoch 6 - iter 30/37 - loss 0.68366654 - samples/sec: 79.27\n",
            "2020-06-11 21:01:29,497 epoch 6 - iter 33/37 - loss 0.70351152 - samples/sec: 71.96\n",
            "2020-06-11 21:01:41,724 epoch 6 - iter 36/37 - loss 0.70261227 - samples/sec: 73.07\n",
            "2020-06-11 21:01:53,026 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:01:53,030 EPOCH 6 done: loss 0.6970 - lr 0.1000000\n",
            "2020-06-11 21:01:55,369 DEV : loss 0.6408273577690125 - score 0.8673\n",
            "2020-06-11 21:01:55,512 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-06-11 21:01:57,313 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:01:58,986 epoch 7 - iter 3/37 - loss 0.70013468 - samples/sec: 76.72\n",
            "2020-06-11 21:02:12,550 epoch 7 - iter 6/37 - loss 0.68761887 - samples/sec: 76.37\n",
            "2020-06-11 21:02:24,819 epoch 7 - iter 9/37 - loss 0.64462974 - samples/sec: 78.74\n",
            "2020-06-11 21:02:37,556 epoch 7 - iter 12/37 - loss 0.63525976 - samples/sec: 79.08\n",
            "2020-06-11 21:02:49,838 epoch 7 - iter 15/37 - loss 0.68096458 - samples/sec: 82.22\n",
            "2020-06-11 21:03:02,142 epoch 7 - iter 18/37 - loss 0.71077445 - samples/sec: 74.87\n",
            "2020-06-11 21:03:14,709 epoch 7 - iter 21/37 - loss 0.68366236 - samples/sec: 73.87\n",
            "2020-06-11 21:03:27,044 epoch 7 - iter 24/37 - loss 0.66254595 - samples/sec: 78.75\n",
            "2020-06-11 21:03:39,278 epoch 7 - iter 27/37 - loss 0.67542110 - samples/sec: 80.84\n",
            "2020-06-11 21:03:51,646 epoch 7 - iter 30/37 - loss 0.70931425 - samples/sec: 71.77\n",
            "2020-06-11 21:04:03,861 epoch 7 - iter 33/37 - loss 0.71582474 - samples/sec: 80.93\n",
            "2020-06-11 21:04:15,791 epoch 7 - iter 36/37 - loss 0.70840377 - samples/sec: 82.85\n",
            "2020-06-11 21:04:27,331 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:04:27,332 EPOCH 7 done: loss 0.7145 - lr 0.1000000\n",
            "2020-06-11 21:04:29,778 DEV : loss 0.7970978617668152 - score 0.8497\n",
            "2020-06-11 21:04:29,915 BAD EPOCHS (no improvement): 1\n",
            "2020-06-11 21:04:29,920 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:04:31,786 epoch 8 - iter 3/37 - loss 0.64629859 - samples/sec: 72.68\n",
            "2020-06-11 21:04:43,921 epoch 8 - iter 6/37 - loss 0.74689816 - samples/sec: 75.56\n",
            "2020-06-11 21:04:56,220 epoch 8 - iter 9/37 - loss 0.71584784 - samples/sec: 82.30\n",
            "2020-06-11 21:05:10,921 epoch 8 - iter 12/37 - loss 0.68329914 - samples/sec: 83.92\n",
            "2020-06-11 21:05:23,295 epoch 8 - iter 15/37 - loss 0.66015652 - samples/sec: 71.06\n",
            "2020-06-11 21:05:35,821 epoch 8 - iter 18/37 - loss 0.64321664 - samples/sec: 74.41\n",
            "2020-06-11 21:05:48,668 epoch 8 - iter 21/37 - loss 0.61538849 - samples/sec: 73.66\n",
            "2020-06-11 21:06:00,998 epoch 8 - iter 24/37 - loss 0.64332861 - samples/sec: 76.17\n",
            "2020-06-11 21:06:13,529 epoch 8 - iter 27/37 - loss 0.63801726 - samples/sec: 81.08\n",
            "2020-06-11 21:06:26,039 epoch 8 - iter 30/37 - loss 0.62611323 - samples/sec: 81.44\n",
            "2020-06-11 21:06:38,475 epoch 8 - iter 33/37 - loss 0.62596131 - samples/sec: 79.71\n",
            "2020-06-11 21:06:50,936 epoch 8 - iter 36/37 - loss 0.61147656 - samples/sec: 79.69\n",
            "2020-06-11 21:07:02,542 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:07:02,543 EPOCH 8 done: loss 0.6085 - lr 0.1000000\n",
            "2020-06-11 21:07:05,172 DEV : loss 0.6934536695480347 - score 0.8647\n",
            "2020-06-11 21:07:05,309 BAD EPOCHS (no improvement): 2\n",
            "2020-06-11 21:07:05,314 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:07:06,990 epoch 9 - iter 3/37 - loss 0.54321440 - samples/sec: 72.39\n",
            "2020-06-11 21:07:19,304 epoch 9 - iter 6/37 - loss 0.71510090 - samples/sec: 74.99\n",
            "2020-06-11 21:07:31,858 epoch 9 - iter 9/37 - loss 0.69588967 - samples/sec: 78.17\n",
            "2020-06-11 21:07:45,370 epoch 9 - iter 12/37 - loss 0.64923282 - samples/sec: 66.27\n",
            "2020-06-11 21:07:57,817 epoch 9 - iter 15/37 - loss 0.61717195 - samples/sec: 73.42\n",
            "2020-06-11 21:08:09,924 epoch 9 - iter 18/37 - loss 0.58611671 - samples/sec: 83.20\n",
            "2020-06-11 21:08:22,267 epoch 9 - iter 21/37 - loss 0.62714600 - samples/sec: 67.03\n",
            "2020-06-11 21:08:34,551 epoch 9 - iter 24/37 - loss 0.66657718 - samples/sec: 79.36\n",
            "2020-06-11 21:08:46,407 epoch 9 - iter 27/37 - loss 0.64566728 - samples/sec: 84.75\n",
            "2020-06-11 21:08:58,616 epoch 9 - iter 30/37 - loss 0.63745926 - samples/sec: 81.15\n",
            "2020-06-11 21:09:11,038 epoch 9 - iter 33/37 - loss 0.65486001 - samples/sec: 80.69\n",
            "2020-06-11 21:09:23,200 epoch 9 - iter 36/37 - loss 0.65429498 - samples/sec: 76.71\n",
            "2020-06-11 21:09:34,958 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:09:34,961 EPOCH 9 done: loss 0.6642 - lr 0.1000000\n",
            "2020-06-11 21:09:38,727 DEV : loss 0.8263334631919861 - score 0.8448\n",
            "2020-06-11 21:09:38,866 BAD EPOCHS (no improvement): 3\n",
            "2020-06-11 21:09:38,871 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:09:40,582 epoch 10 - iter 3/37 - loss 0.77258299 - samples/sec: 71.02\n",
            "2020-06-11 21:09:52,919 epoch 10 - iter 6/37 - loss 0.64141030 - samples/sec: 74.59\n",
            "2020-06-11 21:10:05,373 epoch 10 - iter 9/37 - loss 0.59684251 - samples/sec: 66.85\n",
            "2020-06-11 21:10:20,301 epoch 10 - iter 12/37 - loss 0.61461889 - samples/sec: 75.83\n",
            "2020-06-11 21:10:32,534 epoch 10 - iter 15/37 - loss 0.62057803 - samples/sec: 80.78\n",
            "2020-06-11 21:10:44,948 epoch 10 - iter 18/37 - loss 0.60317676 - samples/sec: 74.46\n",
            "2020-06-11 21:10:57,162 epoch 10 - iter 21/37 - loss 0.60640293 - samples/sec: 80.66\n",
            "2020-06-11 21:11:09,243 epoch 10 - iter 24/37 - loss 0.58003941 - samples/sec: 82.81\n",
            "2020-06-11 21:11:21,573 epoch 10 - iter 27/37 - loss 0.57638815 - samples/sec: 76.20\n",
            "2020-06-11 21:11:33,837 epoch 10 - iter 30/37 - loss 0.59974796 - samples/sec: 76.92\n",
            "2020-06-11 21:11:46,253 epoch 10 - iter 33/37 - loss 0.60300414 - samples/sec: 81.15\n",
            "2020-06-11 21:11:58,301 epoch 10 - iter 36/37 - loss 0.59519816 - samples/sec: 94.14\n",
            "2020-06-11 21:12:09,710 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:12:09,711 EPOCH 10 done: loss 0.5949 - lr 0.1000000\n",
            "2020-06-11 21:12:12,064 DEV : loss 0.8744912147521973 - score 0.8497\n",
            "Epoch    10: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-06-11 21:12:12,201 BAD EPOCHS (no improvement): 4\n",
            "2020-06-11 21:12:13,878 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:12:13,883 Testing using best model ...\n",
            "2020-06-11 21:12:13,888 loading file drive/My Drive/Colab Notebooks/capstone/data/best-model.pt\n",
            "2020-06-11 21:12:16,978 \t0.6301\n",
            "2020-06-11 21:12:16,983 \n",
            "Results:\n",
            "- F-score (micro) 0.8439\n",
            "- F-score (macro) 0.8224\n",
            "- Accuracy 0.6301\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.5556    0.7143        45\n",
            "           1     1.0000    0.7975    0.8873        79\n",
            "          -1     1.0000    0.7632    0.8657        76\n",
            "\n",
            "   micro avg     1.0000    0.7300    0.8439       200\n",
            "   macro avg     1.0000    0.7054    0.8224       200\n",
            "weighted avg     1.0000    0.7300    0.8402       200\n",
            " samples avg     1.0000    0.8151    0.8767       200\n",
            "\n",
            "2020-06-11 21:12:16,986 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.8829440474510193,\n",
              "  0.7203056216239929,\n",
              "  0.9014942049980164,\n",
              "  0.7286069393157959,\n",
              "  0.8807229995727539,\n",
              "  0.6408273577690125,\n",
              "  0.7970978617668152,\n",
              "  0.6934536695480347,\n",
              "  0.8263334631919861,\n",
              "  0.8744912147521973],\n",
              " 'dev_score_history': [0.7989,\n",
              "  0.8622,\n",
              "  0.8077,\n",
              "  0.8522,\n",
              "  0.8099,\n",
              "  0.8673,\n",
              "  0.8497,\n",
              "  0.8647,\n",
              "  0.8448,\n",
              "  0.8497],\n",
              " 'test_score': 0.8439,\n",
              " 'train_loss_history': [1.2002636323104034,\n",
              "  0.9350489458522281,\n",
              "  0.8268443056055017,\n",
              "  0.8040031033593256,\n",
              "  0.7500786281920768,\n",
              "  0.6970284959754428,\n",
              "  0.7145128443434432,\n",
              "  0.6085004999830916,\n",
              "  0.664192912546364,\n",
              "  0.5949043977904964]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5maM-7gQWqJ",
        "colab_type": "text"
      },
      "source": [
        "### Second Stage (train on hand annotated datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbrXhSRlnCR3",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0E6iEy9UgYP",
        "colab_type": "code",
        "outputId": "72ba36ad-14b8-4a9c-eca8-8346ea90c312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "new_data_folder = \"./drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/\"\n",
        "new_column_name_map = {5: \"text\", 4: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(new_data_folder,\n",
        "                                         new_column_name_map,\n",
        "                                         skip_header=True, #yes header in \n",
        "                                         delimiter=',',    # comma separated rows\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-11 21:14:19,317 Reading data from drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled\n",
            "2020-06-11 21:14:19,318 Train: drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/train.csv\n",
            "2020-06-11 21:14:19,319 Dev: drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/dev.csv\n",
            "2020-06-11 21:14:19,319 Test: drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGDir71nHb6",
        "colab_type": "text"
      },
      "source": [
        "#### Second Stage fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWg4fjqNYMKa",
        "colab_type": "code",
        "outputId": "4ac06b61-e3fa-4179-f93a-63dd651aa628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-11 21:14:23,960 loading file ./drive/My Drive/Colab Notebooks/capstone/data/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1XWYH6QZGl",
        "colab_type": "code",
        "outputId": "a6634374-a9f2-4d89-8b8f-b583ca7ffd4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer = ModelTrainer(benchmark_classifier, corpus)\n",
        "trainer.train(new_data_folder, max_epochs=10)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-11 21:14:39,141 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:14:39,146 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-06-11 21:14:39,147 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:14:39,147 Corpus: \"Corpus: 165 train + 25 dev + 25 test sentences\"\n",
            "2020-06-11 21:14:39,148 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:14:39,149 Parameters:\n",
            "2020-06-11 21:14:39,150  - learning_rate: \"0.1\"\n",
            "2020-06-11 21:14:39,150  - mini_batch_size: \"32\"\n",
            "2020-06-11 21:14:39,151  - patience: \"3\"\n",
            "2020-06-11 21:14:39,152  - anneal_factor: \"0.5\"\n",
            "2020-06-11 21:14:39,153  - max_epochs: \"10\"\n",
            "2020-06-11 21:14:39,154  - shuffle: \"True\"\n",
            "2020-06-11 21:14:39,157  - train_with_dev: \"False\"\n",
            "2020-06-11 21:14:39,158  - batch_growth_annealing: \"False\"\n",
            "2020-06-11 21:14:39,159 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:14:39,161 Model training base path: \"drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled\"\n",
            "2020-06-11 21:14:39,162 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:14:39,163 Device: cuda:0\n",
            "2020-06-11 21:14:39,165 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:14:39,167 Embeddings storage mode: cpu\n",
            "2020-06-11 21:14:39,180 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:14:39,931 epoch 1 - iter 1/6 - loss 1.66114259 - samples/sec: 66.26\n",
            "2020-06-11 21:14:51,441 epoch 1 - iter 2/6 - loss 1.64794064 - samples/sec: 78.58\n",
            "2020-06-11 21:15:02,968 epoch 1 - iter 3/6 - loss 1.46415627 - samples/sec: 86.18\n",
            "2020-06-11 21:15:14,562 epoch 1 - iter 4/6 - loss 1.34592184 - samples/sec: 88.23\n",
            "2020-06-11 21:15:27,928 epoch 1 - iter 5/6 - loss 1.56332338 - samples/sec: 73.75\n",
            "2020-06-11 21:15:39,763 epoch 1 - iter 6/6 - loss 1.52510260 - samples/sec: 288.87\n",
            "2020-06-11 21:15:51,369 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:15:51,371 EPOCH 1 done: loss 1.5251 - lr 0.1000000\n",
            "2020-06-11 21:15:52,074 DEV : loss 1.3760476112365723 - score 0.6944\n",
            "2020-06-11 21:15:52,110 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "saving best model\n",
            "2020-06-11 21:15:53,968 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:15:54,846 epoch 2 - iter 1/6 - loss 1.21896505 - samples/sec: 63.88\n",
            "2020-06-11 21:16:08,170 epoch 2 - iter 2/6 - loss 1.34578860 - samples/sec: 80.09\n",
            "2020-06-11 21:16:19,948 epoch 2 - iter 3/6 - loss 1.22393487 - samples/sec: 73.39\n",
            "2020-06-11 21:16:31,931 epoch 2 - iter 4/6 - loss 1.12664030 - samples/sec: 86.30\n",
            "2020-06-11 21:16:43,396 epoch 2 - iter 5/6 - loss 1.10699414 - samples/sec: 78.26\n",
            "2020-06-11 21:16:54,503 epoch 2 - iter 6/6 - loss 1.14799018 - samples/sec: 331.43\n",
            "2020-06-11 21:17:05,857 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:17:05,858 EPOCH 2 done: loss 1.1480 - lr 0.1000000\n",
            "2020-06-11 21:17:06,526 DEV : loss 1.2450100183486938 - score 0.7353\n",
            "2020-06-11 21:17:06,559 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-06-11 21:17:08,425 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:17:09,197 epoch 3 - iter 1/6 - loss 0.76304138 - samples/sec: 74.78\n",
            "2020-06-11 21:17:21,402 epoch 3 - iter 2/6 - loss 0.77165547 - samples/sec: 67.01\n",
            "2020-06-11 21:17:33,183 epoch 3 - iter 3/6 - loss 0.75218250 - samples/sec: 51.65\n",
            "2020-06-11 21:17:44,609 epoch 3 - iter 4/6 - loss 0.71256170 - samples/sec: 80.16\n",
            "2020-06-11 21:17:56,696 epoch 3 - iter 5/6 - loss 0.74335973 - samples/sec: 83.29\n",
            "2020-06-11 21:18:07,710 epoch 3 - iter 6/6 - loss 0.72699074 - samples/sec: 320.36\n",
            "2020-06-11 21:18:19,105 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:18:19,109 EPOCH 3 done: loss 0.7270 - lr 0.1000000\n",
            "2020-06-11 21:18:19,766 DEV : loss 1.7610528469085693 - score 0.7692\n",
            "2020-06-11 21:18:19,798 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-06-11 21:18:21,596 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:18:22,385 epoch 4 - iter 1/6 - loss 1.37061787 - samples/sec: 64.62\n",
            "2020-06-11 21:18:34,601 epoch 4 - iter 2/6 - loss 1.19666708 - samples/sec: 66.37\n",
            "2020-06-11 21:18:46,520 epoch 4 - iter 3/6 - loss 0.99556935 - samples/sec: 80.33\n",
            "2020-06-11 21:18:57,880 epoch 4 - iter 4/6 - loss 0.95007619 - samples/sec: 85.60\n",
            "2020-06-11 21:19:09,289 epoch 4 - iter 5/6 - loss 0.96903052 - samples/sec: 84.29\n",
            "2020-06-11 21:19:20,413 epoch 4 - iter 6/6 - loss 0.91344334 - samples/sec: 325.43\n",
            "2020-06-11 21:19:31,564 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:19:31,565 EPOCH 4 done: loss 0.9134 - lr 0.1000000\n",
            "2020-06-11 21:19:32,198 DEV : loss 0.8523023128509521 - score 0.8333\n",
            "2020-06-11 21:19:32,230 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-06-11 21:19:34,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:19:34,957 epoch 5 - iter 1/6 - loss 0.73015058 - samples/sec: 68.74\n",
            "2020-06-11 21:19:47,597 epoch 5 - iter 2/6 - loss 0.69207579 - samples/sec: 67.37\n",
            "2020-06-11 21:19:59,011 epoch 5 - iter 3/6 - loss 0.65025564 - samples/sec: 81.85\n",
            "2020-06-11 21:20:10,677 epoch 5 - iter 4/6 - loss 0.62862583 - samples/sec: 88.70\n",
            "2020-06-11 21:20:22,074 epoch 5 - iter 5/6 - loss 0.62731051 - samples/sec: 83.92\n",
            "2020-06-11 21:20:34,256 epoch 5 - iter 6/6 - loss 0.56616988 - samples/sec: 269.88\n",
            "2020-06-11 21:20:46,697 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:20:46,700 EPOCH 5 done: loss 0.5662 - lr 0.1000000\n",
            "2020-06-11 21:20:47,317 DEV : loss 0.8766542077064514 - score 0.8621\n",
            "2020-06-11 21:20:47,355 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-06-11 21:20:49,237 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:20:49,968 epoch 6 - iter 1/6 - loss 0.34430003 - samples/sec: 75.29\n",
            "2020-06-11 21:21:02,868 epoch 6 - iter 2/6 - loss 0.40442893 - samples/sec: 69.12\n",
            "2020-06-11 21:21:14,445 epoch 6 - iter 3/6 - loss 0.48489275 - samples/sec: 74.08\n",
            "2020-06-11 21:21:26,004 epoch 6 - iter 4/6 - loss 0.52983177 - samples/sec: 82.74\n",
            "2020-06-11 21:21:37,350 epoch 6 - iter 5/6 - loss 0.56753498 - samples/sec: 79.89\n",
            "2020-06-11 21:21:48,474 epoch 6 - iter 6/6 - loss 0.67567522 - samples/sec: 290.88\n",
            "2020-06-11 21:21:59,600 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:21:59,603 EPOCH 6 done: loss 0.6757 - lr 0.1000000\n",
            "2020-06-11 21:22:00,208 DEV : loss 0.8038918375968933 - score 0.8772\n",
            "2020-06-11 21:22:00,241 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-06-11 21:22:02,104 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:22:02,863 epoch 7 - iter 1/6 - loss 0.37119338 - samples/sec: 70.38\n",
            "2020-06-11 21:22:17,124 epoch 7 - iter 2/6 - loss 0.32148938 - samples/sec: 85.09\n",
            "2020-06-11 21:22:28,681 epoch 7 - iter 3/6 - loss 0.33227577 - samples/sec: 76.53\n",
            "2020-06-11 21:22:39,780 epoch 7 - iter 4/6 - loss 0.39644854 - samples/sec: 83.14\n",
            "2020-06-11 21:22:51,305 epoch 7 - iter 5/6 - loss 0.51318510 - samples/sec: 80.59\n",
            "2020-06-11 21:23:02,544 epoch 7 - iter 6/6 - loss 0.46617567 - samples/sec: 382.27\n",
            "2020-06-11 21:23:13,571 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:23:13,574 EPOCH 7 done: loss 0.4662 - lr 0.1000000\n",
            "2020-06-11 21:23:14,460 DEV : loss 1.3781912326812744 - score 0.7692\n",
            "2020-06-11 21:23:14,489 BAD EPOCHS (no improvement): 1\n",
            "2020-06-11 21:23:14,492 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:23:15,229 epoch 8 - iter 1/6 - loss 0.42702609 - samples/sec: 61.40\n",
            "2020-06-11 21:23:26,520 epoch 8 - iter 2/6 - loss 0.64625028 - samples/sec: 91.41\n",
            "2020-06-11 21:23:38,117 epoch 8 - iter 3/6 - loss 0.61515917 - samples/sec: 83.98\n",
            "2020-06-11 21:23:49,593 epoch 8 - iter 4/6 - loss 0.51515457 - samples/sec: 79.78\n",
            "2020-06-11 21:24:01,211 epoch 8 - iter 5/6 - loss 0.46891279 - samples/sec: 81.86\n",
            "2020-06-11 21:24:12,250 epoch 8 - iter 6/6 - loss 0.45311287 - samples/sec: 289.70\n",
            "2020-06-11 21:24:23,265 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:24:23,266 EPOCH 8 done: loss 0.4531 - lr 0.1000000\n",
            "2020-06-11 21:24:23,864 DEV : loss 2.0921192169189453 - score 0.7353\n",
            "2020-06-11 21:24:23,897 BAD EPOCHS (no improvement): 2\n",
            "2020-06-11 21:24:23,900 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:24:24,601 epoch 9 - iter 1/6 - loss 0.58891082 - samples/sec: 74.34\n",
            "2020-06-11 21:24:36,174 epoch 9 - iter 2/6 - loss 0.47909713 - samples/sec: 80.84\n",
            "2020-06-11 21:24:47,824 epoch 9 - iter 3/6 - loss 0.41630128 - samples/sec: 77.57\n",
            "2020-06-11 21:24:59,362 epoch 9 - iter 4/6 - loss 0.39880129 - samples/sec: 79.10\n",
            "2020-06-11 21:25:10,732 epoch 9 - iter 5/6 - loss 0.42130509 - samples/sec: 90.72\n",
            "2020-06-11 21:25:22,288 epoch 9 - iter 6/6 - loss 0.41995644 - samples/sec: 328.83\n",
            "2020-06-11 21:25:33,219 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:25:33,224 EPOCH 9 done: loss 0.4200 - lr 0.1000000\n",
            "2020-06-11 21:25:33,839 DEV : loss 1.024451732635498 - score 0.8333\n",
            "2020-06-11 21:25:33,876 BAD EPOCHS (no improvement): 3\n",
            "2020-06-11 21:25:33,881 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:25:34,815 epoch 10 - iter 1/6 - loss 0.08654150 - samples/sec: 44.38\n",
            "2020-06-11 21:25:47,954 epoch 10 - iter 2/6 - loss 0.15143371 - samples/sec: 79.56\n",
            "2020-06-11 21:25:59,975 epoch 10 - iter 3/6 - loss 0.16804135 - samples/sec: 79.01\n",
            "2020-06-11 21:26:11,426 epoch 10 - iter 4/6 - loss 0.16050556 - samples/sec: 83.57\n",
            "2020-06-11 21:26:22,848 epoch 10 - iter 5/6 - loss 0.16353161 - samples/sec: 80.80\n",
            "2020-06-11 21:26:33,874 epoch 10 - iter 6/6 - loss 0.16242523 - samples/sec: 362.74\n",
            "2020-06-11 21:26:45,207 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:26:45,210 EPOCH 10 done: loss 0.1624 - lr 0.1000000\n",
            "2020-06-11 21:26:45,827 DEV : loss 1.8005850315093994 - score 0.8197\n",
            "Epoch    10: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-06-11 21:26:45,860 BAD EPOCHS (no improvement): 4\n",
            "2020-06-11 21:26:47,660 ----------------------------------------------------------------------------------------------------\n",
            "2020-06-11 21:26:47,665 Testing using best model ...\n",
            "2020-06-11 21:26:47,669 loading file drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled/best-model.pt\n",
            "2020-06-11 21:26:49,605 \t0.72\n",
            "2020-06-11 21:26:49,610 \n",
            "Results:\n",
            "- F-score (micro) 0.8772\n",
            "- F-score (macro) 0.5556\n",
            "- Accuracy 0.72\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000        20\n",
            "           1     1.0000    0.0000    0.0000         2\n",
            "          -1     1.0000    0.5000    0.6667        10\n",
            "\n",
            "   micro avg     1.0000    0.7812    0.8772        32\n",
            "   macro avg     1.0000    0.5000    0.5556        32\n",
            "weighted avg     1.0000    0.7812    0.8333        32\n",
            " samples avg     1.0000    0.8600    0.9067        32\n",
            "\n",
            "2020-06-11 21:26:49,613 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [1.3760476112365723,\n",
              "  1.2450100183486938,\n",
              "  1.7610528469085693,\n",
              "  0.8523023128509521,\n",
              "  0.8766542077064514,\n",
              "  0.8038918375968933,\n",
              "  1.3781912326812744,\n",
              "  2.0921192169189453,\n",
              "  1.024451732635498,\n",
              "  1.8005850315093994],\n",
              " 'dev_score_history': [0.6944,\n",
              "  0.7353,\n",
              "  0.7692,\n",
              "  0.8333,\n",
              "  0.8621,\n",
              "  0.8772,\n",
              "  0.7692,\n",
              "  0.7353,\n",
              "  0.8333,\n",
              "  0.8197],\n",
              " 'test_score': 0.8772,\n",
              " 'train_loss_history': [1.5251025954882305,\n",
              "  1.1479901770750682,\n",
              "  0.7269907395044962,\n",
              "  0.9134433368841807,\n",
              "  0.5661698778470358,\n",
              "  0.675675223271052,\n",
              "  0.46617567042509717,\n",
              "  0.4531128679712613,\n",
              "  0.41995643575986225,\n",
              "  0.16242523243029913]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKyyw1CSZFy",
        "colab_type": "code",
        "outputId": "bb830ad0-00c9-406f-e48f-b83d0c6b5dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "mortgage_classifier = TextClassifier.load(new_data_folder + '/best-model.pt')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-11 22:56:19,218 loading file ./drive/My Drive/Colab Notebooks/capstone/data/phase_2_mortgage_rate_oversampled//best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V32lWB1gblaq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f2afca6-6a80-4d9f-ce74-a10a4ef2f2d2"
      },
      "source": [
        "sentence = Sentence(\"Canada's growth weakens as investment drops, consumers fade\")\n",
        "\n",
        "mortgage_classifier.predict(sentence, multi_class_prob=True)\n",
        "\n",
        "print(sentence.labels) ## incorrect, but uncertain"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1 (0.4634)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRpxvYnV1fCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.read_csv(data_folder + \"mortgage_rates_CBC_article_to_predict.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkUvqlX212UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt4t3vR0crZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def finetuned_model_predictions(input_file_path, finetuned_classifier, output_file_path):\n",
        "  '''Makes Sentiment Predictions on unannotated data points contained in the input csvfile by loading the user-defined classifier.\n",
        "     Exports the csvfile by adding two columns 'pred_label' and 'confidence' and filling in results from model predictions.\n",
        "  '''\n",
        "  unannotated_df = pd.read_csv(input_file_path)\n",
        "\n",
        "  unannotated_df['best_label'] = None\n",
        "  unannotated_df['best_confidence'] = None\n",
        "  unannotated_df['second_likely'] = None\n",
        "  unannotated_df['second_confidence'] = None\n",
        "  unannotated_df['least_likely'] = None\n",
        "  unannotated_df['least_confidence'] = None\n",
        "  for i in range(len(unannotated_df)):\n",
        "    #print(unannotated_df['title_desc'].iloc[i])\n",
        "    sentence = Sentence(unannotated_df['title_desc'].iloc[i])\n",
        "    finetuned_classifier.predict(sentence,  multi_class_prob=True)\n",
        "    print(sentence.labels)\n",
        "    pred_score_label = [(sentence.labels[c].score, sentence.labels[c].value) for c in range(len(sentence.labels))]\n",
        "    pred_score_label.sort()\n",
        "    print(pred_score_label)\n",
        "    # list in ascending order on confidence score\n",
        "    best_label = int(pred_score_label[-1][1])\n",
        "    best_confidence = pred_score_label[-1][0]\n",
        "    second_likely_label = int(pred_score_label[-2][1]) \n",
        "    second_likely_confidence = pred_score_label[-2][0]\n",
        "    least_likely_label = int(pred_score_label[0][1]) \n",
        "    least_likely_confidence = pred_score_label[0][0]\n",
        "\n",
        "    unannotated_df['best_label'].iloc[i] = best_label\n",
        "    unannotated_df['best_confidence'].iloc[i] = best_confidence\n",
        "    unannotated_df['second_likely'].iloc[i] = second_likely_label\n",
        "    unannotated_df['second_confidence'].iloc[i] = second_likely_confidence\n",
        "    unannotated_df['least_likely'].iloc[i] = least_likely_label\n",
        "    unannotated_df['least_confidence'].iloc[i] = least_likely_confidence\n",
        "\n",
        "  print(f\"All { len(unannotated_df) } rows done prediction! \")\n",
        "  unannotated_df.to_csv(output_file_path,index=False)\n",
        "  print(\"Done export!\")\n",
        "\n",
        "  return unannotated_df['best_label'].value_counts()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRvRZ5gw29St",
        "colab_type": "code",
        "outputId": "cba96fda-32d5-451f-9c34-f2bfac59160c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# #BLOOMBERG - MAKE PREDICTIONS W ALL PROBS\n",
        "# input_name = data_folder + \"predictions_dataset_mortgagerates_Bloomberg.csv\"\n",
        "# print(input_name)\n",
        "# output_name = data_folder + \"unannotated_mortgagerates_Bloomberg_predictions.csv\"\n",
        "# print(output_name)\n",
        "\n",
        "#finetuned_model_predictions(input_name, mortgage_classifier, output_name)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./drive/My Drive/Colab Notebooks/capstone/data/predictions_dataset_mortgagerates_Bloomberg.csv\n",
            "./drive/My Drive/Colab Notebooks/capstone/data/unannotated_mortgagerates_Bloomberg_predictions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OZO_rtxR0q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfb2EbvJVnZh",
        "colab_type": "code",
        "outputId": "b5b8e030-6899-408c-b720-e3f7d840f688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#CBC - MAKE PREDICTIONS W ALL PROBS\n",
        "input_name = data_folder + \"predictions_dataset_mortgagerates_cbc.csv\"\n",
        "print(input_name)\n",
        "output_name = data_folder + \"unannotated_mortgagerates_CBC_predictions.csv\"\n",
        "print(output_name)\n",
        "\n",
        "finetuned_model_predictions(input_name, mortgage_classifier, output_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./drive/My Drive/Colab Notebooks/capstone/data/predictions_dataset_mortgagerates_cbc.csv\n",
            "./drive/My Drive/Colab Notebooks/capstone/data/unannotated_mortgagerate_CBC_predictions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQV5zEwF14Cw",
        "colab_type": "code",
        "outputId": "071c2fe1-c139-499c-f5cd-e5e754614eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pred_list = []\n",
        "conf_list = []\n",
        "\n",
        "for index, row in pred_df.iterrows():\n",
        "  article_text = row[\"title_desc\"]\n",
        "  article_sentence = Sentence(article_text)\n",
        "  mortgage_classifier.predict(article_sentence)\n",
        "  pred = article_sentence.labels[0].value\n",
        "  print(pred)\n",
        "  pred_list.append(pred)\n",
        "\n",
        "  conf_score = article_sentence.labels[0].score\n",
        "  print(conf_score)\n",
        "  conf_list.append(conf_score)\n",
        "\n",
        "  print('----')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0.5833262801170349\n",
            "----\n",
            "0\n",
            "0.8457203507423401\n",
            "----\n",
            "-1\n",
            "0.3939833641052246\n",
            "----\n",
            "-1\n",
            "0.7230633497238159\n",
            "----\n",
            "-1\n",
            "0.7956459522247314\n",
            "----\n",
            "-1\n",
            "0.5243971347808838\n",
            "----\n",
            "0\n",
            "0.8241885900497437\n",
            "----\n",
            "-1\n",
            "0.5161066651344299\n",
            "----\n",
            "0\n",
            "0.9054300785064697\n",
            "----\n",
            "0\n",
            "0.5838729739189148\n",
            "----\n",
            "-1\n",
            "0.9202001690864563\n",
            "----\n",
            "-1\n",
            "0.7700586915016174\n",
            "----\n",
            "-1\n",
            "0.7929283380508423\n",
            "----\n",
            "-1\n",
            "0.5186101198196411\n",
            "----\n",
            "-1\n",
            "0.7283235192298889\n",
            "----\n",
            "0\n",
            "0.7462179660797119\n",
            "----\n",
            "0\n",
            "0.9179391264915466\n",
            "----\n",
            "-1\n",
            "0.723307728767395\n",
            "----\n",
            "-1\n",
            "0.723307728767395\n",
            "----\n",
            "0\n",
            "0.9848251938819885\n",
            "----\n",
            "-1\n",
            "0.6162759065628052\n",
            "----\n",
            "0\n",
            "0.8945677876472473\n",
            "----\n",
            "-1\n",
            "0.6524528861045837\n",
            "----\n",
            "-1\n",
            "0.8799123167991638\n",
            "----\n",
            "-1\n",
            "0.61030113697052\n",
            "----\n",
            "-1\n",
            "0.61030113697052\n",
            "----\n",
            "0\n",
            "0.9861264824867249\n",
            "----\n",
            "0\n",
            "0.987683117389679\n",
            "----\n",
            "-1\n",
            "0.6217166185379028\n",
            "----\n",
            "0\n",
            "0.4838629364967346\n",
            "----\n",
            "0\n",
            "0.8227150440216064\n",
            "----\n",
            "-1\n",
            "0.5220191478729248\n",
            "----\n",
            "0\n",
            "0.8764476776123047\n",
            "----\n",
            "0\n",
            "0.9738495945930481\n",
            "----\n",
            "0\n",
            "0.7048612236976624\n",
            "----\n",
            "0\n",
            "0.9464749097824097\n",
            "----\n",
            "-1\n",
            "0.6920495629310608\n",
            "----\n",
            "0\n",
            "0.9608901143074036\n",
            "----\n",
            "0\n",
            "0.7481488585472107\n",
            "----\n",
            "0\n",
            "0.9535633325576782\n",
            "----\n",
            "-1\n",
            "0.9190465211868286\n",
            "----\n",
            "-1\n",
            "0.5463420748710632\n",
            "----\n",
            "0\n",
            "0.8133000135421753\n",
            "----\n",
            "0\n",
            "0.957953155040741\n",
            "----\n",
            "-1\n",
            "0.8195844888687134\n",
            "----\n",
            "0\n",
            "0.730255126953125\n",
            "----\n",
            "-1\n",
            "0.6552487015724182\n",
            "----\n",
            "-1\n",
            "0.9461883902549744\n",
            "----\n",
            "0\n",
            "0.8879565596580505\n",
            "----\n",
            "0\n",
            "0.9701850414276123\n",
            "----\n",
            "-1\n",
            "0.5205972194671631\n",
            "----\n",
            "0\n",
            "0.9987040758132935\n",
            "----\n",
            "0\n",
            "0.48939162492752075\n",
            "----\n",
            "0\n",
            "0.9774554967880249\n",
            "----\n",
            "0\n",
            "0.8820390701293945\n",
            "----\n",
            "0\n",
            "0.6866989731788635\n",
            "----\n",
            "0\n",
            "0.9774554967880249\n",
            "----\n",
            "0\n",
            "0.6904755234718323\n",
            "----\n",
            "-1\n",
            "0.8698023557662964\n",
            "----\n",
            "0\n",
            "0.964982807636261\n",
            "----\n",
            "1\n",
            "0.4242871403694153\n",
            "----\n",
            "0\n",
            "0.8386717438697815\n",
            "----\n",
            "0\n",
            "0.5362359881401062\n",
            "----\n",
            "0\n",
            "0.7498077750205994\n",
            "----\n",
            "0\n",
            "0.6681461334228516\n",
            "----\n",
            "0\n",
            "0.9279248118400574\n",
            "----\n",
            "0\n",
            "0.9279248118400574\n",
            "----\n",
            "-1\n",
            "0.8517391681671143\n",
            "----\n",
            "0\n",
            "0.9788872003555298\n",
            "----\n",
            "0\n",
            "0.6765930652618408\n",
            "----\n",
            "-1\n",
            "0.5427541136741638\n",
            "----\n",
            "-1\n",
            "0.5127909779548645\n",
            "----\n",
            "0\n",
            "0.6567027568817139\n",
            "----\n",
            "0\n",
            "0.9628497362136841\n",
            "----\n",
            "0\n",
            "0.9954694509506226\n",
            "----\n",
            "0\n",
            "0.9612399935722351\n",
            "----\n",
            "-1\n",
            "0.5127909779548645\n",
            "----\n",
            "0\n",
            "0.5480616688728333\n",
            "----\n",
            "-1\n",
            "0.7482961416244507\n",
            "----\n",
            "0\n",
            "0.5651090145111084\n",
            "----\n",
            "0\n",
            "0.9298241138458252\n",
            "----\n",
            "0\n",
            "0.5651090145111084\n",
            "----\n",
            "0\n",
            "0.9954694509506226\n",
            "----\n",
            "0\n",
            "0.9874289631843567\n",
            "----\n",
            "0\n",
            "0.9955001473426819\n",
            "----\n",
            "0\n",
            "0.9955001473426819\n",
            "----\n",
            "-1\n",
            "0.5992812514305115\n",
            "----\n",
            "1\n",
            "0.5158616304397583\n",
            "----\n",
            "0\n",
            "0.8970370888710022\n",
            "----\n",
            "1\n",
            "0.6774313449859619\n",
            "----\n",
            "0\n",
            "0.972307026386261\n",
            "----\n",
            "0\n",
            "0.7627779841423035\n",
            "----\n",
            "0\n",
            "0.7784238457679749\n",
            "----\n",
            "0\n",
            "0.994499921798706\n",
            "----\n",
            "0\n",
            "0.9298712015151978\n",
            "----\n",
            "-1\n",
            "0.5683609247207642\n",
            "----\n",
            "-1\n",
            "0.5683609247207642\n",
            "----\n",
            "0\n",
            "0.994499921798706\n",
            "----\n",
            "0\n",
            "0.4891136884689331\n",
            "----\n",
            "1\n",
            "0.7017706036567688\n",
            "----\n",
            "0\n",
            "0.9857171773910522\n",
            "----\n",
            "0\n",
            "0.9961250424385071\n",
            "----\n",
            "0\n",
            "0.6760703325271606\n",
            "----\n",
            "-1\n",
            "0.9577069878578186\n",
            "----\n",
            "0\n",
            "0.9298712015151978\n",
            "----\n",
            "-1\n",
            "0.5614399313926697\n",
            "----\n",
            "-1\n",
            "0.7680593729019165\n",
            "----\n",
            "-1\n",
            "0.6201648116111755\n",
            "----\n",
            "0\n",
            "0.9833446145057678\n",
            "----\n",
            "0\n",
            "0.992198646068573\n",
            "----\n",
            "-1\n",
            "0.4607471525669098\n",
            "----\n",
            "0\n",
            "0.9910138249397278\n",
            "----\n",
            "0\n",
            "0.6249313354492188\n",
            "----\n",
            "0\n",
            "0.8453556895256042\n",
            "----\n",
            "0\n",
            "0.7165437936782837\n",
            "----\n",
            "0\n",
            "0.7165437936782837\n",
            "----\n",
            "0\n",
            "0.928024172782898\n",
            "----\n",
            "0\n",
            "0.8453556895256042\n",
            "----\n",
            "1\n",
            "0.6148869395256042\n",
            "----\n",
            "-1\n",
            "0.5346603393554688\n",
            "----\n",
            "0\n",
            "0.9862318634986877\n",
            "----\n",
            "0\n",
            "0.9383276700973511\n",
            "----\n",
            "0\n",
            "0.9435617327690125\n",
            "----\n",
            "0\n",
            "0.9174548387527466\n",
            "----\n",
            "0\n",
            "0.627829909324646\n",
            "----\n",
            "0\n",
            "0.6656681895256042\n",
            "----\n",
            "0\n",
            "0.5340589284896851\n",
            "----\n",
            "0\n",
            "0.5952253937721252\n",
            "----\n",
            "0\n",
            "0.9306917786598206\n",
            "----\n",
            "0\n",
            "0.9057310223579407\n",
            "----\n",
            "0\n",
            "0.9760484099388123\n",
            "----\n",
            "0\n",
            "0.7148228287696838\n",
            "----\n",
            "0\n",
            "0.9816107749938965\n",
            "----\n",
            "0\n",
            "0.5099163055419922\n",
            "----\n",
            "0\n",
            "0.7148228287696838\n",
            "----\n",
            "0\n",
            "0.5725260972976685\n",
            "----\n",
            "0\n",
            "0.9583832621574402\n",
            "----\n",
            "0\n",
            "0.5481159687042236\n",
            "----\n",
            "0\n",
            "0.8957244157791138\n",
            "----\n",
            "0\n",
            "0.6800258159637451\n",
            "----\n",
            "0\n",
            "0.6800258159637451\n",
            "----\n",
            "0\n",
            "0.7798213362693787\n",
            "----\n",
            "0\n",
            "0.9863714575767517\n",
            "----\n",
            "-1\n",
            "0.6840746998786926\n",
            "----\n",
            "0\n",
            "0.43224287033081055\n",
            "----\n",
            "0\n",
            "0.6042570471763611\n",
            "----\n",
            "-1\n",
            "0.7142716646194458\n",
            "----\n",
            "0\n",
            "0.895915687084198\n",
            "----\n",
            "1\n",
            "0.49335193634033203\n",
            "----\n",
            "0\n",
            "0.9764546751976013\n",
            "----\n",
            "0\n",
            "0.9986944794654846\n",
            "----\n",
            "0\n",
            "0.9527829885482788\n",
            "----\n",
            "0\n",
            "0.9986944794654846\n",
            "----\n",
            "0\n",
            "0.6502994894981384\n",
            "----\n",
            "0\n",
            "0.5378075242042542\n",
            "----\n",
            "0\n",
            "0.9444385170936584\n",
            "----\n",
            "-1\n",
            "0.5341562628746033\n",
            "----\n",
            "0\n",
            "0.9244308471679688\n",
            "----\n",
            "0\n",
            "0.8028528690338135\n",
            "----\n",
            "0\n",
            "0.8847524523735046\n",
            "----\n",
            "0\n",
            "0.9527829885482788\n",
            "----\n",
            "0\n",
            "0.9444385170936584\n",
            "----\n",
            "-1\n",
            "0.65311199426651\n",
            "----\n",
            "-1\n",
            "0.6118548512458801\n",
            "----\n",
            "0\n",
            "0.9244308471679688\n",
            "----\n",
            "-1\n",
            "0.6118548512458801\n",
            "----\n",
            "0\n",
            "0.8223796486854553\n",
            "----\n",
            "1\n",
            "0.9382610321044922\n",
            "----\n",
            "1\n",
            "0.5431433320045471\n",
            "----\n",
            "0\n",
            "0.5803050994873047\n",
            "----\n",
            "0\n",
            "0.8223796486854553\n",
            "----\n",
            "0\n",
            "0.9952138662338257\n",
            "----\n",
            "0\n",
            "0.9952138662338257\n",
            "----\n",
            "0\n",
            "0.6048591732978821\n",
            "----\n",
            "0\n",
            "0.9249727129936218\n",
            "----\n",
            "0\n",
            "0.9952138662338257\n",
            "----\n",
            "0\n",
            "0.8534560799598694\n",
            "----\n",
            "0\n",
            "0.6048591732978821\n",
            "----\n",
            "0\n",
            "0.5058773756027222\n",
            "----\n",
            "-1\n",
            "0.455570250749588\n",
            "----\n",
            "0\n",
            "0.5058773756027222\n",
            "----\n",
            "-1\n",
            "0.5905554294586182\n",
            "----\n",
            "0\n",
            "0.8261200189590454\n",
            "----\n",
            "-1\n",
            "0.5905554294586182\n",
            "----\n",
            "0\n",
            "0.9061497449874878\n",
            "----\n",
            "0\n",
            "0.9935964345932007\n",
            "----\n",
            "0\n",
            "0.8707551956176758\n",
            "----\n",
            "0\n",
            "0.8707551956176758\n",
            "----\n",
            "0\n",
            "0.9935964345932007\n",
            "----\n",
            "0\n",
            "0.8001543879508972\n",
            "----\n",
            "0\n",
            "0.8149585723876953\n",
            "----\n",
            "1\n",
            "0.950413167476654\n",
            "----\n",
            "0\n",
            "0.9660902619361877\n",
            "----\n",
            "-1\n",
            "0.6384871006011963\n",
            "----\n",
            "0\n",
            "0.9660902619361877\n",
            "----\n",
            "-1\n",
            "0.4781244695186615\n",
            "----\n",
            "1\n",
            "0.4373388886451721\n",
            "----\n",
            "0\n",
            "0.8058847188949585\n",
            "----\n",
            "0\n",
            "0.9009319543838501\n",
            "----\n",
            "0\n",
            "0.9009319543838501\n",
            "----\n",
            "0\n",
            "0.6575592160224915\n",
            "----\n",
            "-1\n",
            "0.5184411406517029\n",
            "----\n",
            "0\n",
            "0.6575592160224915\n",
            "----\n",
            "0\n",
            "0.8591176867485046\n",
            "----\n",
            "0\n",
            "0.8127198815345764\n",
            "----\n",
            "1\n",
            "0.6706447005271912\n",
            "----\n",
            "0\n",
            "0.8591176867485046\n",
            "----\n",
            "1\n",
            "0.46332210302352905\n",
            "----\n",
            "0\n",
            "0.8127198815345764\n",
            "----\n",
            "0\n",
            "0.9413312077522278\n",
            "----\n",
            "-1\n",
            "0.4578247666358948\n",
            "----\n",
            "0\n",
            "0.9413312077522278\n",
            "----\n",
            "0\n",
            "0.9722641706466675\n",
            "----\n",
            "0\n",
            "0.931847870349884\n",
            "----\n",
            "0\n",
            "0.629153311252594\n",
            "----\n",
            "-1\n",
            "0.4578247666358948\n",
            "----\n",
            "0\n",
            "0.9181478023529053\n",
            "----\n",
            "0\n",
            "0.9119212031364441\n",
            "----\n",
            "0\n",
            "0.9924029111862183\n",
            "----\n",
            "1\n",
            "0.9169769883155823\n",
            "----\n",
            "0\n",
            "0.9181478023529053\n",
            "----\n",
            "0\n",
            "0.914290189743042\n",
            "----\n",
            "-1\n",
            "0.7489941120147705\n",
            "----\n",
            "0\n",
            "0.9610273838043213\n",
            "----\n",
            "1\n",
            "0.5704066157341003\n",
            "----\n",
            "0\n",
            "0.9924029111862183\n",
            "----\n",
            "1\n",
            "0.9140901565551758\n",
            "----\n",
            "1\n",
            "0.5704066157341003\n",
            "----\n",
            "1\n",
            "0.9140901565551758\n",
            "----\n",
            "1\n",
            "0.5849648118019104\n",
            "----\n",
            "0\n",
            "0.9610273838043213\n",
            "----\n",
            "1\n",
            "0.5704066157341003\n",
            "----\n",
            "0\n",
            "0.8249685168266296\n",
            "----\n",
            "0\n",
            "0.8249685168266296\n",
            "----\n",
            "-1\n",
            "0.5715274810791016\n",
            "----\n",
            "0\n",
            "0.9768720269203186\n",
            "----\n",
            "0\n",
            "0.8408538699150085\n",
            "----\n",
            "0\n",
            "0.9242126941680908\n",
            "----\n",
            "0\n",
            "0.9903573393821716\n",
            "----\n",
            "0\n",
            "0.5293673872947693\n",
            "----\n",
            "0\n",
            "0.9881261587142944\n",
            "----\n",
            "0\n",
            "0.9903573393821716\n",
            "----\n",
            "0\n",
            "0.9881261587142944\n",
            "----\n",
            "0\n",
            "0.866226077079773\n",
            "----\n",
            "0\n",
            "0.9300028681755066\n",
            "----\n",
            "0\n",
            "0.9497312903404236\n",
            "----\n",
            "0\n",
            "0.9300028681755066\n",
            "----\n",
            "0\n",
            "0.9436260461807251\n",
            "----\n",
            "0\n",
            "0.9300028681755066\n",
            "----\n",
            "0\n",
            "0.9497312903404236\n",
            "----\n",
            "-1\n",
            "0.5753954648971558\n",
            "----\n",
            "-1\n",
            "0.6113917827606201\n",
            "----\n",
            "0\n",
            "0.9855823516845703\n",
            "----\n",
            "-1\n",
            "0.5753954648971558\n",
            "----\n",
            "-1\n",
            "0.6113917827606201\n",
            "----\n",
            "0\n",
            "0.8868564963340759\n",
            "----\n",
            "-1\n",
            "0.6113917827606201\n",
            "----\n",
            "0\n",
            "0.946033239364624\n",
            "----\n",
            "0\n",
            "0.9699277281761169\n",
            "----\n",
            "0\n",
            "0.7384837865829468\n",
            "----\n",
            "0\n",
            "0.7384837865829468\n",
            "----\n",
            "-1\n",
            "0.4728853702545166\n",
            "----\n",
            "0\n",
            "0.5945981740951538\n",
            "----\n",
            "0\n",
            "0.9904341697692871\n",
            "----\n",
            "0\n",
            "0.9904341697692871\n",
            "----\n",
            "0\n",
            "0.7934226989746094\n",
            "----\n",
            "-1\n",
            "0.4728853702545166\n",
            "----\n",
            "0\n",
            "0.4737481474876404\n",
            "----\n",
            "0\n",
            "0.7782605290412903\n",
            "----\n",
            "0\n",
            "0.6489474177360535\n",
            "----\n",
            "0\n",
            "0.8667775988578796\n",
            "----\n",
            "0\n",
            "0.7636364698410034\n",
            "----\n",
            "-1\n",
            "0.8524603843688965\n",
            "----\n",
            "0\n",
            "0.9019364714622498\n",
            "----\n",
            "0\n",
            "0.9947376847267151\n",
            "----\n",
            "0\n",
            "0.9323815703392029\n",
            "----\n",
            "0\n",
            "0.8276392817497253\n",
            "----\n",
            "0\n",
            "0.7139638066291809\n",
            "----\n",
            "0\n",
            "0.9397067427635193\n",
            "----\n",
            "-1\n",
            "0.5557470321655273\n",
            "----\n",
            "-1\n",
            "0.5557470321655273\n",
            "----\n",
            "-1\n",
            "0.6337345838546753\n",
            "----\n",
            "0\n",
            "0.8523023724555969\n",
            "----\n",
            "0\n",
            "0.8891795873641968\n",
            "----\n",
            "0\n",
            "0.9496447443962097\n",
            "----\n",
            "0\n",
            "0.9496447443962097\n",
            "----\n",
            "0\n",
            "0.9944211840629578\n",
            "----\n",
            "0\n",
            "0.9661639332771301\n",
            "----\n",
            "0\n",
            "0.9944211840629578\n",
            "----\n",
            "0\n",
            "0.9145631194114685\n",
            "----\n",
            "0\n",
            "0.9145631194114685\n",
            "----\n",
            "0\n",
            "0.9968365430831909\n",
            "----\n",
            "0\n",
            "0.5990732908248901\n",
            "----\n",
            "0\n",
            "0.5341294407844543\n",
            "----\n",
            "0\n",
            "0.9501262903213501\n",
            "----\n",
            "0\n",
            "0.9898331165313721\n",
            "----\n",
            "0\n",
            "0.5990732908248901\n",
            "----\n",
            "0\n",
            "0.4920549690723419\n",
            "----\n",
            "0\n",
            "0.8592660427093506\n",
            "----\n",
            "0\n",
            "0.9841258525848389\n",
            "----\n",
            "-1\n",
            "0.6699318885803223\n",
            "----\n",
            "0\n",
            "0.8490521311759949\n",
            "----\n",
            "0\n",
            "0.786296546459198\n",
            "----\n",
            "0\n",
            "0.786296546459198\n",
            "----\n",
            "0\n",
            "0.9397538304328918\n",
            "----\n",
            "0\n",
            "0.7597381472587585\n",
            "----\n",
            "0\n",
            "0.44951143860816956\n",
            "----\n",
            "0\n",
            "0.9397538304328918\n",
            "----\n",
            "0\n",
            "0.6742253303527832\n",
            "----\n",
            "0\n",
            "0.9868032336235046\n",
            "----\n",
            "0\n",
            "0.9868032336235046\n",
            "----\n",
            "0\n",
            "0.9001421332359314\n",
            "----\n",
            "0\n",
            "0.9001421332359314\n",
            "----\n",
            "0\n",
            "0.9143128395080566\n",
            "----\n",
            "0\n",
            "0.9143128395080566\n",
            "----\n",
            "0\n",
            "0.9819638729095459\n",
            "----\n",
            "-1\n",
            "0.7012293338775635\n",
            "----\n",
            "0\n",
            "0.9443699717521667\n",
            "----\n",
            "0\n",
            "0.8823479413986206\n",
            "----\n",
            "0\n",
            "0.8823479413986206\n",
            "----\n",
            "-1\n",
            "0.6246797442436218\n",
            "----\n",
            "0\n",
            "0.8615285754203796\n",
            "----\n",
            "0\n",
            "0.9673453569412231\n",
            "----\n",
            "0\n",
            "0.9673453569412231\n",
            "----\n",
            "0\n",
            "0.9673453569412231\n",
            "----\n",
            "0\n",
            "0.961482048034668\n",
            "----\n",
            "0\n",
            "0.961482048034668\n",
            "----\n",
            "0\n",
            "0.8594030141830444\n",
            "----\n",
            "0\n",
            "0.6569146513938904\n",
            "----\n",
            "0\n",
            "0.6246793866157532\n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pM-EFFv3J4O",
        "colab_type": "code",
        "outputId": "8d353b79-ce81-409c-fd98-fd0413829cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(conf_list))\n",
        "print(len(pred_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "330\n",
            "330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We-qZI5A7f_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pred_df[\"pred_label\"] = pd.Series(pred_list)\n",
        "pred_df[\"confidence\"] = pd.Series(conf_list)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHzwpiCK8pia",
        "colab_type": "code",
        "outputId": "813116ea-3250-41d2-b764-cd2dd827300c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "pred_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>title_desc</th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Mortgage arrears rate could spike to double wh...</td>\n",
              "      <td>2020-05-14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.583326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Interest rates are plunging — so why aren't mo...</td>\n",
              "      <td>2020-04-04</td>\n",
              "      <td>0</td>\n",
              "      <td>0.845720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Why worries about the coronavirus are pushing ...</td>\n",
              "      <td>2020-01-29</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.393983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CBC</td>\n",
              "      <td>U.S. Fed chair rules out negative interest rat...</td>\n",
              "      <td>2020-05-13</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.723063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CBC</td>\n",
              "      <td>Mortgages in arrears in Alberta hit highest ra...</td>\n",
              "      <td>2019-08-14</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.795646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 source  ... pred_label confidence\n",
              "0           0    CBC  ...          0   0.583326\n",
              "1           1    CBC  ...          0   0.845720\n",
              "2           2    CBC  ...         -1   0.393983\n",
              "3           3    CBC  ...         -1   0.723063\n",
              "4           4    CBC  ...         -1   0.795646\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nbTLQd67yfh",
        "colab_type": "code",
        "outputId": "d9ef8794-69c1-4d74-a0ed-77e5093d62bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index, row in pred_df.iterrows():\n",
        "  print(row[\"title_desc\"])\n",
        "  print(row[\"pred_label\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mortgage arrears rate could spike to double what it was in 2009, Bank of Canada says. Central bank says number of people falling behind on mortgages could almost quadruple\n",
            "0\n",
            "Interest rates are plunging — so why aren't mortgage rates?. Bond yields and central bank rates have never been lower, but not all the savings are filtering down\n",
            "0\n",
            "Why worries about the coronavirus are pushing mortgage rates down. Fear has pushed investors to buy up bonds, which is causing cheaper borrowing for home buyers\n",
            "-1\n",
            "U.S. Fed chair rules out negative interest rates even as Trump trumpets them. U.S. president goes negative on Jerome Powell for rejection of below-zero interest rates\n",
            "-1\n",
            "Mortgages in arrears in Alberta hit highest rate since 2013. Rate seen as a 'lagging indicator' of the economy, driven largely by unemployment\n",
            "-1\n",
            "'Pretty cheap money': Canadian mortgage rates falling to their lowest level in 2 years. Fixed and variable loans have gotten cheaper because costs for lenders are down too\n",
            "-1\n",
            "Housing starts up in some parts of Canada despite COVID-19. Multi-unit housing projects remained strong in some provinces in April, CMHC says\n",
            "0\n",
            "Federal deficit likely to be higher than $252 billion, parliamentary budget officer says. PBO says it's possible federal debt will hit $1 trillion because of pandemic relief spending\n",
            "-1\n",
            "Time to buy? What the pandemic means for Vancouver's real estate market. Mark Ting, On the Coast's finance columnist, on what lies ahead for buyers and sellers amid COVID-19\n",
            "0\n",
            "Put yourself in their shoes: Let's thank the women on the front line of the pandemic. Women are often in harm's way in this pandemic, says MUN president \n",
            "0\n",
            "Canada lost nearly 2 million jobs in April amid COVID-19 crisis: Statistics Canada. Statistics Canada says unemployment rate soared to 13% as full force of pandemic hit\n",
            "-1\n",
            "Ontario has now lost more than 1 million jobs during the COVID-19 pandemic. Unemployment rate climbs to 11.3%, with a warning that many workers have simply left the job market\n",
            "-1\n",
            "Another quarter-million Albertans lost work in April as COVID-19 shutdown grips province. Employment rate for young women cut nearly in half as pandemic hits service sector especially hard\n",
            "-1\n",
            "U.S. economy lost 20.5 million jobs in April. Unemployment rate surged to 14.7 per cent last month\n",
            "-1\n",
            "CMHC to take more mortgages off banks' books to free up cash for loans amid COVID-19 crisis. Government had similar program in place during 2009 financial crisis\n",
            "-1\n",
            "Deficit reduction will have to wait for the economic recovery, federal officials say. Federal aid programs could continue well into the recovery phase, says government official\n",
            "0\n",
            "Tiff Macklem to lead the Bank of Canada. Stephen Poloz’s term as governor ends in June\n",
            "0\n",
            "Canada's big banks cut credit card interest rates to ease coronavirus impact. Big Six will temporarily reduce credit card interest rates amid COVID-19 pandemic\n",
            "-1\n",
            "Canada's big banks cut credit card interest rates to ease coronavirus impact. Big Six will temporarily reduce credit card interest rates amid COVID-19 pandemic\n",
            "-1\n",
            "Why high interest rates were a problem for '80s renters, too. They didn't have mortgages, but their landlords did\n",
            "0\n",
            "Quebec lost 264,000 jobs to COVID-19 crisis last month. Quebec's unemployment rate rose to 8.1 per cent last month\n",
            "-1\n",
            "Changes to mortgage stress test rules good news for young home buyers, says P.E.I. broker. Broker says wiggle room will make a difference for people carrying extra debt\n",
            "0\n",
            "Bank of Canada holds rate steady at 0.25% and hints it has no plans to go any lower. Bank expects economic activity to slow by as much as 30% from end of 2019\n",
            "-1\n",
            "Bank of Canada makes emergency interest rate cut. Move comes on top of previous 50-point cut last week\n",
            "-1\n",
            "B.C. home sales to fall by 40 per cent but comeback is likely, report says. Provincial economy expected to shrink by 4 per cent, economist says \n",
            "-1\n",
            "B.C. home sales to fall by 40 per cent but comeback is likely, report says. Provincial economy expected to shrink by 4 per cent, economist says \n",
            "-1\n",
            "Ottawa unveils new mortgage stress test rules that will make it easier to pass. New rules will be in force as of April\n",
            "0\n",
            "Financially impacted by COVID-19? A personal-finance expert answers your most pressing questions. How to approach issues like cash flow, mortgage deferral, retirement investments and more right now\n",
            "0\n",
            "Tenants left homeless after Campbell River apartment fire granted hotel housing until end of May. Nearly 90 residents lost their homes after a low-income apartment building fire on April 8\n",
            "-1\n",
            "Foreclosure rate steadily increasing in Fort McMurray. 'There's a lot of homeowners that are very much underwater' as house prices drop\n",
            "0\n",
            "The economy's on life support and Canadians need help now. What's the holdup?. As Canadians wait anxiously for household financial aid, many wonder why banks aren't doing more\n",
            "0\n",
            "COVID-19 crisis may usher in new financial era if the world begins to shun risk: Don Pittis. Ants and grasshoppers: Consumers, businesses with savings will have to help the rest\n",
            "-1\n",
            "As COVID-19 bailouts pile up, Canadians ask for relief on credit card rates. Credit cards have much higher interest rates than other forms of debt and so far, are drawing less scrutiny\n",
            "0\n",
            "Italians allowed to visit relatives as country loosens more coronavirus restrictions. Anyone wearing a mask and following physical distancing can visit relatives to sixth degree and kin to fourth\n",
            "0\n",
            "Low vacancy rates for Saint John apartments could spell trouble for low-income renters. 'Affordability becomes an issue' when vacancy rate outpaces supply, says analyst with CMHC \n",
            "0\n",
            "U.S. Federal Reserve slashes rate to near 0 in effort to offset COVID-19 impact. Fed also said it will drop some bank requirements in order to encourage lending\n",
            "0\n",
            "Calgary home prices forecast to decline again in 2020, but by less than in 2019. Real estate board expects prices to drop 0.7%, compared with 3.4% last year\n",
            "-1\n",
            "Rents in Regina, Saskatoon expected to increase slightly in 2020: report. Vacancy rates in both cities have been declining according to CMHC\n",
            "0\n",
            "Will COVID-19 affect the spring real estate market?. Mark Ting, On the Coast's finance columnist, on what you should do if you're looking to buy — or sell\n",
            "0\n",
            "Interest rates made home buyers look beyond their comfort zone in 1979. Interest rate of almost 15 per cent drove property seekers to less desirable districts\n",
            "0\n",
            "Sask. finance minister to provide an update Friday amid fiscal uncertainty. COVID-19 and economic situation could have Sask. headed for $1B deficit: analysts\n",
            "-1\n",
            "TSX and Dow Jones lose another 10% as coronavirus sell-off continues. When stock markets go down by 7%, automatic trading halts kick in to calm the situation\n",
            "-1\n",
            "P.E.I. vacancy rate improved, but still lowest in country. Charlottetown vacancy rate now at 1.2% \n",
            "0\n",
            "How COVID might affect our food supply; Wedding delays might have hidden costs: CBC's Marketplace cheat sheet. Newsletter: Consumer and health news you need from the week\n",
            "0\n",
            "Fewer homes on the market could mean bargains for buyers still on the hunt during COVID-19. Real estate market has slowed to a halt, leaving buyer's market during COVID-19 pandemic\n",
            "-1\n",
            "Tough to tell when P.E.I. vacancy rate will rebound, says analyst. 'I would say now ... at 1.2 per cent it’s still very low'\n",
            "0\n",
            "Inflation's return would upend consumer and market strategies: Don Pittis. Experts warn record spending and printing money could lead to post-COVID price rises\n",
            "-1\n",
            "U.S. Federal Reserve cuts benchmark interest rate by half-point to offset coronavirus impact. Rate cut is biggest since 2008 financial crisis\n",
            "-1\n",
            "Will COVID-19 cause the next North American recession?. Finance columnist Mark Ting answers questions about the financial impact of coronavirus\n",
            "0\n",
            "Strategic Group puts 50 Calgary properties, with $650M in mortgages, under creditor protection. Company cited high vacancy rate, economic conditions as factors\n",
            "0\n",
            "Tight rental market has Dartmouth renters worried over looming 'renoviction'. Tenants can reapply to the building after renovations, but rents will be hundreds of dollars higher\n",
            "-1\n",
            "What it's like being 30 and going through the 3rd recession of your adult life. Millennials who coped with previous economic downturns share tips on surviving\n",
            "0\n",
            "Average rent in Calgary climbs by 1.7% as population, labour force grow. New rental units added to market also tend to demand higher rent, analyst says\n",
            "0\n",
            "Bank of Canada holds interest rates steady. Central bank holds the overnight rate steady at 1.75%\n",
            "0\n",
            "Mortgage stress test rules get more lenient for first time. Posted mortgage rates in Canada have inched lower, so stress test benchmark has followed suit\n",
            "0\n",
            "What's happened in Canada since WHO declared COVID-19 a pandemic. Canada had more than 100 confirmed cases on March 11 when pandemic declared\n",
            "0\n",
            "Bank of Canada holds interest rates steady. Central bank holds the overnight rate steady at 1.75%\n",
            "0\n",
            "Stephen Poloz gets racier as his farewell tour progresses: Don Pittis. Bank governor warns on Trump re-election and slams premiers on internal trade\n",
            "0\n",
            "Bank of Canada follows U.S. with half-point rate cut to soften blow of coronavirus. Bank rate reduction comes amid economic concerns over coronavirus outbreak\n",
            "-1\n",
            "Vacancy rates for some B.C. seniors' facilities up for first time in years. Spaces still in high demand for those with low income or high-level care needs\n",
            "0\n",
            "2019 home sales outlook improves, after 5% rise in August. Canadian Real Estate Association says declining mortgage rates luring buyers back\n",
            "1\n",
            "Home sales rise for 5th month in a row in July, prices up 4% in past year. Canada's housing market is showing signs of coming out of stress-test slumber \n",
            "0\n",
            "Fed saw last month less risk of U.S. recession. Central bank noted U.S. economy 'showing resilience' despite trade war, according to minutes of Dec. meeting\n",
            "0\n",
            "What profits at Canada's big banks are saying about the odds of a recession. Royal and CIBC revealed numbers last week. Now it's BMO, Scotia and TD's turn\n",
            "0\n",
            "'Renoviction' rates soar due to big-city housing crunch. 'It's a way of making outrageous profits in a very short time,' housing advocate says\n",
            "0\n",
            "Moncton, Dieppe break building permit records as construction booms. Residential construction is increasing but vacancy rates are falling \n",
            "0\n",
            "Moncton, Dieppe break building permit records as construction booms. Residential construction is increasing but vacancy rates are falling \n",
            "0\n",
            "Economic forecasts for Alberta point to recession, thousands of job losses. Province's economy to be hit hard by double whammy of COVID-19 and oil-price shock\n",
            "-1\n",
            "Why it was hard to sell or buy a home in Vancouver in 1981. Interest rates were the stumbling point \n",
            "0\n",
            "Fed chair sees North America as an economic oasis in 2020: Don Pittis. Solidifying our trade link with the U.S. means optimism could spread north next year\n",
            "0\n",
            "Canada's economy grew at 0.3% pace in fourth quarter, slowest level in almost 4 years. Bad weather and strikes slowed growth to a crawl\n",
            "-1\n",
            "Interest rate cut for COVID-19 is like surgery with a club: Don Pittis. Cheap money is a blunt instrument that won't fix specific economic problems caused by coronavirus outbreak\n",
            "-1\n",
            "Real estate market hits new heights in Ottawa-Gatineau. Record comes amidst affordable housing shortage\n",
            "0\n",
            "Home Capital Group to sell $425M worth of uninsured mortgage-backed securities. Move by alternative mortgage lender is likely to be welcomed by the Bank of Canada\n",
            "0\n",
            "COVID-19 unknowns leave economy dazed and wobbly: Don Pittis. It is certain the world will recover, but doubts remain over when and how\n",
            "0\n",
            "'It's been tough': Edmonton's job market limps into new year. 'I'm beginning to see now that the statistics ring true so it's been tough'\n",
            "0\n",
            "Interest rate cut for COVID-19 is like surgery with a club: Don Pittis. Cheap money is a blunt instrument that won't fix specific economic problems caused by coronavirus outbreak\n",
            "-1\n",
            "Calgary realtors bracing for a 'double whammy'. Price declines already predicted for 2020, now COVID-19 brings more uncertainty\n",
            "0\n",
            "'Agonizing': The prospect of a historic oil glut weighs on crude prices. North American benchmark price drops below $30 US per barrel\n",
            "-1\n",
            "Poloz sees parts of Canadian economy beginning to restart in 'late May'. But Bank of Canada governor tells MPs full recovery could take a year under 'best-case' scenario\n",
            "0\n",
            "Feds announce $200M for affordable rentals where Honest Ed's once stood. Mirvish Village project will ensure location stays true to roots as low-income hub, Ahmed Hussen says\n",
            "0\n",
            "Poloz sees parts of Canadian economy beginning to restart in 'late May'. But Bank of Canada governor tells MPs full recovery could take a year under 'best-case' scenario\n",
            "0\n",
            "COVID-19 unknowns leave economy dazed and wobbly: Don Pittis. It is certain the world will recover, but doubts remain over when and how\n",
            "0\n",
            "Manitoba Liberal leader calls on Ottawa to forgive personal, government debts. Dougald Lamont is calling for mass debt forgiveness across Canada\n",
            "0\n",
            "Here's some of the financial help available in B.C. during the COVID-19 crisis. This list will be updated as more funds and programs become available \n",
            "0\n",
            "Here's some of the financial help available in B.C. during the COVID-19 crisis. This list will be updated as more funds and programs become available \n",
            "0\n",
            "Fed's Powell sees steady growth, signals pause in rate cuts. Powell's testimony comes a day after Trump attacked the Fed for not cutting interest rates further\n",
            "-1\n",
            "Vancouver keeps crown as Canadian metropolis with highest rents and lowest vacancies. Property values went down — but average rents increased higher than inflation \n",
            "1\n",
            "Businesses in B.C. 'feeling the pinch' of coronavirus outbreak on global markets. Wide sector of industries affected — from manufacturing to tourism\n",
            "0\n",
            "Inflation rate nudges down to 1.9% as gasoline and vegetables got cheaper. Air fare increases one of the biggest factors to the upside\n",
            "1\n",
            "Chris Hall: Bill Morneau's keeping his pandemic focus firmly on the near-term. He knows Canadians want to be told when to expect a return to 'normal' — but he's got bigger problems\n",
            "0\n",
            "Bank of Canada deputy says Canadian economy is 'resilient'. Despite trade war between U.S. and China, deputy governor Timothy Lane says economy is strong\n",
            "0\n",
            "'Less bad' doesn't mean good: What Vancouver's housing market could hold in 2020. For the first time in five years, there were no major surges in any aspect of the market \n",
            "0\n",
            "Bank of Canada may cut rates to aid economy sickened by COVID-19: Don Pittis. Central bank action may be part of a co-ordinated G7 plan as recommended by OECD\n",
            "0\n",
            "Coronavirus: What's happening in Canada and around the world Wednesday. B.C. announces plan to ease COVID-19 restrictions, allowing small gatherings\n",
            "0\n",
            "Alaska population at lowest level since 2012. The state's population decline is second only to West Virginia in U.S.\n",
            "-1\n",
            "Alaska population at lowest level since 2012. The state's population decline is second only to West Virginia in U.S.\n",
            "-1\n",
            "Bank of Canada may cut rates to aid economy sickened by COVID-19: Don Pittis. Central bank action may be part of a co-ordinated G7 plan as recommended by OECD\n",
            "0\n",
            "Surging rent costs push families to choose between housing and food, says advocate. The Benedict Labre House says there has been a surge in demand for food baskets in the last year\n",
            "0\n",
            "Cheaper energy pulls Canada's inflation rate down to 2% in June. If energy is stripped out, cost of living increased at a 2.6% annual pace last month\n",
            "1\n",
            "Ottawa-area residents love where they live, but not what they're paying: survey. Capital region renters among least satisfied with housing affordability\n",
            "0\n",
            "Bank of Canada holds interest rates steady. Holds benchmark interest rate at 1.75 per cent\n",
            "0\n",
            "Sask. Landlord Association sees sharp spike in unpaid rents during COVID-19. Association says survey found 27 per cent of renters haven't paid bills yet\n",
            "0\n",
            "Alberta men under 25 and over 55 face highest unemployment rates, says StatsCan. Job market in province stagnates, adding just 1,200 full-time jobs in August\n",
            "-1\n",
            "Coronavirus: What's happening in Canada and around the world Wednesday. B.C. announces plan to ease COVID-19 restrictions, allowing small gatherings\n",
            "0\n",
            "'Now is the time for action,' says Mayor Valérie Plante, as Montreal vacancy rate hits 15-year low. Tenants' advocates worry critical housing shortage will lead to 'renters finding themselves on the streets'\n",
            "-1\n",
            "Containment efforts will delay, not prevent, COVID-19 outbreak in Canada, Hajdu warns. Health authorities hope delay will buy time to get hospitals through the busy flu season\n",
            "-1\n",
            "Employment held steady in October, Statistics Canada says. Economy lost 1,800 jobs, a number low enough that unemployment rate is unchanged\n",
            "-1\n",
            "Home sales climb higher in July, Canadian Real Estate Association reports. Sales up in most large markets, including Calgary, Edmonton, Toronto, Montreal, B.C. Lower Mainland\n",
            "0\n",
            "Meet the Toronto man who is spending $400 a month to live in a backyard yurt. Man says he slept in $3,000 structure through the winter\n",
            "0\n",
            "Canada's inflation rate held steady at 2% in July, higher than expected. Loonie inches higher on strong number, and odds of a rate cut next month get lower\n",
            "-1\n",
            "'This is a choice': Fort McMurray residents brave the winter cold in their RVs. 'We don't live in here because we have to'\n",
            "0\n",
            "In 1987, a triple-digit-point stock market drop was huge. Frenzied selloff at TSE drew in curious spectators on Black Monday\n",
            "0\n",
            "Vacancy rate on the rise in Regina, so why isn't the cost of rent going down?. Some residents struggle to afford rent in Regina despite oversupply\n",
            "0\n",
            "Morneau says he's not worried about a recession despite job numbers. Finance minister says investment remains strong, Canada's economy expected to continue growing\n",
            "0\n",
            "Morneau says he's not worried about a recession despite job numbers. Finance minister says investment remains strong, Canada's economy expected to continue growing\n",
            "0\n",
            "Winter is coming, and so is an uncharted economic abyss: Neil Macdonald. The economic situation scares me. But then, I'm not an economist\n",
            "0\n",
            "Vacancy rate on the rise in Regina, so why isn't the cost of rent going down?. Some residents struggle to afford rent in Regina despite oversupply\n",
            "0\n",
            "Canadian inflation 1.9% in September as lower gas prices keep rate steady. Rate held at 1.9% for second straight month, close to Bank of Canada's ideal target of 2%\n",
            "1\n",
            "Tenants left homeless after apartment fire struggle with Campbell River housing crisis — and a pandemic. Nearly 90 Campbell River residents are struggling to find housing while emergency supports are running out\n",
            "-1\n",
            "Big families, small budgets: The challenge of housing for refugees. Valentina Cerka works to overcome barriers and find affordable housing for refugees in Winnipeg\n",
            "0\n",
            "Toronto must be 'brave' and enact bold new zoning laws to confront housing crisis, advocates say. Detached houses are all the city allows on more than a third of residential land\n",
            "0\n",
            "Soaring condo insurance rates help push Fort McMurray homeowner into bankruptcy. 'There's not anything we can do anymore,' Kaleena Carriere says\n",
            "0\n",
            "Breaking down Canadians' questions about the cost of living. It's the number one concern among Canadians heading into the fall federal election \n",
            "0\n",
            "Bank of Canada holds interest rate at 1.75%, wary of global slowdown. Central bank says outlook for global economy 'has weakened further' since July\n",
            "0\n",
            "45 per cent of Hamilton renters living in unaffordable housing, new report says. Average rent in the downtown core, mountain has risen 40 per cent in 8 years\n",
            "0\n",
            "U.S. reports on GDP, consumer spending remain positive. Improvement in economic data seemingly reduces the risks of a recession in the near term\n",
            "0\n",
            "Bank of Canada holds key interest rate steady at 1.75%. Decision in line with what economists were expecting\n",
            "0\n",
            "Expect Bank of Canada to take heart from an improving U.S. economic climate: Don Pittis. The sun is shining, the birds are chirping, but central bankers must plan for storms\n",
            "0\n",
            "All eyes on Bank of Canada's interest rate decision, view of global economic climate. Governor Stephen Poloz to give 1st policy announcement since early July\n",
            "0\n",
            "Whitehorse residents paint picture of what dismal rental market looks like. Median price for renting in Whitehorse is $1,050 a month, according to Yukon Bureau of Statistics\n",
            "0\n",
            "European Central Bank keeps rates low as new president takes helm. Decision follows a similar one by the U.S. Federal Reserve\n",
            "0\n",
            "The Liberals' first-time homebuyers incentive is a bad deal. The program asks too much in exchange for savings of a couple of hundred dollars a month\n",
            "0\n",
            "Toronto home sales jump 17.4% in December, average price up 12%. Condos saw the biggest price gains through 2019\n",
            "0\n",
            "European Central Bank keeps rates low as new president takes helm. Decision follows a similar one by the U.S. Federal Reserve\n",
            "0\n",
            "Canadian and U.S. economies are converging but danger lurks: Don Pittis. Poloz and Wilkins warn that markets overestimate the power of a rate-cut quick fix\n",
            "0\n",
            "Toronto to explore tax targeting vacant storefronts on city's main streets. A busy 2.3-kilometre section of Queen Street East is home to 44 vacant stores\n",
            "0\n",
            "More Fed cuts expected to push Canadian interest rates lower: Don Pittis. Watch for effects of shrinking global economy to hit Canada as well\n",
            "0\n",
            "Bank of Canada unlikely to follow any Fed interest rate cut. U.S. central bank expected to drop interbank lending rate by 25 basis points\n",
            "0\n",
            "Name calling and market pressure may curb U.S. Fed's independence: Don Pittis. With few signs of recession, could Jerome  Powell leave rates unchanged even if he wanted to?\n",
            "0\n",
            "Name calling and market pressure may curb U.S. Fed's independence: Don Pittis. With few signs of recession, could Jerome  Powell leave rates unchanged even if he wanted to?\n",
            "0\n",
            "Bank of Canada's Poloz says global growth to remain slow, low global interest rates. Central bank kept key interest rate on hold last week at 1.75 per cent\n",
            "0\n",
            "New home construction in Halifax driving higher assessment values. Home values in Nova Scotia up 2.9 per cent, commercial properties 1.2 per cent\n",
            "0\n",
            "Pallister repeats call for Ottawa to borrow on behalf of provinces. Provinces need help to keep costs of COVID-19 down, Manitoba premier says\n",
            "-1\n",
            "Faced with rental housing crisis, Rosemont—La Petite-Patrie moves to restrict Airbnbs. Borough cracks down on hundreds of property owners who are turning apartments into hotels\n",
            "0\n",
            "Inflation climbs to 2.2%, Statistics Canada reports. Annual pace of inflation heated up in November as gas prices rose\n",
            "0\n",
            "The price of an average London home could hit $450K in 2020. While sales aren't expected to match the frenetic pace of 2017, tight inventories will cause prices to rise\n",
            "-1\n",
            "Calgary housing market among the most affordable in Canada, report says. 'If you are the median income earner, there are options for you'\n",
            "0\n",
            "Canada's economy rebounded with 0.1% GDP increase in November. October contraction reversed by slight expansion in November\n",
            "1\n",
            "Port Hawkesbury Paper cutting wood deliveries due to declining markets, COVID-19. Nova Scotia sawmills expecting almost immediate effects from the change\n",
            "0\n",
            "City of Charlottetown wants short-term rentals defined as tourism accommodations. 'We just want to make sure that they're properly regulated'\n",
            "0\n",
            "Bank of Canada flags Alberta economic challenges in latest update. Crown corporation anticipates province will stablilize next year\n",
            "0\n",
            "City of Charlottetown wants short-term rentals defined as tourism accommodations. 'We just want to make sure that they're properly regulated'\n",
            "0\n",
            "Hamilton looks at an empty homes tax to ward off speculators and help local rents. More than half of vacant Vancouver homes are back on the market, but can it work in Hamilton?\n",
            "0\n",
            "Blip or trend? This week will test Canada's job-creation machine: Don Pittis. Some experts called doom when the country's job numbers plunged. But there's another view.\n",
            "0\n",
            "Powell hints Federal Reserve will cut rates if needed over trade wars. Expectations are rising that the Fed will cut rates at least once and possibly twice before year's end\n",
            "0\n",
            "Business sentiment improves after downturn early in year. Global trade tensions, weakness in oilpatch still hang over Canadian outlook\n",
            "-1\n",
            "Police worry about budget cuts at social agencies as crime rate increases. DOAP Team is dramatically scaling back patrols\n",
            "0\n",
            "Bank of Canada resists pressure to cut its interest rate — for now. Central bank leaves key rate at 1.75%, but appears ready to adjust lower\n",
            "0\n",
            "U.S. Federal Reserve cuts interest rates for 3rd time this year. The target range for the federal funds is now 1.5 to 1.75%\n",
            "0\n",
            "Bank of Canada flags Alberta economic challenges in latest update. Crown corporation anticipates province will stablilize next year\n",
            "0\n",
            "Powell hints Federal Reserve will cut rates if needed over trade wars. Expectations are rising that the Fed will cut rates at least once and possibly twice before year's end\n",
            "0\n",
            "Canada's economy lost 2,200 jobs last month. Jobless rate ticks up to 5.5%, although past year has seen 421,000 jobs added\n",
            "-1\n",
            "As the U.S. economy tilts toward concern, Canada's is on the upswing: Don Pittis. Federal Reserve chair Jerome Powell holds interest rates steady, but opens the door to future cuts\n",
            "-1\n",
            "Police worry about budget cuts at social agencies as crime rate increases. DOAP Team is dramatically scaling back patrols\n",
            "0\n",
            "As the U.S. economy tilts toward concern, Canada's is on the upswing: Don Pittis. Federal Reserve chair Jerome Powell holds interest rates steady, but opens the door to future cuts\n",
            "-1\n",
            "If COVID-19 creates an economic crisis, many see stimulus as a chance for change: Don Pittis. Morneau and others must decide whether to use bailouts to perpetuate what some see as an ailing status quo\n",
            "0\n",
            "Saint John tax assessment not yet catching up to hot sales market. 1.83% assessment growth actually improves on much of past 6 years\n",
            "1\n",
            "Calgary had a lot more shoplifting but a lot fewer homicides last year. City's crime severity index rose 5% in 2018 while provincial rating remains steady\n",
            "1\n",
            "Retailers foresee holiday joy — even as Poloz looks to hold line on rates: Don Pittis. While the world cuts interest rates, the Bank of Canada likely won't if we keep shopping\n",
            "0\n",
            "If COVID-19 creates an economic crisis, many see stimulus as a chance for change: Don Pittis. Morneau and others must decide whether to use bailouts to perpetuate what some see as an ailing status quo\n",
            "0\n",
            "'Stop building' hotels in Calgary, industry urges, as supply of rooms outstrips demand. City has seen 2,600 new rooms added in the past 3 years, and 1,200 of those are less than a year old\n",
            "0\n",
            "'Stop building' hotels in Calgary, industry urges, as supply of rooms outstrips demand. City has seen 2,600 new rooms added in the past 3 years, and 1,200 of those are less than a year old\n",
            "0\n",
            "'Secret' memo outlines tools the finance department and Bank of Canada could use in a recession. Economists say Ottawa needs a new playbook to tackle the next global recession\n",
            "0\n",
            "Growing demand prompts Sydney shelter to move into bigger location. 'It's very difficult to find affordable housing right now in this community'\n",
            "0\n",
            "'Stop building' hotels in Calgary, industry urges, as supply of rooms outstrips demand. City has seen 2,600 new rooms added in the past 3 years, and 1,200 of those are less than a year old\n",
            "0\n",
            "Last week's gloom and doom has not seized Canadian economy yet: Don Pittis. Can the economy withstand the latest barrage of gloomy economic news?\n",
            "0\n",
            "'Secret' memo outlines tools the finance department and Bank of Canada could use in a recession. Economists say Ottawa needs a new playbook to tackle the next global recession\n",
            "0\n",
            "New mortgage loans slowed in Canada but overall value is still rising, says CMHC. The average value of a mortgage reached $209,570, which is more than 3% higher than a year ago\n",
            "0\n",
            "Rising home prices encourage consumers to borrow and spend, giving economy a boost. Bank of Canada study analyzes spending triggered by borrowing against the house\n",
            "-1\n",
            "New mortgage loans slowed in Canada but overall value is still rising, says CMHC. The average value of a mortgage reached $209,570, which is more than 3% higher than a year ago\n",
            "0\n",
            "Who is Daniel Bard, the elusive man at centre of missing money scandal?. Moncton man, formerly employed by government-funded agency, being investigated by RCMP for breach of trust\n",
            "-1\n",
            "Growing push to tax both vacant, luxury homes during city's budget process. Hiking tax on pricey properties is 'housing paying for housing,' councillor says\n",
            "0\n",
            "Who is Daniel Bard, the elusive man at centre of missing money scandal?. Moncton man, formerly employed by government-funded agency, being investigated by RCMP for breach of trust\n",
            "-1\n",
            "Everything happens at once: how one week of the COVID-19 crisis went for the Trudeau government. The early response is hitting the right notes - but there will be opportunities for recrimination later\n",
            "0\n",
            "When student housing was hard to come by in Vancouver. In 1981, there wasn't much available for students and what was available was pretty expensive\n",
            "0\n",
            "Government says new Victoria micro-apartments will help with middle-income housing crisis. Housing advocates say the project still doesn't address the growing need for middle-income family housing\n",
            "0\n",
            "Government says new Victoria micro-apartments will help with middle-income housing crisis. Housing advocates say the project still doesn't address the growing need for middle-income family housing\n",
            "0\n",
            "When student housing was hard to come by in Vancouver. In 1981, there wasn't much available for students and what was available was pretty expensive\n",
            "0\n",
            "Saskatoon downtown office vacancy rate will increase as River Landing progresses: analyst. Vacancy rate will grow to more than 20 per cent, observers say\n",
            "0\n",
            "Pro-democracy activist Joshua Wong barred from Hong Kong election. Wong has been repeatedly arrested and jailed since playing key role in 2014 protests\n",
            "0\n",
            "Moncton gets fair share of real estate boom. Home sales in Moncton are up 23.7 per cent compared to the first five months of 2018\n",
            "1\n",
            "Counterfeit crackdown; cannabis costs: CBC's Marketplace consumer cheat sheet. Newsletter: Consumer and health news you need from the week\n",
            "0\n",
            "Nygard company signed $50M US loan security on Christmas Day. Peter Nygard also owes $1.6M to crisis-response firm; company wants Manitoba court to make him pay\n",
            "-1\n",
            "Counterfeit crackdown; cannabis costs: CBC's Marketplace consumer cheat sheet. Newsletter: Consumer and health news you need from the week\n",
            "0\n",
            "Ontario's rising rents hurt the poor, Ottawa advocates say. Province raises cap on rent increase to 2.2% for 2020, highest hike since 2013\n",
            "-1\n",
            "CMHC reports annual pace of housing starts climbed 1.9% in August. Housing starts rose to 226,639 units in August, up from 222,467 units in July\n",
            "1\n",
            "Green Party bill to provide snapshot of short-term rentals on P.E.I. using 'accurate, objective data'. MLA says idea is to eventually curtail growth of the industry to ease pressure on housing\n",
            "0\n",
            "Harsh winter cools Sudbury's real estate market. In some aspects it's cheaper to own a home than rent, Real Estate Board says\n",
            "0\n",
            "Harsh winter cools Sudbury's real estate market. In some aspects it's cheaper to own a home than rent, Real Estate Board says\n",
            "0\n",
            "N.L. home construction at 50-year low, but sales on the rise following disastrous year. Real estate leaders hoping industry has bottomed out, and better days ahead\n",
            "0\n",
            "Stock markets sell off as inverted yield curve in bond market prompts recession fears. Dow Jones loses 800 points, TSX down almost 300\n",
            "-1\n",
            "N.L. home construction at 50-year low, but sales on the rise following disastrous year. Real estate leaders hoping industry has bottomed out, and better days ahead\n",
            "0\n",
            "With real estate market booming, Montreal property assessments climb 13.7%. Beaconsfield, Hampstead, Mount Royal, Kirkland and Westmount among those with biggest jumps\n",
            "0\n",
            "From fossil fuels to Muskrat: How MUN could lead the charge to electrify public buildings. Shift to electricity at Memorial University could displace 11 million litres of diesel annually\n",
            "0\n",
            "Can the Tories double the rate of job creation in Manitoba?. PCs promise 40,000 new jobs in 4 years ... that's more new jobs than Manitoba added in the previous 9 years\n",
            "1\n",
            "With real estate market booming, Montreal property assessments climb 13.7%. Beaconsfield, Hampstead, Mount Royal, Kirkland and Westmount among those with biggest jumps\n",
            "0\n",
            "New cabinet must make the best of an uncertain economic outlook: Don Pittis. Market indicators turn optimistic on global economy but others say, 'Hold on'\n",
            "1\n",
            "From fossil fuels to Muskrat: How MUN could lead the charge to electrify public buildings. Shift to electricity at Memorial University could displace 11 million litres of diesel annually\n",
            "0\n",
            "Former Bank of Canada governor Mark Carney to serve as UN special envoy on climate. Carney drew international acclaim during his 5 years as Canada's top central banker\n",
            "0\n",
            "U.S. central bank cuts interest rate again — but split on what to do next. Federal Reserve moving to stimulate economy as trade fears mount\n",
            "-1\n",
            "Former Bank of Canada governor Mark Carney to serve as UN special envoy on climate. Carney drew international acclaim during his 5 years as Canada's top central banker\n",
            "0\n",
            "Interest in off-grid homes growing, but mortgages haven't kept pace. People who work in the solar power industry report growing interest in self-sufficient homes\n",
            "0\n",
            "Rent hike tension spills over at Carling Avenue highrise. After protest, Timbercreek management agrees to meet with tenants\n",
            "0\n",
            "CMHC sees 'moderate overvaluation' in Canada's housing market, but little vulnerability overall. Quarterly report finds pockets of concern, but overall lower level of risk\n",
            "0\n",
            "U.S. central bank cuts interest rate again — but split on what to do next. Federal Reserve moving to stimulate economy as trade fears mount\n",
            "-1\n",
            "The search for jobs and a recovery in Red Deer: 'There's absolutely nothing out there'. People, business owners, social agencies 'continue to struggle' in central Alberta city\n",
            "0\n",
            "Demand for rental units on the rise in Saint John. Study indicates 1,500 new rental units in development, thousands more needed\n",
            "0\n",
            "How fast is your cost of living going up? Play our interactive game. Try your hand at guessing inflation rates in various categories\n",
            "0\n",
            "Canadians took on less debt in first quarter of 2019 — but total amount they owe is still growing. Debt to disposable income ratio holds steady at 177%, just below record high set in 2018\n",
            "1\n",
            "The search for jobs and a recovery in Red Deer: 'There's absolutely nothing out there'. People, business owners, social agencies 'continue to struggle' in central Alberta city\n",
            "0\n",
            "This Toronto landlord has only raised rent by $100 — since the 1980s. Downtown apartments going for as little as $800 per month, thanks to novelist David Kendall\n",
            "0\n",
            "St. John's housing prices will lead country in growth, according to Moody's. Economist says below-trend prices, drop in unemployment rate leading to predicted increase\n",
            "-1\n",
            "Short-term rental owners speak out over proposed Charlottetown bylaw. 'If all of my units were returned to the long-term market — none of them are affordable'\n",
            "0\n",
            "Federal Reserve holds key interest rate steady — but its patience is wearing thin. U.S. central bank keeps benchmark rate in range between 2.25% and 2.5%\n",
            "1\n",
            "How fast is your cost of living going up? Play our interactive game. Try your hand at guessing inflation rates in various categories\n",
            "0\n",
            "Housing market rebounded in May from record lows earlier in the year, CREA says. Number of home sales inching higher, but prices still lower than they were in 2018\n",
            "1\n",
            "Federal Reserve holds key interest rate steady — but its patience is wearing thin. U.S. central bank keeps benchmark rate in range between 2.25% and 2.5%\n",
            "1\n",
            "Housing market rebounded in May from record lows earlier in the year, CREA says. Number of home sales inching higher, but prices still lower than they were in 2018\n",
            "1\n",
            "His business nearly collapsed when the EU was created. Now this customs broker is readying for a Brexit boom. With Boris Johnson poised to 'get Brexit done,' George Baker says he could see a 500 per cent jump in business\n",
            "1\n",
            "Short-term rental owners speak out over proposed Charlottetown bylaw. 'If all of my units were returned to the long-term market — none of them are affordable'\n",
            "0\n",
            "Federal Reserve holds key interest rate steady — but its patience is wearing thin. U.S. central bank keeps benchmark rate in range between 2.25% and 2.5%\n",
            "1\n",
            "To pay off or borrow more is the question facing Canadians: Don Pittis. As recession threatens and an election beckons is it time for us to borrow or time to shuck debt? \n",
            "0\n",
            "To pay off or borrow more is the question facing Canadians: Don Pittis. As recession threatens and an election beckons is it time for us to borrow or time to shuck debt? \n",
            "0\n",
            "Global uncertainty prompts rethink of B.C. budget projections. Finance Minister Carole James delivered the 2019 first-quarter financial results Monday\n",
            "-1\n",
            "'Unprecedented times' could mean unprecedented options on the table to aid provinces. Academics, think-tanks believe federal government may need to do more\n",
            "0\n",
            "Toronto police union calls allegations it mishandled millions of dollars 'misinformation'. TPA sold its HQ for $7.4M. It was flipped a year later for $11.5M, records show\n",
            "0\n",
            "International buyers eye N.S. vacation properties — especially in Cape Breton. Recent numbers from Statistics Canada show N.S. has higher rate of non-resident owners than B.C., Ontario\n",
            "0\n",
            "North Bay real estate investors share how to finalize the deal. Dave and Melanie Dupuis share tips on navigating the real estate investment world\n",
            "0\n",
            "Dow at record above 27,000 as U.S. rate cuts look likely. Powell's testimony to Congress indicates key rate could be cut in July\n",
            "0\n",
            "Saint John housing programs more effective, but shelter use on the rise, report shows. More co-ordinated approach to homelessness needed, says Human Development Council \n",
            "0\n",
            "North Bay real estate investors share how to finalize the deal. Dave and Melanie Dupuis share tips on navigating the real estate investment world\n",
            "0\n",
            "Saint John housing programs more effective, but shelter use on the rise, report shows. More co-ordinated approach to homelessness needed, says Human Development Council \n",
            "0\n",
            "U.S. corporate leaders swing left to fix 'frayed' American dream: Don Pittis. But critics call 11th-hour conversion a smokescreen to block new rules and taxes\n",
            "0\n",
            "Extreme measures: European governments pull out the stops to slow COVID-19. Europe's measures could offer a glimpse of Canada's future\n",
            "0\n",
            "'We should approach the issue very carefully': Nations pressured to loosen COVID-19-related rules. The decisions are complicated because each country is on its own coronavirus arc\n",
            "0\n",
            "Extreme measures: European governments pull out the stops to slow COVID-19. Europe's measures could offer a glimpse of Canada's future\n",
            "0\n",
            "Green MLA calls on province to regulate short-term rentals. Minister Ernie Hudson says he wants to collaborate with municipalities, not 'dictate' \n",
            "0\n",
            "Extreme measures: European governments pull out the stops to slow COVID-19. Europe's measures could offer a glimpse of Canada's future\n",
            "0\n",
            "'We should approach the issue very carefully': Nations pressured to loosen COVID-19-related rules. The decisions are complicated because each country is on its own coronavirus arc\n",
            "0\n",
            "Yellowknife's housing market slows as economic slump looms on the horizon: CMHC. CMHC's annual report on Northern housing shows mixed outlook across the 3 territories \n",
            "-1\n",
            "Even in an 'affordable' Canadian city, cost-of-living squeeze has people putting pressure on politicians. Cost of living is a big federal election issue, even in places where daily expenses are lower than average\n",
            "-1\n",
            "P.E.I. needs more pet-friendly housing, say violence prevention advocates. 'Finding housing even if you have no barriers is very very difficult'\n",
            "0\n",
            "Yellowknife's housing market slows as economic slump looms on the horizon: CMHC. CMHC's annual report on Northern housing shows mixed outlook across the 3 territories \n",
            "-1\n",
            "Even in an 'affordable' Canadian city, cost-of-living squeeze has people putting pressure on politicians. Cost of living is a big federal election issue, even in places where daily expenses are lower than average\n",
            "-1\n",
            "Having trouble finding housing in eastern P.E.I.? Rotary wants to know. Vacancy rates on P.E.I. are at a record low\n",
            "0\n",
            "Even in an 'affordable' Canadian city, cost-of-living squeeze has people putting pressure on politicians. Cost of living is a big federal election issue, even in places where daily expenses are lower than average\n",
            "-1\n",
            "When grocery stores are the only game in town, even entrepreneurs turn into employees. Leadership coaches, fashion designers jump at chance to deliver groceries, wash down produce\n",
            "0\n",
            "Vancouver Tenants Union wants to build an eviction database. Group says there's a 'big gap' because most eviction data isn't currently recorded anywhere\n",
            "0\n",
            "Province not prepared to ease policies as housing market sputters. Vancouver homeowners cite rising taxes, falling equity; NDP argues moderation is improving affordability\n",
            "0\n",
            "Province not prepared to ease policies as housing market sputters. Vancouver homeowners cite rising taxes, falling equity; NDP argues moderation is improving affordability\n",
            "0\n",
            "Low-income rates could rise as StatsCan moves to redraw poverty line. Poverty rates increased by 2.2 per cent the last time the measurement changed in 2008\n",
            "-1\n",
            "Oil prices take biggest plunge in decades, taking another bite out of reeling Alberta. Alberta Premier Kenney, with softened tone, shifts emphasis from restraint to protection of economy, jobs\n",
            "0\n",
            "Getting past the senior stereotypes: U of A researcher says attitudes need to mature. As population ages, discrimination based on age will cause increasing harm\n",
            "0\n",
            "Getting past the senior stereotypes: U of A researcher says attitudes need to mature. As population ages, discrimination based on age will cause increasing harm\n",
            "0\n",
            "Shutdown order will kill some businesses, advocates warn. Ontario, Quebec ordering non-essential businesses closed for 14 days by midnight\n",
            "0\n",
            "Low-income rates could rise as StatsCan moves to redraw poverty line. Poverty rates increased by 2.2 per cent the last time the measurement changed in 2008\n",
            "-1\n",
            "'Recessionary conditions' pushing home prices lower in B.C., report says. Median price projected to be 4.1% lower in 2019, marking 1st decline in 7 years\n",
            "0\n",
            "Mike Bloomberg courts black voters, but past record as NYC mayor under scrutiny. Opponents unearth past comments on policing and housing, which they say aren't reflective of Democratic Party\n",
            "0\n",
            "Support coming for Canadians quarantined due to coronavirus, finance minister says. Liberal government will increase the risk adjustment provision in the upcoming budget\n",
            "0\n",
            "All eyes on Canadian jobs numbers as election heads into 5th week: Don Pittis. Still few signs of Canadian recession, but this week's data may tell us more\n",
            "0\n",
            "Why this economist says equalization reform isn't the answer if Alberta wants help during its busts. Revised fiscal stabilization program would hold most promise for the province, Bev Dahlby argues\n",
            "0\n",
            "'They squandered the good times': Poilievre says Canada lacks 'cushion' to weather economic crises. Conservative finance committee members criticize Liberal record ahead of federal budget\n",
            "-1\n",
            "Should you feel guilty for taking family money to buy a home?. One woman explains why she felt guilty after getting family money to pay for her down payment\n",
            "0\n",
            "Former Bank of Canada governor Mark Carney urges financial sector to act against climate change. Carney is set to become the UN's special envoy for climate change next year\n",
            "0\n",
            "'Cheaper, warmer and newer': P.E.I. seniors move into new affordable building. 'Some people can’t afford $1,200, $1,300 a month in rent, it’s crazy' \n",
            "0\n",
            "Fort Saskatchewan condo residents waiting for answers a month after evacuation. Resident says 95 per cent of belongings left behind, doesn't know when he can get them\n",
            "0\n",
            "High household debt, possible housing market shocks are main risks to the economy: Bank of Canada. Stephen Poloz, governor of the Bank of Canada, will speak to reporters after latest financial review\n",
            "0\n",
            "Vancouver is still in a housing crisis. But when will we know if it's over?. It's a question without a defined answer — but one that could have big policy implications down the road\n",
            "0\n",
            "Highrise condo buyer denied insurance due to flood emergency. Aviva Canada turned down Inna Nei, citing state of emergency declared in April\n",
            "-1\n",
            "Highrise condo buyer denied insurance due to flood emergency. Aviva Canada turned down Inna Nei, citing state of emergency declared in April\n",
            "-1\n",
            "She fled domestic abuse. Now she and her daughter are victims of the housing crisis. Shelters are full, wait lists are long and market rents are too high for most single mothers\n",
            "-1\n",
            "When 'math is accessible to any brain,' we can make better political, social choices, says mathematician. Math could help people make more rational, thought-out decisions, says John Mighton\n",
            "0\n",
            "Zombie debt will haunt more Canadians as scourge of indebtedness rises: experts. Be warned, old debts can be resurrected\n",
            "0\n",
            "How a leaner, regulated Nalcor could save millions and better protect consumers. Liberty Consulting is proposing a dramatic shakeup at embattled Crown corporation in the Muskrat era\n",
            "0\n",
            "How a leaner, regulated Nalcor could save millions and better protect consumers. Liberty Consulting is proposing a dramatic shakeup at embattled Crown corporation in the Muskrat era\n",
            "0\n",
            "Why 4 websites give you 4 different credit scores — and none is the number most lenders actually see. The most popular credit score that lenders use in Canada can’t be accessed directly by consumers\n",
            "0\n",
            "A tale of two tenants: B.C. renters feeling affordability squeeze as parties campaign on housing. Metro Vancouver is home to 6 of the most expensive ridings for renters in all of Canada\n",
            "0\n",
            "Why 4 websites give you 4 different credit scores — and none is the number most lenders actually see. The most popular credit score that lenders use in Canada can’t be accessed directly by consumers\n",
            "0\n",
            "Island voters prepare to go back to the polls. 'People were not looking forward to this election, more like dreading this election'\n",
            "0\n",
            "Island voters prepare to go back to the polls. 'People were not looking forward to this election, more like dreading this election'\n",
            "0\n",
            "Here's what Calgarians will be paying more for in 2020. Here's a list of what goes up in price for Calgarians as of Jan. 1\n",
            "0\n",
            "COVID-19: Here's what's happening around the world March 4. Italy cases top 3,000 with over 100 dead, as the sick in South Korea wait for beds\n",
            "0\n",
            "Stock markets down on growing concern about coronavirus in China. Canada's main stock index fell for the first time in 7 sessions on concerns about the outbreak\n",
            "0\n",
            "'Tent town' draws attention to Island's affordable housing crisis. 'There are people that are very close to this situation … there are people living in cars.'\n",
            "0\n",
            "Why earnings in Alberta have been stagnant for years. Albertans earn less because they're working less, and working differently\n",
            "0\n",
            "COVID-19: Here's what's happening around the world March 4. Italy cases top 3,000 with over 100 dead, as the sick in South Korea wait for beds\n",
            "0\n",
            "Modelling suggests as many as 800,000 COVID-19 infections could sweep Alberta, Premier Jason Kenney says. ‘Perhaps the greatest challenge of our generation,’ Kenney says during televised address \n",
            "0\n",
            "'Rents have just gone sky high': Cardigan candidates, voters weigh in on housing crisis. 'It's nothing that a senior can really afford'\n",
            "0\n",
            "Forget Toronto. Buying in P.E.I. increasingly 'cutthroat' as home prices rise. 'People are banging on doors, saying 'I really like your house, are you interested in selling?'\n",
            "0\n",
            "Scheer pitches east-west energy corridor, blasts Trudeau for 'all-out attack' on oil. Conservative leader insists he can return budget to balance without deep spending cuts\n",
            "-1\n",
            "Ford layoffs another hint Canada is heading for peak car: Don Pittis. The automotive industry has lost its place as a keystone of the Canadian economy\n",
            "0\n",
            "Recounting a devastating week in North America's biggest oil play. A day-by-day account in the west Texas oilfields as oil markets in a free fall\n",
            "0\n",
            "Recounting a devastating week in North America's biggest oil play. A day-by-day account in the west Texas oilfields as oil markets in a free fall\n",
            "0\n",
            "Toronto area housing sales up 24.3% in July, prices rise due to tighter supply. Overall average selling price for properties in GTA was $806,755\n",
            "0\n",
            "Liberals move to deliver tax cut they say will help 20 million Canadians. Finance minister says new measure will lower taxes for people earning less than about $150K a year\n",
            "0\n",
            "PM says closures, social distancing measures could be in place for weeks or months. COVID-19 emergency funds will be flowing in 2 to 3 weeks, government promises\n",
            "0\n",
            "Toronto area housing sales up 24.3% in July, prices rise due to tighter supply. Overall average selling price for properties in GTA was $806,755\n",
            "0\n",
            "'I've never felt shame like this in my life': 500 homeless, 5,000 await affordable housing. Despite desperate need for affordable housing, new agreement will create just 151 units in first 3 years \n",
            "0\n",
            "What's the difference between the Conservative and Liberal platforms? The colour: Robyn Urback. This election essentially comes down to whose face you won't mind staring at for the next 4 years\n",
            "0\n",
            "What's the difference between the Conservative and Liberal platforms? The colour: Robyn Urback. This election essentially comes down to whose face you won't mind staring at for the next 4 years\n",
            "0\n",
            "Stocks fall as trade concerns spark growth fears, push investors to bonds. Each of the major U.S. indexes suffered their fourth decline in five sessions\n",
            "0\n",
            "Stocks fall as trade concerns spark growth fears, push investors to bonds. Each of the major U.S. indexes suffered their fourth decline in five sessions\n",
            "0\n",
            "CIBC, TD close bleak 4th-quarter earning season with lower profit. CIBC drew an impairment charge for the sale of its stake in Barbadian bank\n",
            "0\n",
            "CIBC, TD close bleak 4th-quarter earning season with lower profit. CIBC drew an impairment charge for the sale of its stake in Barbadian bank\n",
            "0\n",
            "Green Party platform aims to transition economy, protect consumers, promote tax fairness. Leader Elizabeth May says full costing of election promises to come within a week\n",
            "0\n",
            "As province gets stable credit ratings, finance minister says can't cut services for surplus. Tom Osborne is no longer promising the province will reach surplus in 2022-23\n",
            "-1\n",
            "Transat still negotiating takeover with Air Canada, as rival bidder says counteroffer is coming. Two companies are still negotiating until exclusive window closes on June 26\n",
            "0\n",
            "Coronavirus: Here's what's happening in Canada and around the world on March 13. The federal government warns Canadians against travelling outside of the country\n",
            "0\n",
            "Coronavirus: Here's what's happening in Canada and around the world on March 13. The federal government warns Canadians against travelling outside of the country\n",
            "0\n",
            "Coronavirus: What's happening in Canada and around the world on March 27. Bank of Canada makes another emergency rate cut, U.K. prime minister tests positive\n",
            "-1\n",
            "Coronavirus: Here's what's happening in Canada and the world March 19. PM talks about need for increased testing, travel restrictions between Canada and U.S.\n",
            "0\n",
            "Crown, Keith Hobbs spar in day 13 of former mayor's extortion trial. Keith Hobbs, wife Marisa, Mary Voss all face one charge each of extortion\n",
            "0\n",
            "Crown, Keith Hobbs spar in day 13 of former mayor's extortion trial. Keith Hobbs, wife Marisa, Mary Voss all face one charge each of extortion\n",
            "0\n",
            "Crown, Keith Hobbs spar in day 13 of former mayor's extortion trial. Keith Hobbs, wife Marisa, Mary Voss all face one charge each of extortion\n",
            "0\n",
            "Signs gambling has become a potential problem. And what you can do to get back on track\n",
            "0\n",
            "Signs gambling has become a potential problem. And what you can do to get back on track\n",
            "0\n",
            "On housing, local authorities bemoan territory's 'paternalistic' policies. Local authorities, contractors point finger at the N.W.T. Housing Corporation for granting ‘limited control’\n",
            "0\n",
            "N.B. COVID-19 roundup: Province braces for 'next big wave' of coronavirus. Premier Blaine Higgs and Dr. Jennifer Russell say returning travellers who have no symptoms pose risk\n",
            "0\n",
            "OPINION | NDP climate plan tries (and fails) to carve out middle ground. The plan is riddled with inconsistencies and short on details\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqxuE1-C8C3Q",
        "colab_type": "code",
        "outputId": "836828f7-2e43-4e02-a7ba-3324c58ad070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "out_filepath = data_folder + \"unannotated_mortgagerate_CBC_predictions.csv\"\n",
        "print(out_filepath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./drive/My Drive/Colab Notebooks/capstone/data//unannotated_mortgagerate_CBC_predictions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3wJcDN0-NcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df.to_csv(out_filepath,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LJrM4eJ4-6j",
        "colab_type": "code",
        "outputId": "c6988ba8-6365-48ac-bec4-9967f79e1823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "mort_test_df = pd.read_csv(data_folder + \"/test.csv\", header=None)\n",
        "\n",
        "mort_test_df.head()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>Finnish metal products company Componenta Oyj ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Incap and Lankapaja aim to enter into actual a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>Turkish stocks tumble as crackdown on lira spe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Summer Winds Down, and Big Tech Is Called Befo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>Here's why the slump in semiconductor stocks m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                                  1\n",
              "0 -1  Finnish metal products company Componenta Oyj ...\n",
              "1  1  Incap and Lankapaja aim to enter into actual a...\n",
              "2 -1  Turkish stocks tumble as crackdown on lira spe...\n",
              "3  1  Summer Winds Down, and Big Tech Is Called Befo...\n",
              "4 -1  Here's why the slump in semiconductor stocks m..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_vRywDs-ePH",
        "colab_type": "code",
        "outputId": "2817e498-7110-46fc-b1eb-f04d51f4f3dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "correct = 0\n",
        "severe_incorrect = 0\n",
        "for i in range(len(corpus.test)):\n",
        "  print(i)\n",
        "  sentence = Sentence(mort_test_df.iloc[i,1])\n",
        "  mortgage_classifier.predict(sentence)\n",
        "  if sentence.labels[0].value == corpus.test[i].labels[0].value:\n",
        "    correct += 1\n",
        "  else:\n",
        "\n",
        "    print(\"INCORRECT CLASSIFICATION: \")\n",
        "    print(\"TEXT: \", sentence)\n",
        "    print(\"TRUE LABEL: \", corpus.test[i].labels[0].value)\n",
        "    print(\"PRED: \",sentence.labels[0].value)\n",
        "    \n",
        "    if corpus.test[i].labels[0].value != \"0\" and sentence.labels[0].value != \"0\":\n",
        "      severe_incorrect += 1\n",
        "\n",
        "\n",
        "  print(\"----\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "----\n",
            "1\n",
            "----\n",
            "2\n",
            "----\n",
            "3\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Summer Winds Down, and Big Tech Is Called Before Congress. The newest jobs numbers are expected to show healthy gains, and Detroit automakers will report sales for August.\"   [− Tokens: 28  − Sentence-Labels: {'class': [0 (0.5657)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "4\n",
            "----\n",
            "5\n",
            "----\n",
            "6\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Many listed stocks currently undervalued. More than half of listed stocks here are trading at prices below \"book value\" . suited for valuing capital-intensive companies or financial businesses with a lot of .\"   [− Tokens: 33  − Sentence-Labels: {'class': [1 (0.4755)]}]\n",
            "TRUE LABEL:  0\n",
            "PRED:  1\n",
            "----\n",
            "7\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Revenue grew 1 percent to euro742 .2 million US$ 964 million from euro735 million .\"   [− Tokens: 15  − Sentence-Labels: {'class': [0 (0.8079)]}]\n",
            "TRUE LABEL:  1\n",
            "PRED:  0\n",
            "----\n",
            "8\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"The Point Village , designed by Scott Tallon Walker , will include a shopping center , office premises , a hotel and a cinema .\"   [− Tokens: 25  − Sentence-Labels: {'class': [0 (0.9933)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "9\n",
            "----\n",
            "10\n",
            "----\n",
            "11\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Outokumpu of Finland , stainless steel manufacturer , plans to enter into a supply agreement with the Indian Railways .\"   [− Tokens: 20  − Sentence-Labels: {'class': [0 (0.982)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "12\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"How 9/11 still affects stock, bond investors. Moreover, without strong economic growth to cushion it, the market likely will . . “China developed a business model based on reinforcing the worst aspects of .\"   [− Tokens: 34  − Sentence-Labels: {'class': [0 (0.6038)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "13\n",
            "----\n",
            "14\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"Aspocomp has repaid its interest bearing liability to Standard Chartered Bank and will use the rest of the consideration to partially repay its interest bearing liabilities in Finland and to improve its liquidity .\"   [− Tokens: 34  − Sentence-Labels: {'class': [0 (0.9596)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "15\n",
            "----\n",
            "16\n",
            "----\n",
            "17\n",
            "----\n",
            "18\n",
            "----\n",
            "19\n",
            "----\n",
            "20\n",
            "----\n",
            "21\n",
            "----\n",
            "22\n",
            "INCORRECT CLASSIFICATION: \n",
            "TEXT:  Sentence: \"This includes a EUR 39.5 mn change in the fair value of investment properties .\"   [− Tokens: 15  − Sentence-Labels: {'class': [0 (0.992)]}]\n",
            "TRUE LABEL:  -1\n",
            "PRED:  0\n",
            "----\n",
            "23\n",
            "----\n",
            "24\n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg-KPkMC370O",
        "colab_type": "code",
        "outputId": "64299eb4-dc9d-45ed-ec2e-225fc1616b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "print(\"CORRECT: \",correct/len(corpus.test))\n",
        "print(\"INCORRECT: \",1 - correct/len(corpus.test))\n",
        "print(\"OPPOSITE PREDICTIONS (SEVERELY INCORRECT): \",severe_incorrect/len(corpus.test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CORRECT:  0.68\n",
            "INCORRECT:  0.31999999999999995\n",
            "OPPOSITE PREDICTIONS (SEVERELY INCORRECT):  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzj8_OEJ63_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Approximately 70% correct\n",
        "#In incorrect labels, most had a true label of negative but were overfit to be neutral\n",
        "\n",
        "#Not many positive news examples likely means that accuracy in positive tags is not that high"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}