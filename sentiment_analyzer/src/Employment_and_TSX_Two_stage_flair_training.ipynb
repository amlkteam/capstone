{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rp6aEGVRYlYp"
   },
   "source": [
    "## Two stage flair training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NVY0ZiGk38i_",
    "outputId": "a0bf10d6-8cbd-4f22-9f81-e5abc3d5d76c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/flairNLP/flair.git\n",
      "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-ccur1r0t\n",
      "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-ccur1r0t\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting transformers>=2.10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
      "\u001b[K     |████████████████████████████████| 665kB 6.1MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.6.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.22.2.post1)\n",
      "Collecting langdetect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
      "\u001b[K     |████████████████████████████████| 983kB 17.7MB/s \n",
      "\u001b[?25hCollecting segtok>=1.5.7\n",
      "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (0.1.2)\n",
      "Collecting bpemb>=0.2.9\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
      "Collecting pytest>=5.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/f9/9f2b6c672c8f8bb87a4c1bd52c1b57213627b035305aad745d015b2a62ae/pytest-5.4.2-py3-none-any.whl (247kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 37.5MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (3.2.1)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.5) (1.5.0+cu101)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
      "Collecting mpld3==0.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
      "\u001b[K     |████████████████████████████████| 798kB 16.2MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (1.18.4)\n",
      "Collecting tokenizers==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 39.8MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (2.23.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 35.5MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 41.5MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (0.7)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.10.0->flair==0.5) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.5) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.5) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (3.10.1)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.5) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (0.1.9)\n",
      "Collecting pluggy<1.0,>=0.12\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (8.3.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.5) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.5) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.5) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.10.0->flair==0.5) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.10.0->flair==0.5) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.13.13)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.5) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.5) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (1.16.13)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.5) (0.15.2)\n",
      "Building wheels for collected packages: flair\n",
      "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for flair: filename=flair-0.5-cp36-none-any.whl size=149375 sha256=b1eee8c2a38333738eb30bd3d268d8ce07f799e658608d38a395dcd303156b63\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9k8i2ivi/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
      "Successfully built flair\n",
      "Building wheels for collected packages: langdetect, segtok, sqlitedict, mpld3, sacremoses\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=848ec2d625d449a33f04365d1e256b3d57d6fc4c1f85c19317c95e504beb2fd4\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=c870c005b92a9c529642eac4ba8ce68878c443f5b3280692a47c5a924b41754e\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=eb05388db342a9f51721d7b9def99ddfffe44cd170b673a27bef9ddad824f9fb\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=96801603492c7642a0c3d3eb86918b320dd37effb90f91710a2e71dab344936e\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=1600e5764d6e0e8bcadda74f5e8c0d444f55bf1abfab45f6c887b31c2e02c5bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built langdetect segtok sqlitedict mpld3 sacremoses\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers, langdetect, segtok, bpemb, pluggy, pytest, deprecated, sqlitedict, mpld3, flair\n",
      "  Found existing installation: pluggy 0.7.1\n",
      "    Uninstalling pluggy-0.7.1:\n",
      "      Successfully uninstalled pluggy-0.7.1\n",
      "  Found existing installation: pytest 3.6.4\n",
      "    Uninstalling pytest-3.6.4:\n",
      "      Successfully uninstalled pytest-3.6.4\n",
      "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.2 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0 tokenizers-0.7.0 transformers-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/flairNLP/flair.git@63aeabf9a18bdf53af3bcba5bd80f43ac717656e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP7gl75D39dn"
   },
   "outputs": [],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.data import Corpus\n",
    "from flair.data import Sentence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim.adam import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfpsjw8I4Si-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "_VBdZ1L34XwO",
    "outputId": "f672ead0-eb76-47e0-bb91-c1d63e0fccde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U90p69Xd5KIE"
   },
   "outputs": [],
   "source": [
    "data_folder = \"./drive/My Drive/capstone/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WkUisuXz7tuK"
   },
   "source": [
    "### First Stage (Train on benchmark dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6K-_Bmpa6gn8"
   },
   "outputs": [],
   "source": [
    "benchmark = pd.read_csv(data_folder + \"combined_benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "HVaSsyAn72AU",
    "outputId": "90d3d87c-722b-41c1-fd1f-100d3989b196"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Why not subscribe to the magazine ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>Tornio Works employs 2,300 of whom more than 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The move is aimed at boosting sales , cost-eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>As a result of the merger , the largest profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>18 March 2010 A leakage in the gypsum pond was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0                Why not subscribe to the magazine ?\n",
       "1     -1  Tornio Works employs 2,300 of whom more than 1...\n",
       "2      1  The move is aimed at boosting sales , cost-eff...\n",
       "3      0  As a result of the merger , the largest profes...\n",
       "4     -1  18 March 2010 A leakage in the gypsum pond was..."
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = benchmark[['label', 'text']]\n",
    "benchmark.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9t_MVMXq8pvf"
   },
   "source": [
    "#### Create train, dev and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUbbfcSC8ekr"
   },
   "outputs": [],
   "source": [
    "benchmark = benchmark.sample(frac=1)\n",
    "benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', sep='\\t', index = False, header = False)\n",
    "benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', sep='\\t', index = False, header = False)\n",
    "benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', sep='\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7QE3IS69txr"
   },
   "source": [
    "#### Build corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zz-2gNy58wDI",
    "outputId": "1bc31adc-dc66-4e97-a4b5-ca7ce66fc2c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 21:33:57,559 Reading data from drive/My Drive/capstone/data\n",
      "2020-05-21 21:33:57,560 Train: drive/My Drive/capstone/data/train.csv\n",
      "2020-05-21 21:33:57,561 Dev: drive/My Drive/capstone/data/dev.csv\n",
      "2020-05-21 21:33:57,563 Test: drive/My Drive/capstone/data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_folder), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "column_name_map = {1: \"text\", 0: \"label_topic\"}\n",
    "\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=False, #no header in kaggle data\n",
    "                                         delimiter='\\t',    # comma separated rows\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qb1lynSQ98-z"
   },
   "source": [
    "#### Create word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354,
     "referenced_widgets": [
      "c77f1ef62e4b4eb096c479d3e32115fd",
      "841075c3d81d45be8dbd463b49f4b616",
      "6d9aa008f1914208bc0fe13a47d61d57",
      "c6fefd65bcff4f21bde5a7ccff636080",
      "d740f077937b423584eeb7b338411fab",
      "b539d242fcf148dba6384f206950fec2",
      "149fbbfca875490eacfedf3dee2d3bab",
      "4c4be3c21c8848b3b668007be4c5c4ba",
      "9b8e6eaa6f55457ca311a0a5e9f82cee",
      "133f98493e654f4a98a80c59e26324a8",
      "3f7a1ec90af14d919f8f2b6075483a93",
      "0a9bf515ae1c43858bd9dfa018099c76",
      "c93f08209dea4de9a7e6503519e24a43",
      "1506181aa044402d94d73420b9e8314e",
      "c968cebc32074dadb00536adabe5f4b0",
      "9352560607e64304a280dd3b659c1401",
      "aa5cd174d4d349e39f24121162d339ba",
      "010cce0aea28493395142cbe902d1c96",
      "80b256e0b95848ea8159cefb51c40f2a",
      "1745a2ab7cf1455ab9970f53544091b0",
      "111034d875a042b181ec27ab95493eda",
      "dd2e1fe5770a489ea24fd889f4dcd85c",
      "1e93801303b349f3b4b4c24bf655ace6",
      "940f0d92faa34d69a70cc87bebe2f4ec"
     ]
    },
    "colab_type": "code",
    "id": "4u9PFUze9_5y",
    "outputId": "f20a2afc-8be1-4511-cb1f-d908d4f5a53f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77f1ef62e4b4eb096c479d3e32115fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8e6eaa6f55457ca311a0a5e9f82cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5cd174d4d349e39f24121162d339ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-21 21:34:20,508 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpx661a1f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19689779/19689779 [00:00<00:00, 49444260.47B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 21:34:21,096 copying /tmp/tmpx661a1f1 to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 21:34:21,125 removing temp file /tmp/tmpx661a1f1\n",
      "2020-05-21 21:34:37,776 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp119mrbt1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19689779/19689779 [00:00<00:00, 51132721.58B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 21:34:38,322 copying /tmp/tmp119mrbt1 to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 21:34:38,354 removing temp file /tmp/tmp119mrbt1\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HovCqFfSMjmJ"
   },
   "source": [
    "#### First Stage Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Wik8DDxm-DKy",
    "outputId": "a95b394e-05f7-45f5-e630-5491ae7e0cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 21:34:44,497 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "100%|██████████| 1314/1314 [00:02<00:00, 642.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 21:34:46,855 [b'0', b'-1', b'1']\n",
      "2020-05-21 21:34:46,874 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:34:46,877 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): BertEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-05-21 21:34:46,881 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:34:46,882 Corpus: \"Corpus: 1168 train + 147 dev + 146 test sentences\"\n",
      "2020-05-21 21:34:46,883 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:34:46,889 Parameters:\n",
      "2020-05-21 21:34:46,890  - learning_rate: \"0.1\"\n",
      "2020-05-21 21:34:46,904  - mini_batch_size: \"32\"\n",
      "2020-05-21 21:34:46,907  - patience: \"3\"\n",
      "2020-05-21 21:34:46,908  - anneal_factor: \"0.5\"\n",
      "2020-05-21 21:34:46,909  - max_epochs: \"10\"\n",
      "2020-05-21 21:34:46,910  - shuffle: \"True\"\n",
      "2020-05-21 21:34:46,912  - train_with_dev: \"False\"\n",
      "2020-05-21 21:34:46,913  - batch_growth_annealing: \"False\"\n",
      "2020-05-21 21:34:46,915 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:34:46,916 Model training base path: \"drive/My Drive/capstone/data\"\n",
      "2020-05-21 21:34:46,920 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:34:46,921 Device: cuda:0\n",
      "2020-05-21 21:34:46,930 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:34:46,932 Embeddings storage mode: cpu\n",
      "2020-05-21 21:34:46,946 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 21:34:49,614 epoch 1 - iter 3/37 - loss 1.37792166 - samples/sec: 41.88\n",
      "2020-05-21 21:35:04,758 epoch 1 - iter 6/37 - loss 1.38339380 - samples/sec: 50.24\n",
      "2020-05-21 21:35:20,032 epoch 1 - iter 9/37 - loss 1.25956689 - samples/sec: 47.84\n",
      "2020-05-21 21:35:35,205 epoch 1 - iter 12/37 - loss 1.27234081 - samples/sec: 44.19\n",
      "2020-05-21 21:35:50,097 epoch 1 - iter 15/37 - loss 1.23371030 - samples/sec: 56.95\n",
      "2020-05-21 21:36:05,057 epoch 1 - iter 18/37 - loss 1.22769420 - samples/sec: 57.27\n",
      "2020-05-21 21:36:19,920 epoch 1 - iter 21/37 - loss 1.21607478 - samples/sec: 57.71\n",
      "2020-05-21 21:36:35,063 epoch 1 - iter 24/37 - loss 1.20891273 - samples/sec: 52.59\n",
      "2020-05-21 21:36:50,015 epoch 1 - iter 27/37 - loss 1.19474173 - samples/sec: 55.33\n",
      "2020-05-21 21:37:04,955 epoch 1 - iter 30/37 - loss 1.17071977 - samples/sec: 52.95\n",
      "2020-05-21 21:37:19,909 epoch 1 - iter 33/37 - loss 1.14583929 - samples/sec: 54.74\n",
      "2020-05-21 21:37:34,727 epoch 1 - iter 36/37 - loss 1.15452903 - samples/sec: 52.71\n",
      "2020-05-21 21:37:48,457 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:37:48,458 EPOCH 1 done: loss 1.1595 - lr 0.1000000\n",
      "2020-05-21 21:37:51,776 DEV : loss 0.9445202946662903 - score 0.7007\n",
      "2020-05-21 21:37:51,933 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-21 21:37:54,046 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:37:56,358 epoch 2 - iter 3/37 - loss 0.85524519 - samples/sec: 50.25\n",
      "2020-05-21 21:38:11,253 epoch 2 - iter 6/37 - loss 1.09922825 - samples/sec: 54.97\n",
      "2020-05-21 21:38:26,507 epoch 2 - iter 9/37 - loss 1.00522574 - samples/sec: 54.98\n",
      "2020-05-21 21:38:41,368 epoch 2 - iter 12/37 - loss 0.98037452 - samples/sec: 54.78\n",
      "2020-05-21 21:38:56,222 epoch 2 - iter 15/37 - loss 0.97838963 - samples/sec: 55.68\n",
      "2020-05-21 21:39:11,054 epoch 2 - iter 18/37 - loss 0.98308966 - samples/sec: 59.10\n",
      "2020-05-21 21:39:26,334 epoch 2 - iter 21/37 - loss 0.95657368 - samples/sec: 51.80\n",
      "2020-05-21 21:39:41,357 epoch 2 - iter 24/37 - loss 0.95138034 - samples/sec: 52.98\n",
      "2020-05-21 21:39:56,173 epoch 2 - iter 27/37 - loss 0.95253751 - samples/sec: 57.74\n",
      "2020-05-21 21:40:10,860 epoch 2 - iter 30/37 - loss 0.98773212 - samples/sec: 61.09\n",
      "2020-05-21 21:40:26,100 epoch 2 - iter 33/37 - loss 0.97131553 - samples/sec: 52.78\n",
      "2020-05-21 21:40:41,006 epoch 2 - iter 36/37 - loss 0.96665085 - samples/sec: 56.53\n",
      "2020-05-21 21:40:54,593 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:40:54,597 EPOCH 2 done: loss 0.9739 - lr 0.1000000\n",
      "2020-05-21 21:40:57,735 DEV : loss 0.931380569934845 - score 0.6871\n",
      "2020-05-21 21:40:57,920 BAD EPOCHS (no improvement): 1\n",
      "2020-05-21 21:40:57,930 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:41:00,220 epoch 3 - iter 3/37 - loss 0.78594307 - samples/sec: 53.17\n",
      "2020-05-21 21:41:15,319 epoch 3 - iter 6/37 - loss 0.87059626 - samples/sec: 57.18\n",
      "2020-05-21 21:41:30,252 epoch 3 - iter 9/37 - loss 0.83778094 - samples/sec: 56.83\n",
      "2020-05-21 21:41:45,306 epoch 3 - iter 12/37 - loss 0.82532736 - samples/sec: 53.17\n",
      "2020-05-21 21:42:00,170 epoch 3 - iter 15/37 - loss 0.82298377 - samples/sec: 58.05\n",
      "2020-05-21 21:42:15,125 epoch 3 - iter 18/37 - loss 0.83990110 - samples/sec: 55.10\n",
      "2020-05-21 21:42:29,999 epoch 3 - iter 21/37 - loss 0.86151212 - samples/sec: 57.33\n",
      "2020-05-21 21:42:44,930 epoch 3 - iter 24/37 - loss 0.84199478 - samples/sec: 54.04\n",
      "2020-05-21 21:42:59,845 epoch 3 - iter 27/37 - loss 0.85924654 - samples/sec: 55.98\n",
      "2020-05-21 21:43:14,781 epoch 3 - iter 30/37 - loss 0.84688073 - samples/sec: 55.50\n",
      "2020-05-21 21:43:29,649 epoch 3 - iter 33/37 - loss 0.84553108 - samples/sec: 57.70\n",
      "2020-05-21 21:43:44,517 epoch 3 - iter 36/37 - loss 0.82642869 - samples/sec: 54.67\n",
      "2020-05-21 21:43:58,244 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:43:58,249 EPOCH 3 done: loss 0.8259 - lr 0.1000000\n",
      "2020-05-21 21:44:01,262 DEV : loss 1.0202172994613647 - score 0.6961\n",
      "2020-05-21 21:44:01,422 BAD EPOCHS (no improvement): 2\n",
      "2020-05-21 21:44:01,427 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:44:04,053 epoch 4 - iter 3/37 - loss 0.69517150 - samples/sec: 42.90\n",
      "2020-05-21 21:44:19,829 epoch 4 - iter 6/37 - loss 0.72263813 - samples/sec: 53.00\n",
      "2020-05-21 21:44:35,580 epoch 4 - iter 9/37 - loss 0.75209264 - samples/sec: 56.52\n",
      "2020-05-21 21:44:51,337 epoch 4 - iter 12/37 - loss 0.72499405 - samples/sec: 56.21\n",
      "2020-05-21 21:45:07,397 epoch 4 - iter 15/37 - loss 0.72337782 - samples/sec: 56.74\n",
      "2020-05-21 21:45:23,166 epoch 4 - iter 18/37 - loss 0.73976502 - samples/sec: 56.25\n",
      "2020-05-21 21:45:38,982 epoch 4 - iter 21/37 - loss 0.72228904 - samples/sec: 55.21\n",
      "2020-05-21 21:45:54,710 epoch 4 - iter 24/37 - loss 0.75199094 - samples/sec: 57.58\n",
      "2020-05-21 21:46:10,811 epoch 4 - iter 27/37 - loss 0.75499927 - samples/sec: 49.97\n",
      "2020-05-21 21:46:26,421 epoch 4 - iter 30/37 - loss 0.74420565 - samples/sec: 58.69\n",
      "2020-05-21 21:46:42,230 epoch 4 - iter 33/37 - loss 0.75718331 - samples/sec: 54.88\n",
      "2020-05-21 21:46:57,865 epoch 4 - iter 36/37 - loss 0.78696104 - samples/sec: 61.53\n",
      "2020-05-21 21:47:12,503 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:47:12,508 EPOCH 4 done: loss 0.7832 - lr 0.1000000\n",
      "2020-05-21 21:47:15,796 DEV : loss 0.8029612898826599 - score 0.7415\n",
      "2020-05-21 21:47:15,951 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-21 21:47:18,187 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:47:20,541 epoch 5 - iter 3/37 - loss 0.64034499 - samples/sec: 49.05\n",
      "2020-05-21 21:47:36,013 epoch 5 - iter 6/37 - loss 0.79552535 - samples/sec: 55.93\n",
      "2020-05-21 21:47:51,916 epoch 5 - iter 9/37 - loss 0.76471422 - samples/sec: 53.36\n",
      "2020-05-21 21:48:07,934 epoch 5 - iter 12/37 - loss 0.76398595 - samples/sec: 48.46\n",
      "2020-05-21 21:48:23,588 epoch 5 - iter 15/37 - loss 0.74059561 - samples/sec: 58.19\n",
      "2020-05-21 21:48:39,467 epoch 5 - iter 18/37 - loss 0.73144527 - samples/sec: 55.84\n",
      "2020-05-21 21:48:55,232 epoch 5 - iter 21/37 - loss 0.71586683 - samples/sec: 56.07\n",
      "2020-05-21 21:49:11,306 epoch 5 - iter 24/37 - loss 0.72395818 - samples/sec: 52.77\n",
      "2020-05-21 21:49:27,162 epoch 5 - iter 27/37 - loss 0.72656212 - samples/sec: 57.58\n",
      "2020-05-21 21:49:42,920 epoch 5 - iter 30/37 - loss 0.72081359 - samples/sec: 56.03\n",
      "2020-05-21 21:49:58,665 epoch 5 - iter 33/37 - loss 0.71714353 - samples/sec: 56.90\n",
      "2020-05-21 21:50:14,470 epoch 5 - iter 36/37 - loss 0.73095743 - samples/sec: 58.60\n",
      "2020-05-21 21:50:29,039 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:50:29,041 EPOCH 5 done: loss 0.7250 - lr 0.1000000\n",
      "2020-05-21 21:50:33,455 DEV : loss 0.8560692667961121 - score 0.7596\n",
      "2020-05-21 21:50:33,627 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-21 21:50:35,752 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:50:38,190 epoch 6 - iter 3/37 - loss 0.63888168 - samples/sec: 51.43\n",
      "2020-05-21 21:50:53,821 epoch 6 - iter 6/37 - loss 0.78605540 - samples/sec: 55.68\n",
      "2020-05-21 21:51:09,795 epoch 6 - iter 9/37 - loss 0.70923318 - samples/sec: 58.92\n",
      "2020-05-21 21:51:25,526 epoch 6 - iter 12/37 - loss 0.72843050 - samples/sec: 57.41\n",
      "2020-05-21 21:51:41,177 epoch 6 - iter 15/37 - loss 0.73410404 - samples/sec: 56.53\n",
      "2020-05-21 21:51:57,278 epoch 6 - iter 18/37 - loss 0.74840003 - samples/sec: 56.32\n",
      "2020-05-21 21:52:13,020 epoch 6 - iter 21/37 - loss 0.72714724 - samples/sec: 56.50\n",
      "2020-05-21 21:52:28,843 epoch 6 - iter 24/37 - loss 0.71306286 - samples/sec: 55.04\n",
      "2020-05-21 21:52:44,545 epoch 6 - iter 27/37 - loss 0.69998651 - samples/sec: 57.90\n",
      "2020-05-21 21:53:00,385 epoch 6 - iter 30/37 - loss 0.68654988 - samples/sec: 58.09\n",
      "2020-05-21 21:53:16,322 epoch 6 - iter 33/37 - loss 0.69359179 - samples/sec: 50.98\n",
      "2020-05-21 21:53:32,036 epoch 6 - iter 36/37 - loss 0.71336695 - samples/sec: 57.81\n",
      "2020-05-21 21:53:46,625 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:53:46,627 EPOCH 6 done: loss 0.7038 - lr 0.1000000\n",
      "2020-05-21 21:53:49,593 DEV : loss 0.8320075869560242 - score 0.7324\n",
      "2020-05-21 21:53:49,742 BAD EPOCHS (no improvement): 1\n",
      "2020-05-21 21:53:49,747 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:53:52,381 epoch 7 - iter 3/37 - loss 0.67194335 - samples/sec: 49.78\n",
      "2020-05-21 21:54:08,092 epoch 7 - iter 6/37 - loss 0.59081362 - samples/sec: 58.02\n",
      "2020-05-21 21:54:23,855 epoch 7 - iter 9/37 - loss 0.54072740 - samples/sec: 56.66\n",
      "2020-05-21 21:54:39,668 epoch 7 - iter 12/37 - loss 0.60737691 - samples/sec: 58.63\n",
      "2020-05-21 21:54:55,538 epoch 7 - iter 15/37 - loss 0.65824075 - samples/sec: 56.61\n",
      "2020-05-21 21:55:11,237 epoch 7 - iter 18/37 - loss 0.64680442 - samples/sec: 57.85\n",
      "2020-05-21 21:55:27,133 epoch 7 - iter 21/37 - loss 0.64072014 - samples/sec: 56.84\n",
      "2020-05-21 21:55:42,843 epoch 7 - iter 24/37 - loss 0.65696819 - samples/sec: 57.42\n",
      "2020-05-21 21:55:58,755 epoch 7 - iter 27/37 - loss 0.69582895 - samples/sec: 57.95\n",
      "2020-05-21 21:56:14,659 epoch 7 - iter 30/37 - loss 0.67759945 - samples/sec: 55.81\n",
      "2020-05-21 21:56:30,356 epoch 7 - iter 33/37 - loss 0.68227184 - samples/sec: 58.23\n",
      "2020-05-21 21:56:46,079 epoch 7 - iter 36/37 - loss 0.67792013 - samples/sec: 57.87\n",
      "2020-05-21 21:57:00,535 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:57:00,537 EPOCH 7 done: loss 0.6765 - lr 0.1000000\n",
      "2020-05-21 21:57:03,744 DEV : loss 1.0983926057815552 - score 0.7052\n",
      "2020-05-21 21:57:03,899 BAD EPOCHS (no improvement): 2\n",
      "2020-05-21 21:57:03,904 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 21:57:06,144 epoch 8 - iter 3/37 - loss 0.59439997 - samples/sec: 52.96\n",
      "2020-05-21 21:57:21,873 epoch 8 - iter 6/37 - loss 0.56928804 - samples/sec: 55.20\n",
      "2020-05-21 21:57:37,489 epoch 8 - iter 9/37 - loss 0.64330026 - samples/sec: 58.25\n",
      "2020-05-21 21:57:53,477 epoch 8 - iter 12/37 - loss 0.72071398 - samples/sec: 49.90\n",
      "2020-05-21 21:58:09,250 epoch 8 - iter 15/37 - loss 0.67545224 - samples/sec: 56.58\n",
      "2020-05-21 21:58:24,957 epoch 8 - iter 18/37 - loss 0.63852616 - samples/sec: 58.47\n",
      "2020-05-21 21:58:40,845 epoch 8 - iter 21/37 - loss 0.61622297 - samples/sec: 49.90\n",
      "2020-05-21 21:58:56,901 epoch 8 - iter 24/37 - loss 0.59554440 - samples/sec: 51.58\n",
      "2020-05-21 21:59:12,591 epoch 8 - iter 27/37 - loss 0.60221954 - samples/sec: 58.72\n",
      "2020-05-21 21:59:28,320 epoch 8 - iter 30/37 - loss 0.59528004 - samples/sec: 57.45\n",
      "2020-05-21 21:59:44,075 epoch 8 - iter 33/37 - loss 0.59690305 - samples/sec: 56.90\n",
      "2020-05-21 21:59:59,799 epoch 8 - iter 36/37 - loss 0.59973333 - samples/sec: 57.15\n",
      "2020-05-21 22:00:14,199 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 22:00:14,201 EPOCH 8 done: loss 0.5982 - lr 0.1000000\n",
      "2020-05-21 22:00:17,464 DEV : loss 0.8370154500007629 - score 0.746\n",
      "2020-05-21 22:00:17,618 BAD EPOCHS (no improvement): 3\n",
      "2020-05-21 22:00:17,625 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 22:00:19,915 epoch 9 - iter 3/37 - loss 0.79148982 - samples/sec: 52.88\n",
      "2020-05-21 22:00:35,852 epoch 9 - iter 6/37 - loss 0.79131648 - samples/sec: 55.46\n",
      "2020-05-21 22:00:51,719 epoch 9 - iter 9/37 - loss 0.82306821 - samples/sec: 62.23\n",
      "2020-05-21 22:01:07,550 epoch 9 - iter 12/37 - loss 0.78826874 - samples/sec: 54.18\n",
      "2020-05-21 22:01:23,387 epoch 9 - iter 15/37 - loss 0.73234124 - samples/sec: 54.12\n",
      "2020-05-21 22:01:39,065 epoch 9 - iter 18/37 - loss 0.69298738 - samples/sec: 57.99\n",
      "2020-05-21 22:01:55,083 epoch 9 - iter 21/37 - loss 0.65552629 - samples/sec: 48.30\n",
      "2020-05-21 22:02:10,903 epoch 9 - iter 24/37 - loss 0.64999323 - samples/sec: 54.43\n",
      "2020-05-21 22:02:26,840 epoch 9 - iter 27/37 - loss 0.65730035 - samples/sec: 54.08\n",
      "2020-05-21 22:02:42,617 epoch 9 - iter 30/37 - loss 0.65020915 - samples/sec: 57.19\n",
      "2020-05-21 22:02:58,296 epoch 9 - iter 33/37 - loss 0.65261606 - samples/sec: 58.95\n",
      "2020-05-21 22:03:14,367 epoch 9 - iter 36/37 - loss 0.63152339 - samples/sec: 50.67\n",
      "2020-05-21 22:03:28,810 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 22:03:28,816 EPOCH 9 done: loss 0.6327 - lr 0.1000000\n",
      "2020-05-21 22:03:31,784 DEV : loss 1.3560564517974854 - score 0.6871\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-05-21 22:03:31,944 BAD EPOCHS (no improvement): 4\n",
      "2020-05-21 22:03:31,949 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 22:03:34,111 epoch 10 - iter 3/37 - loss 0.63264841 - samples/sec: 52.16\n",
      "2020-05-21 22:03:50,282 epoch 10 - iter 6/37 - loss 0.48688252 - samples/sec: 53.38\n",
      "2020-05-21 22:04:06,139 epoch 10 - iter 9/37 - loss 0.46484144 - samples/sec: 53.50\n",
      "2020-05-21 22:04:21,886 epoch 10 - iter 12/37 - loss 0.43838393 - samples/sec: 56.74\n",
      "2020-05-21 22:04:37,556 epoch 10 - iter 15/37 - loss 0.43753751 - samples/sec: 55.45\n",
      "2020-05-21 22:04:53,430 epoch 10 - iter 18/37 - loss 0.43621853 - samples/sec: 56.95\n",
      "2020-05-21 22:05:09,227 epoch 10 - iter 21/37 - loss 0.45240130 - samples/sec: 58.66\n",
      "2020-05-21 22:05:24,972 epoch 10 - iter 24/37 - loss 0.45714683 - samples/sec: 56.72\n",
      "2020-05-21 22:05:40,659 epoch 10 - iter 27/37 - loss 0.46108902 - samples/sec: 56.48\n",
      "2020-05-21 22:05:56,370 epoch 10 - iter 30/37 - loss 0.45459591 - samples/sec: 55.10\n",
      "2020-05-21 22:06:12,242 epoch 10 - iter 33/37 - loss 0.45016072 - samples/sec: 59.58\n",
      "2020-05-21 22:06:27,952 epoch 10 - iter 36/37 - loss 0.45976658 - samples/sec: 57.95\n",
      "2020-05-21 22:06:42,622 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 22:06:42,628 EPOCH 10 done: loss 0.4617 - lr 0.0500000\n",
      "2020-05-21 22:06:45,675 DEV : loss 0.8271321654319763 - score 0.7732\n",
      "2020-05-21 22:06:45,837 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-21 22:06:50,595 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 22:06:50,604 Testing using best model ...\n",
      "2020-05-21 22:06:50,613 loading file drive/My Drive/capstone/data/best-model.pt\n",
      "2020-05-21 22:06:54,653 0.6643835616438356\t0.6643835616438356\t0.6643835616438356\n",
      "2020-05-21 22:06:54,660 \n",
      "MICRO_AVG: acc 0.776255707762557 - f1-score 0.6643835616438356\n",
      "MACRO_AVG: acc 0.776255707762557 - f1-score 0.6142857142857143\n",
      "-1         tp: 35 - fp: 20 - fn: 10 - tn: 81 - precision: 0.6364 - recall: 0.7778 - accuracy: 0.7945 - f1-score: 0.7000\n",
      "0          tp: 51 - fp: 22 - fn: 2 - tn: 71 - precision: 0.6986 - recall: 0.9623 - accuracy: 0.8356 - f1-score: 0.8095\n",
      "1          tp: 11 - fp: 7 - fn: 37 - tn: 91 - precision: 0.6111 - recall: 0.2292 - accuracy: 0.6986 - f1-score: 0.3333\n",
      "2020-05-21 22:06:54,664 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dev_loss_history': [0.9445202946662903,\n",
       "  0.931380569934845,\n",
       "  1.0202172994613647,\n",
       "  0.8029612898826599,\n",
       "  0.8560692667961121,\n",
       "  0.8320075869560242,\n",
       "  1.0983926057815552,\n",
       "  0.8370154500007629,\n",
       "  1.3560564517974854,\n",
       "  0.8271321654319763],\n",
       " 'dev_score_history': [0.7006802721088435,\n",
       "  0.6870748299319728,\n",
       "  0.6961451247165533,\n",
       "  0.7414965986394558,\n",
       "  0.7596371882086168,\n",
       "  0.7324263038548753,\n",
       "  0.7052154195011338,\n",
       "  0.746031746031746,\n",
       "  0.6870748299319728,\n",
       "  0.7732426303854876],\n",
       " 'test_score': 0.776255707762557,\n",
       " 'train_loss_history': [1.1594745307355314,\n",
       "  0.9738980918317228,\n",
       "  0.8259133777102908,\n",
       "  0.7832235951681394,\n",
       "  0.7250221081682153,\n",
       "  0.703832321070336,\n",
       "  0.6765379398255735,\n",
       "  0.5982233124810297,\n",
       "  0.632674384761501,\n",
       "  0.4617382706822576]}"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train(data_folder, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70VkknqiEeVG"
   },
   "source": [
    "#### Data folder after first stage fine tuning\n",
    "![alt text](https://raw.github.ubc.ca/ltian05/better_dwelling_capstone/aarontian/week_4/screenshots/Screen%20Shot%202020-05-25%20at%204.34.08%20PM.png?token=AAAAOMWRKXQXADFFGZWV72S62WILA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VOUE6KRC9m4W"
   },
   "source": [
    "### Second Stage Employment (fine tune on hand annotated datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "X7aKRaHG9ytj",
    "outputId": "15618da3-a181-4fc0-cf78-a8878b0602a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 21:59:51,972 Reading data from drive/My Drive/capstone/data/second_stage_employment\n",
      "2020-05-28 21:59:51,974 Train: drive/My Drive/capstone/data/second_stage_employment/train.csv\n",
      "2020-05-28 21:59:51,977 Dev: drive/My Drive/capstone/data/second_stage_employment/dev.csv\n",
      "2020-05-28 21:59:51,984 Test: drive/My Drive/capstone/data/second_stage_employment/test.csv\n"
     ]
    }
   ],
   "source": [
    "new_data_folder = './drive/My Drive/capstone/data/second_stage_employment/'\n",
    "new_column_name_map = {3: \"text\", 5: \"label_topic\"}\n",
    "\n",
    "corpus: Corpus = CSVClassificationCorpus(new_data_folder,\n",
    "                                         new_column_name_map,\n",
    "                                         skip_header=True, \n",
    "                                         delimiter=',',    # comma separated rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YTsvf3rj_IXl",
    "outputId": "76696668-5648-4fd8-c96d-346cad54b168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 21:59:55,066 loading file ./drive/My Drive/capstone/data/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PG63aPTd_Pof",
    "outputId": "7b22f4ab-5766-4b88-9b5b-1de91bc9978a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 22:00:05,361 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:05,369 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): BertEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-05-28 22:00:05,376 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:05,379 Corpus: \"Corpus: 58 train + 11 dev + 11 test sentences\"\n",
      "2020-05-28 22:00:05,383 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:05,383 Parameters:\n",
      "2020-05-28 22:00:05,386  - learning_rate: \"0.1\"\n",
      "2020-05-28 22:00:05,387  - mini_batch_size: \"32\"\n",
      "2020-05-28 22:00:05,389  - patience: \"3\"\n",
      "2020-05-28 22:00:05,390  - anneal_factor: \"0.5\"\n",
      "2020-05-28 22:00:05,391  - max_epochs: \"10\"\n",
      "2020-05-28 22:00:05,393  - shuffle: \"True\"\n",
      "2020-05-28 22:00:05,394  - train_with_dev: \"False\"\n",
      "2020-05-28 22:00:05,395  - batch_growth_annealing: \"False\"\n",
      "2020-05-28 22:00:05,397 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:05,398 Model training base path: \"drive/My Drive/capstone/data/second_stage_employment\"\n",
      "2020-05-28 22:00:05,399 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:05,400 Device: cuda:0\n",
      "2020-05-28 22:00:05,402 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:05,403 Embeddings storage mode: cpu\n",
      "2020-05-28 22:00:05,414 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:06,393 epoch 1 - iter 1/2 - loss 1.82105899 - samples/sec: 44.40\n",
      "2020-05-28 22:00:20,050 epoch 1 - iter 2/2 - loss 1.65660012 - samples/sec: 60.02\n",
      "2020-05-28 22:00:33,381 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:33,383 EPOCH 1 done: loss 1.6566 - lr 0.1000000\n",
      "2020-05-28 22:00:33,989 DEV : loss 0.926588773727417 - score 0.7576\n",
      "2020-05-28 22:00:34,009 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-28 22:00:35,928 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:00:36,799 epoch 2 - iter 1/2 - loss 0.84240681 - samples/sec: 50.63\n",
      "2020-05-28 22:00:50,677 epoch 2 - iter 2/2 - loss 0.98053375 - samples/sec: 55.77\n",
      "2020-05-28 22:01:04,004 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:01:04,005 EPOCH 2 done: loss 0.9805 - lr 0.1000000\n",
      "2020-05-28 22:01:04,592 DEV : loss 1.0328346490859985 - score 0.6364\n",
      "2020-05-28 22:01:04,615 BAD EPOCHS (no improvement): 1\n",
      "2020-05-28 22:01:04,621 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:01:05,547 epoch 3 - iter 1/2 - loss 1.23901021 - samples/sec: 45.85\n",
      "2020-05-28 22:01:19,048 epoch 3 - iter 2/2 - loss 1.08642390 - samples/sec: 63.75\n",
      "2020-05-28 22:01:32,374 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:01:32,376 EPOCH 3 done: loss 1.0864 - lr 0.1000000\n",
      "2020-05-28 22:01:32,963 DEV : loss 0.8461851477622986 - score 0.6364\n",
      "2020-05-28 22:01:32,986 BAD EPOCHS (no improvement): 2\n",
      "2020-05-28 22:01:32,991 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:01:34,038 epoch 4 - iter 1/2 - loss 0.79752237 - samples/sec: 56.31\n",
      "2020-05-28 22:01:47,725 epoch 4 - iter 2/2 - loss 0.99477199 - samples/sec: 67.09\n",
      "2020-05-28 22:02:01,070 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:02:01,075 EPOCH 4 done: loss 0.9948 - lr 0.1000000\n",
      "2020-05-28 22:02:01,643 DEV : loss 1.1260348558425903 - score 0.6364\n",
      "2020-05-28 22:02:01,668 BAD EPOCHS (no improvement): 3\n",
      "2020-05-28 22:02:01,674 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:02:02,487 epoch 5 - iter 1/2 - loss 0.87277943 - samples/sec: 58.37\n",
      "2020-05-28 22:02:16,237 epoch 5 - iter 2/2 - loss 1.02697423 - samples/sec: 59.49\n",
      "2020-05-28 22:02:29,468 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:02:29,474 EPOCH 5 done: loss 1.0270 - lr 0.1000000\n",
      "2020-05-28 22:02:30,035 DEV : loss 1.4034475088119507 - score 0.5758\n",
      "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-05-28 22:02:30,057 BAD EPOCHS (no improvement): 4\n",
      "2020-05-28 22:02:30,063 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:02:30,882 epoch 6 - iter 1/2 - loss 0.70821124 - samples/sec: 56.82\n",
      "2020-05-28 22:02:44,592 epoch 6 - iter 2/2 - loss 0.55242281 - samples/sec: 66.33\n",
      "2020-05-28 22:02:57,928 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:02:57,932 EPOCH 6 done: loss 0.5524 - lr 0.0500000\n",
      "2020-05-28 22:02:58,489 DEV : loss 0.9472813010215759 - score 0.697\n",
      "2020-05-28 22:02:58,510 BAD EPOCHS (no improvement): 1\n",
      "2020-05-28 22:02:58,514 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:02:59,363 epoch 7 - iter 1/2 - loss 0.44770175 - samples/sec: 53.01\n",
      "2020-05-28 22:03:13,111 epoch 7 - iter 2/2 - loss 0.40952697 - samples/sec: 59.62\n",
      "2020-05-28 22:03:26,466 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:03:26,467 EPOCH 7 done: loss 0.4095 - lr 0.0500000\n",
      "2020-05-28 22:03:27,110 DEV : loss 1.0166206359863281 - score 0.6364\n",
      "2020-05-28 22:03:27,131 BAD EPOCHS (no improvement): 2\n",
      "2020-05-28 22:03:27,137 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:03:28,040 epoch 8 - iter 1/2 - loss 0.30915171 - samples/sec: 48.30\n",
      "2020-05-28 22:03:41,710 epoch 8 - iter 2/2 - loss 0.37539601 - samples/sec: 58.40\n",
      "2020-05-28 22:03:55,053 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:03:55,055 EPOCH 8 done: loss 0.3754 - lr 0.0500000\n",
      "2020-05-28 22:03:55,635 DEV : loss 1.0762646198272705 - score 0.5758\n",
      "2020-05-28 22:03:55,656 BAD EPOCHS (no improvement): 3\n",
      "2020-05-28 22:03:55,661 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:03:56,541 epoch 9 - iter 1/2 - loss 0.28685430 - samples/sec: 49.82\n",
      "2020-05-28 22:04:10,296 epoch 9 - iter 2/2 - loss 0.32510678 - samples/sec: 58.63\n",
      "2020-05-28 22:04:23,646 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:04:23,651 EPOCH 9 done: loss 0.3251 - lr 0.0500000\n",
      "2020-05-28 22:04:24,247 DEV : loss 1.0556421279907227 - score 0.5758\n",
      "Epoch     9: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-05-28 22:04:24,271 BAD EPOCHS (no improvement): 4\n",
      "2020-05-28 22:04:24,276 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:04:25,363 epoch 10 - iter 1/2 - loss 0.34405151 - samples/sec: 37.64\n",
      "2020-05-28 22:04:39,064 epoch 10 - iter 2/2 - loss 0.30383560 - samples/sec: 64.84\n",
      "2020-05-28 22:04:52,184 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:04:52,186 EPOCH 10 done: loss 0.3038 - lr 0.0250000\n",
      "2020-05-28 22:04:52,759 DEV : loss 1.092240810394287 - score 0.5758\n",
      "2020-05-28 22:04:52,784 BAD EPOCHS (no improvement): 1\n",
      "2020-05-28 22:04:54,847 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 22:04:54,852 Testing using best model ...\n",
      "2020-05-28 22:04:54,858 loading file drive/My Drive/capstone/data/second_stage_employment/best-model.pt\n",
      "2020-05-28 22:04:56,486 0.6363636363636364\t0.6363636363636364\t0.6363636363636364\n",
      "2020-05-28 22:04:56,492 \n",
      "MICRO_AVG: acc 0.7575757575757576 - f1-score 0.6363636363636364\n",
      "MACRO_AVG: acc 0.7575757575757575 - f1-score 0.6444444444444444\n",
      "-1         tp: 3 - fp: 1 - fn: 3 - tn: 4 - precision: 0.7500 - recall: 0.5000 - accuracy: 0.6364 - f1-score: 0.6000\n",
      "0          tp: 1 - fp: 1 - fn: 0 - tn: 9 - precision: 0.5000 - recall: 1.0000 - accuracy: 0.9091 - f1-score: 0.6667\n",
      "1          tp: 3 - fp: 2 - fn: 1 - tn: 5 - precision: 0.6000 - recall: 0.7500 - accuracy: 0.7273 - f1-score: 0.6667\n",
      "2020-05-28 22:04:56,496 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dev_loss_history': [0.926588773727417,\n",
       "  1.0328346490859985,\n",
       "  0.8461851477622986,\n",
       "  1.1260348558425903,\n",
       "  1.4034475088119507,\n",
       "  0.9472813010215759,\n",
       "  1.0166206359863281,\n",
       "  1.0762646198272705,\n",
       "  1.0556421279907227,\n",
       "  1.092240810394287],\n",
       " 'dev_score_history': [0.7575757575757576,\n",
       "  0.6363636363636364,\n",
       "  0.6363636363636364,\n",
       "  0.6363636363636364,\n",
       "  0.5757575757575758,\n",
       "  0.696969696969697,\n",
       "  0.6363636363636364,\n",
       "  0.5757575757575758,\n",
       "  0.5757575757575758,\n",
       "  0.5757575757575758],\n",
       " 'test_score': 0.7575757575757576,\n",
       " 'train_loss_history': [1.6566001176834106,\n",
       "  0.9805337488651276,\n",
       "  1.0864239037036896,\n",
       "  0.9947719871997833,\n",
       "  1.026974231004715,\n",
       "  0.5524228066205978,\n",
       "  0.4095269739627838,\n",
       "  0.3753960132598877,\n",
       "  0.32510678470134735,\n",
       "  0.30383560061454773]}"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ModelTrainer(benchmark_classifier, corpus)\n",
    "trainer.train(new_data_folder, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHnl9BsHECFm"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KyRWAxfpMfJT"
   },
   "source": [
    "### Employment folder after second stage fine tuning\n",
    "![alt text](https://raw.github.ubc.ca/ltian05/better_dwelling_capstone/aarontian/week_4/screenshots/Screen%20Shot%202020-05-25%20at%204.24.58%20PM.png?token=AAAAOMRAGJI4MX5IUK52VM262WISU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyN4HzCJB8po"
   },
   "source": [
    "### Second Stage Stock Market (fine tune on hand annotated datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "DjVBv-u6CBtN",
    "outputId": "fe614169-5d2b-4449-a530-67c7ea874176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 16:31:31,081 Reading data from drive/My Drive/capstone/data/second_stage_stock\n",
      "2020-05-28 16:31:31,083 Train: drive/My Drive/capstone/data/second_stage_stock/train.csv\n",
      "2020-05-28 16:31:31,086 Dev: drive/My Drive/capstone/data/second_stage_stock/dev.csv\n",
      "2020-05-28 16:31:31,090 Test: drive/My Drive/capstone/data/second_stage_stock/test.csv\n"
     ]
    }
   ],
   "source": [
    "new_data_folder = './drive/My Drive/capstone/data/second_stage_stock/'\n",
    "new_column_name_map = {3: \"text\", 5: \"label_topic\"}\n",
    "\n",
    "corpus: Corpus = CSVClassificationCorpus(new_data_folder,\n",
    "                                         new_column_name_map,\n",
    "                                         skip_header=True, \n",
    "                                         delimiter=',',    # comma separated rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6EbMZTabCPzF",
    "outputId": "b25760e0-e20c-4c07-a6f2-a913ca49c56e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 16:31:35,793 loading file ./drive/My Drive/capstone/data/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_M5khGV7CUHJ",
    "outputId": "d4579204-e8b0-4ec7-fc46-a49da72d8012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 16:32:07,516 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:07,521 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): BertEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-05-28 16:32:07,526 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:07,529 Corpus: \"Corpus: 63 train + 12 dev + 12 test sentences\"\n",
      "2020-05-28 16:32:07,531 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:07,534 Parameters:\n",
      "2020-05-28 16:32:07,536  - learning_rate: \"0.1\"\n",
      "2020-05-28 16:32:07,538  - mini_batch_size: \"32\"\n",
      "2020-05-28 16:32:07,541  - patience: \"3\"\n",
      "2020-05-28 16:32:07,548  - anneal_factor: \"0.5\"\n",
      "2020-05-28 16:32:07,550  - max_epochs: \"10\"\n",
      "2020-05-28 16:32:07,553  - shuffle: \"True\"\n",
      "2020-05-28 16:32:07,554  - train_with_dev: \"False\"\n",
      "2020-05-28 16:32:07,555  - batch_growth_annealing: \"False\"\n",
      "2020-05-28 16:32:07,558 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:07,559 Model training base path: \"drive/My Drive/capstone/data/second_stage_stock\"\n",
      "2020-05-28 16:32:07,560 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:07,562 Device: cuda:0\n",
      "2020-05-28 16:32:07,564 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:07,565 Embeddings storage mode: cpu\n",
      "2020-05-28 16:32:07,574 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:08,903 epoch 1 - iter 1/2 - loss 1.53635609 - samples/sec: 29.65\n",
      "2020-05-28 16:32:22,939 epoch 1 - iter 2/2 - loss 1.60392559 - samples/sec: 43.50\n",
      "2020-05-28 16:32:36,280 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:36,289 EPOCH 1 done: loss 1.6039 - lr 0.1000000\n",
      "2020-05-28 16:32:36,922 DEV : loss 1.2610609531402588 - score 0.7222\n",
      "2020-05-28 16:32:36,948 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-28 16:32:38,917 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:32:39,881 epoch 2 - iter 1/2 - loss 1.08414614 - samples/sec: 47.07\n",
      "2020-05-28 16:32:53,902 epoch 2 - iter 2/2 - loss 0.99959868 - samples/sec: 39.53\n",
      "2020-05-28 16:33:07,130 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:33:07,132 EPOCH 2 done: loss 0.9996 - lr 0.1000000\n",
      "2020-05-28 16:33:07,818 DEV : loss 0.9575487971305847 - score 0.6667\n",
      "2020-05-28 16:33:07,847 BAD EPOCHS (no improvement): 1\n",
      "2020-05-28 16:33:07,852 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:33:08,781 epoch 3 - iter 1/2 - loss 0.63824892 - samples/sec: 46.10\n",
      "2020-05-28 16:33:22,605 epoch 3 - iter 2/2 - loss 0.78065604 - samples/sec: 52.12\n",
      "2020-05-28 16:33:35,925 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:33:35,931 EPOCH 3 done: loss 0.7807 - lr 0.1000000\n",
      "2020-05-28 16:33:36,652 DEV : loss 1.0690481662750244 - score 0.7222\n",
      "2020-05-28 16:33:36,688 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-28 16:33:38,812 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:33:39,736 epoch 4 - iter 1/2 - loss 0.82704836 - samples/sec: 47.38\n",
      "2020-05-28 16:33:54,155 epoch 4 - iter 2/2 - loss 1.00059995 - samples/sec: 48.03\n",
      "2020-05-28 16:34:07,471 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:34:07,472 EPOCH 4 done: loss 1.0006 - lr 0.1000000\n",
      "2020-05-28 16:34:08,142 DEV : loss 0.9532806277275085 - score 0.7778\n",
      "2020-05-28 16:34:08,167 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-28 16:34:10,180 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:34:11,236 epoch 5 - iter 1/2 - loss 1.05798388 - samples/sec: 40.42\n",
      "2020-05-28 16:34:28,979 epoch 5 - iter 2/2 - loss 1.08922130 - samples/sec: 40.84\n",
      "2020-05-28 16:34:42,197 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:34:42,198 EPOCH 5 done: loss 1.0892 - lr 0.1000000\n",
      "2020-05-28 16:34:42,860 DEV : loss 0.7961318492889404 - score 0.6667\n",
      "2020-05-28 16:34:43,095 BAD EPOCHS (no improvement): 1\n",
      "2020-05-28 16:34:43,101 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:34:43,973 epoch 6 - iter 1/2 - loss 0.71663207 - samples/sec: 49.92\n",
      "2020-05-28 16:34:57,620 epoch 6 - iter 2/2 - loss 0.62223947 - samples/sec: 58.77\n",
      "2020-05-28 16:35:10,940 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:35:10,944 EPOCH 6 done: loss 0.6222 - lr 0.1000000\n",
      "2020-05-28 16:35:11,564 DEV : loss 0.8032405972480774 - score 0.8333\n",
      "2020-05-28 16:35:11,592 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-05-28 16:35:13,568 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:35:14,444 epoch 7 - iter 1/2 - loss 0.43424040 - samples/sec: 50.07\n",
      "2020-05-28 16:35:29,127 epoch 7 - iter 2/2 - loss 0.41739917 - samples/sec: 47.07\n",
      "2020-05-28 16:35:42,452 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:35:42,453 EPOCH 7 done: loss 0.4174 - lr 0.1000000\n",
      "2020-05-28 16:35:43,071 DEV : loss 0.9901302456855774 - score 0.8333\n",
      "2020-05-28 16:35:43,101 BAD EPOCHS (no improvement): 1\n",
      "2020-05-28 16:35:43,106 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:35:43,971 epoch 8 - iter 1/2 - loss 0.39905494 - samples/sec: 49.64\n",
      "2020-05-28 16:35:57,784 epoch 8 - iter 2/2 - loss 0.36568621 - samples/sec: 55.37\n",
      "2020-05-28 16:36:11,120 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:36:11,121 EPOCH 8 done: loss 0.3657 - lr 0.1000000\n",
      "2020-05-28 16:36:11,777 DEV : loss 1.0061790943145752 - score 0.8333\n",
      "2020-05-28 16:36:11,806 BAD EPOCHS (no improvement): 2\n",
      "2020-05-28 16:36:11,811 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:36:12,690 epoch 9 - iter 1/2 - loss 0.32578743 - samples/sec: 52.76\n",
      "2020-05-28 16:36:26,407 epoch 9 - iter 2/2 - loss 0.33731759 - samples/sec: 54.47\n",
      "2020-05-28 16:36:39,742 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:36:39,745 EPOCH 9 done: loss 0.3373 - lr 0.1000000\n",
      "2020-05-28 16:36:40,373 DEV : loss 1.409272313117981 - score 0.7222\n",
      "2020-05-28 16:36:40,402 BAD EPOCHS (no improvement): 3\n",
      "2020-05-28 16:36:40,408 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:36:41,432 epoch 10 - iter 1/2 - loss 0.48512146 - samples/sec: 40.75\n",
      "2020-05-28 16:36:55,382 epoch 10 - iter 2/2 - loss 0.55743791 - samples/sec: 38.71\n",
      "2020-05-28 16:37:08,718 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:37:08,720 EPOCH 10 done: loss 0.5574 - lr 0.1000000\n",
      "2020-05-28 16:37:09,381 DEV : loss 1.34184730052948 - score 0.7222\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-05-28 16:37:09,412 BAD EPOCHS (no improvement): 4\n",
      "2020-05-28 16:37:11,381 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-28 16:37:11,386 Testing using best model ...\n",
      "2020-05-28 16:37:11,392 loading file drive/My Drive/capstone/data/second_stage_stock/best-model.pt\n",
      "2020-05-28 16:37:13,105 0.75\t0.75\t0.75\n",
      "2020-05-28 16:37:13,110 \n",
      "MICRO_AVG: acc 0.8333333333333334 - f1-score 0.75\n",
      "MACRO_AVG: acc 0.8333333333333334 - f1-score 0.7367724867724869\n",
      "-1         tp: 4 - fp: 1 - fn: 0 - tn: 7 - precision: 0.8000 - recall: 1.0000 - accuracy: 0.9167 - f1-score: 0.8889\n",
      "0          tp: 3 - fp: 0 - fn: 2 - tn: 7 - precision: 1.0000 - recall: 0.6000 - accuracy: 0.8333 - f1-score: 0.7500\n",
      "1          tp: 2 - fp: 2 - fn: 1 - tn: 7 - precision: 0.5000 - recall: 0.6667 - accuracy: 0.7500 - f1-score: 0.5714\n",
      "2020-05-28 16:37:13,114 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dev_loss_history': [1.2610609531402588,\n",
       "  0.9575487971305847,\n",
       "  1.0690481662750244,\n",
       "  0.9532806277275085,\n",
       "  0.7961318492889404,\n",
       "  0.8032405972480774,\n",
       "  0.9901302456855774,\n",
       "  1.0061790943145752,\n",
       "  1.409272313117981,\n",
       "  1.34184730052948],\n",
       " 'dev_score_history': [0.7222222222222222,\n",
       "  0.6666666666666666,\n",
       "  0.7222222222222222,\n",
       "  0.7777777777777778,\n",
       "  0.6666666666666666,\n",
       "  0.8333333333333334,\n",
       "  0.8333333333333334,\n",
       "  0.8333333333333334,\n",
       "  0.7222222222222222,\n",
       "  0.7222222222222222],\n",
       " 'test_score': 0.8333333333333334,\n",
       " 'train_loss_history': [1.6039255857467651,\n",
       "  0.9995986819267273,\n",
       "  0.7806560397148132,\n",
       "  1.0005999505519867,\n",
       "  1.0892212986946106,\n",
       "  0.6222394704818726,\n",
       "  0.41739916801452637,\n",
       "  0.36568620800971985,\n",
       "  0.3373175859451294,\n",
       "  0.5574379116296768]}"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ModelTrainer(benchmark_classifier, corpus)\n",
    "trainer.train(new_data_folder, \n",
    "              max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SE8NBX-aMvL1"
   },
   "source": [
    "#### Stock folder after second stage fine tuning\n",
    "![alt text](https://raw.github.ubc.ca/ltian05/better_dwelling_capstone/aarontian/week_4/screenshots/Screen%20Shot%202020-05-25%20at%204.28.07%20PM.png?token=AAAAOMRZQTYPKV4SLOVBE2K62WIXG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlm7UQK5amSB"
   },
   "source": [
    "### Use model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UGktnLgaEJJg"
   },
   "outputs": [],
   "source": [
    "def finetuned_model_predictions(input_file_path, finetuned_classifier, output_file_path):\n",
    "  '''Makes Sentiment Predictions on unannotated data points contained in the input csvfile by loading the user-defined classifier.\n",
    "     Exports the csvfile by adding two columns 'pred_label' and 'confidence' and filling in results from model predictions.\n",
    "  '''\n",
    "\n",
    "  unannotated_df = pd.read_csv(input_file_path)\n",
    "  ## add two new columns to export predictions\n",
    "  #unannotated_df['pred_label'] = None\n",
    "  #unannotated_df['confidence'] = None\n",
    "  unannotated_df['best_label'] = None\n",
    "  unannotated_df['best_confidence'] = None\n",
    "  unannotated_df['second_likely'] = None\n",
    "  unannotated_df['second_confidence'] = None\n",
    "  unannotated_df['least_likely'] = None\n",
    "  unannotated_df['least_confidence'] = None\n",
    "\n",
    "\n",
    "  for i in range(len(unannotated_df)):\n",
    "\n",
    "    #print(unannotated_df['title_desc'].iloc[i])\n",
    "    sentence = Sentence(unannotated_df['title_desc'].iloc[i])\n",
    "\n",
    "    finetuned_classifier.predict(sentence,  multi_class_prob=True)\n",
    "\n",
    "    pred_score_label = [(sentence.labels[c].score, sentence.labels[c].value) for c in range(len(sentence.labels))]\n",
    "    pred_score_label.sort()\n",
    "\n",
    "    # list in ascending order on confidence score\n",
    "    best_label = int(pred_score_label[-1][1])\n",
    "    best_confidence = pred_score_label[-1][0]\n",
    "    second_likely_label = int(pred_score_label[-2][1]) \n",
    "    second_likely_confidence = pred_score_label[-2][0]\n",
    "    least_likely_label = int(pred_score_label[0][1]) \n",
    "    least_likely_confidence = pred_score_label[0][0]\n",
    "\n",
    "    #best_label_ind = np.argmax(pred_confs)\n",
    "    #best_confidence = sentence.labels[best_label_ind].value\n",
    "    #second_likely_ind = np.argsort(pred_confs)[-2] # array in ascending order\n",
    "    #second_likely_confidence = np.sort(pred_confs)[-2]\n",
    "    #least_likely_ind = np.argsort(pred_confs)[0]\n",
    "    #least_likely_confidence = np.sort(pred_confs)[0]\n",
    "    #print(sentence.labels)\n",
    "    #print(sentence.labels[0].value)\n",
    "    #print(sentence.labels[0].score)\n",
    "\n",
    "    #label_dict = {0:1,1:-1,2:0}\n",
    "\n",
    "    unannotated_df['best_label'].iloc[i] = best_label\n",
    "    unannotated_df['best_confidence'].iloc[i] = best_confidence\n",
    "    #print(label_dict[best_label_ind],best_confidence)\n",
    "    unannotated_df['second_likely'].iloc[i] = second_likely_label\n",
    "    unannotated_df['second_confidence'].iloc[i] = second_likely_confidence\n",
    "    unannotated_df['least_likely'].iloc[i] = least_likely_label\n",
    "    unannotated_df['least_confidence'].iloc[i] = least_likely_confidence\n",
    "\n",
    "    #unannotated_df['pred_label'].iloc[i] = sentence.labels[0].value\n",
    "    #unannotated_df['confidence'].iloc[i] = sentence.labels[0].score\n",
    "\n",
    "  print(f\"All { len(unannotated_df) } rows done prediction! \")\n",
    "\n",
    "  unannotated_df.to_csv(output_file_path,index=False)\n",
    "\n",
    "  print(\"Done export!\")\n",
    "\n",
    "\n",
    "#use case\n",
    "#new_data_folder = '/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/annotations_bnn_cbc/oversampled/'\n",
    "#finetuned_classifier = TextClassifier.load(new_data_folder + 'best-model.pt')\n",
    "#input_file_path = '/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/unannotated_for_predictions/predictions_dataset_GDP_Bloomberg.csv'\n",
    "#output_file_path = '/content/drive/My Drive/Colab Notebooks/capstone_betterdwelling/unannotated_for_predictions/unannotated_GDP_Bloomberg_predictions.csv'\n",
    "\n",
    "#finetuned_model_predictions(input_file_path, finetuned_classifier, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "X8TmXgayfilX",
    "outputId": "002b0564-eef1-4283-dfad-24219d94256e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence: \"Goldman Sachs now sees U.S. jobless rate peaking at 25%, not 15%. Goldman Sachs Group Inc. economists revised their forecasts to reflect a gloomier outlook for the U.S. labor market, though also the potential for a faster recovery from the coronavirus pandemic.\"   [− Tokens: 42  − Sentence-Labels: {'class': [0 (0.0043), -1 (0.8335), 1 (0.1621)]}]]\n",
      "[(0.004326847847551107, '0'), (0.8335288763046265, '-1'), (0.1621442437171936, '1')]\n",
      "[(0.004326847847551107, '0'), (0.1621442437171936, '1'), (0.8335288763046265, '-1')]\n"
     ]
    }
   ],
   "source": [
    "prediction_file = \"./drive/My Drive/capstone/data/prediction/\"\n",
    "bloomberg_employment = pd.read_csv(prediction_file + 'predictions_dataset_employment_Bloomberg.csv')\n",
    "for col, row in bloomberg_employment.iterrows():\n",
    "  title_desc = row['title_desc']\n",
    "  publish_date = row['publishedAt']\n",
    "  predicted = employment_classifier.predict(title_desc, multi_class_prob=True)\n",
    "  print(predicted)\n",
    "  pred_list = [(predicted[0].labels[c].score, predicted[0].labels[c].value) for c in range(len(predicted[0].labels))]\n",
    "  print(pred_list)\n",
    "  pred_list.sort()\n",
    "  print(pred_list)\n",
    "  \n",
    "  #print(predicted[0].labels[0].value)\n",
    "  #print(predicted[0].labels[0].score)\n",
    "  #print(predicted[0].labels[1])\n",
    "  break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yfNxCo43HQvY",
    "outputId": "d439a2fb-37f6-4f57-aeb1-35dfaf292aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 23:43:16,629 loading file ./drive/My Drive/capstone/data/second_stage_employment/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "employment_data_folder = './drive/My Drive/capstone/data/second_stage_employment/'\n",
    "prediction_file = \"./drive/My Drive/capstone/data/prediction/\"\n",
    "employment_file_path = prediction_file + 'predictions_dataset_employment_Bloomberg.csv'\n",
    "employment_classifier = TextClassifier.load(employment_data_folder + 'best-model.pt')\n",
    "employment_out_file_path = 'unannotated_employment_Bloomberg_predictions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wawKxC0XJwQD",
    "outputId": "7504de29-d4cb-4bbd-fd62-c20d3a4d2b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 23:47:23,307 loading file ./drive/My Drive/capstone/data/second_stage_stock/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "stock_data_folder = './drive/My Drive/capstone/data/second_stage_stock/'\n",
    "prediction_file = \"./drive/My Drive/capstone/data/prediction/\"\n",
    "stock_file_path = prediction_file + 'predictions_dataset_stockmarket_Bloomberg.csv'\n",
    "stock_classifier = TextClassifier.load(stock_data_folder + 'best-model.pt')\n",
    "#benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')\n",
    "stock_out_file_path = 'unannotated_stockmarket_Bloomberg_predictions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "A4HBXXnWi8Zx",
    "outputId": "0f9f8ff6-e96f-4c09-a5dd-943c38cab827"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 177 rows done prediction! \n",
      "Done export!\n"
     ]
    }
   ],
   "source": [
    "finetuned_model_predictions(stock_file_path, stock_classifier, stock_out_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_crptEMImwE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Two stage flair training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "010cce0aea28493395142cbe902d1c96": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a9bf515ae1c43858bd9dfa018099c76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9352560607e64304a280dd3b659c1401",
      "placeholder": "​",
      "style": "IPY_MODEL_c968cebc32074dadb00536adabe5f4b0",
      "value": " 433/433 [00:09&lt;00:00, 43.9B/s]"
     }
    },
    "111034d875a042b181ec27ab95493eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "133f98493e654f4a98a80c59e26324a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "149fbbfca875490eacfedf3dee2d3bab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1506181aa044402d94d73420b9e8314e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1745a2ab7cf1455ab9970f53544091b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_940f0d92faa34d69a70cc87bebe2f4ec",
      "placeholder": "​",
      "style": "IPY_MODEL_1e93801303b349f3b4b4c24bf655ace6",
      "value": " 440M/440M [00:09&lt;00:00, 45.5MB/s]"
     }
    },
    "1e93801303b349f3b4b4c24bf655ace6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f7a1ec90af14d919f8f2b6075483a93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1506181aa044402d94d73420b9e8314e",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c93f08209dea4de9a7e6503519e24a43",
      "value": 433
     }
    },
    "4c4be3c21c8848b3b668007be4c5c4ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d9aa008f1914208bc0fe13a47d61d57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b539d242fcf148dba6384f206950fec2",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d740f077937b423584eeb7b338411fab",
      "value": 231508
     }
    },
    "80b256e0b95848ea8159cefb51c40f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd2e1fe5770a489ea24fd889f4dcd85c",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_111034d875a042b181ec27ab95493eda",
      "value": 440473133
     }
    },
    "841075c3d81d45be8dbd463b49f4b616": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9352560607e64304a280dd3b659c1401": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "940f0d92faa34d69a70cc87bebe2f4ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b8e6eaa6f55457ca311a0a5e9f82cee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f7a1ec90af14d919f8f2b6075483a93",
       "IPY_MODEL_0a9bf515ae1c43858bd9dfa018099c76"
      ],
      "layout": "IPY_MODEL_133f98493e654f4a98a80c59e26324a8"
     }
    },
    "aa5cd174d4d349e39f24121162d339ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80b256e0b95848ea8159cefb51c40f2a",
       "IPY_MODEL_1745a2ab7cf1455ab9970f53544091b0"
      ],
      "layout": "IPY_MODEL_010cce0aea28493395142cbe902d1c96"
     }
    },
    "b539d242fcf148dba6384f206950fec2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6fefd65bcff4f21bde5a7ccff636080": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c4be3c21c8848b3b668007be4c5c4ba",
      "placeholder": "​",
      "style": "IPY_MODEL_149fbbfca875490eacfedf3dee2d3bab",
      "value": " 232k/232k [00:00&lt;00:00, 827kB/s]"
     }
    },
    "c77f1ef62e4b4eb096c479d3e32115fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d9aa008f1914208bc0fe13a47d61d57",
       "IPY_MODEL_c6fefd65bcff4f21bde5a7ccff636080"
      ],
      "layout": "IPY_MODEL_841075c3d81d45be8dbd463b49f4b616"
     }
    },
    "c93f08209dea4de9a7e6503519e24a43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c968cebc32074dadb00536adabe5f4b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d740f077937b423584eeb7b338411fab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dd2e1fe5770a489ea24fd889f4dcd85c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
