{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CBC SCRAPING CODE\n",
    "### Authors: JONATHAN CHAN and PANDRAMISHI NAGA SIRISHA\n",
    "\n",
    "###MOST RECENT UPDATE:  \n",
    "##2020 june 9, 9:19PM\n",
    "#edited scrape_urls to handle server error on 1000th API call\n",
    "#wrote docstrings, cleaned code\n",
    "\n",
    "#TO DO:\n",
    "#confirm cleanup of code with Sirisha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json \n",
    "from bs4 import BeautifulSoup\n",
    "#from datetime import date\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import pytz\n",
    "import dateutil.parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.cbc.ca/search_api/v1/search?q=interest%20rate%20index&sortOrder=relevance&page=1&fields=feed'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_initial_url(search_term):\n",
    "    \"\"\"returns the URL of the first page API call given a search string\n",
    "    \n",
    "    input:\n",
    "    search_term: search string\n",
    "    \"\"\"\n",
    "    \n",
    "    words = search_term.split()\n",
    "    url_prefix = \"https://www.cbc.ca/search_api/v1/search?\"\n",
    "    query = \"q=\" + \"%20\".join(words)\n",
    "    url_suffix = \"&sortOrder=relevance&page=1&fields=feed\"\n",
    "    first_url = url_prefix + query + url_suffix\n",
    "    #print(\"FIRST URL API CALL: \", first_url)\n",
    "    return first_url\n",
    "    \n",
    "get_initial_url(\"interest rate index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_urls(initial_url):\n",
    "    \"\"\"This function takes in the first query url and scrapes all other articles from past 1 year and returns \n",
    "    the urls of such articles\n",
    "    \n",
    "    input: \n",
    "    initial_url: URL of first call for CBC search API\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    url_list = []\n",
    "    current_date = datetime.datetime.now(datetime.timezone.utc)\n",
    "    last_year_date = current_date - timedelta(days=365)\n",
    "    main_url = initial_url\n",
    "    r = requests.get(initial_url)\n",
    "    info = r.json()\n",
    "     \n",
    "    for json_dict in info:\n",
    "        if dateutil.parser.parse(json_dict['publishtime']) > last_year_date:\n",
    "            url_list.append(json_dict[\"url\"])\n",
    "            \n",
    "    page_num = 2     \n",
    "    while len(info) != 0:\n",
    "        if page_num >= 1000: #internal server error after page 1000\n",
    "            break\n",
    "            \n",
    "        if page_num % 20 == 0:\n",
    "            print(\"API CALLS SCRAPED: \", str(page_num))\n",
    "            print(\"ARTICLES IN URL LIST: \", len(url_list))\n",
    "            \n",
    "        split_url = main_url.split(\"page\")\n",
    "        new_url = split_url[0] + \"page=\" + str(page_num) + \"&fields=feed\" \n",
    "        r = requests.get(new_url)\n",
    "        info = r.json()\n",
    "        \n",
    "        for json_dict in info:\n",
    "            if dateutil.parser.parse(json_dict['publishtime']) > last_year_date:\n",
    "                url_list.append(json_dict[\"url\"])\n",
    "        page_num += 1\n",
    "        \n",
    "    print(\"FINAL URLS FROM THE PAST YEAR: \", len(url_list))\n",
    "    \n",
    "    return url_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author(soup):\n",
    "    \"\"\"returns the author of a BeautifulSoup article if it exists, None if cannot be found\n",
    "    \n",
    "    Assume author info is contained within span tag (class: authorText)\n",
    "    \"\"\"\n",
    "    author_span = soup.find(\"span\", {\"class\": \"authorText\"})\n",
    "    \n",
    "    if author_span:\n",
    "        return author_span.text\n",
    "    else:\n",
    "        #print(\"No author found in article!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    \"\"\"returns the title of a BeautifulSoup article if it exists, None if cannot be found\n",
    "    \n",
    "    Assume title info is contained within h1 tag (class: detailHeadline)\n",
    "    \"\"\"\n",
    "    title_tag = soup.find(\"h1\", {\"class\": \"detailHeadline\"})\n",
    "    \n",
    "    if title_tag:\n",
    "        title_text = title_tag.text\n",
    "        return title_text\n",
    "    else:\n",
    "        #print(\"no title found in article!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc(soup):\n",
    "    \"\"\"returns the description of a BeautifulSoup article if it exists, None if not\n",
    "    \n",
    "    Assume description is contained within h2 tag (class: deck)\n",
    "    \"\"\"\n",
    "    desc_tag = soup.find(\"h2\", {\"class\": \"deck\"})\n",
    "    \n",
    "    if desc_tag:\n",
    "        desc_text = desc_tag.text\n",
    "        return desc_text\n",
    "    else:\n",
    "        #print(\"No description found in article!\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_to_image(soup):\n",
    "    \"\"\"returns the url to the header image of a CBC article (BeautifulSoup) if it exists, None if not\n",
    "    \n",
    "    Assume image url is contained within src attribute of img tag \n",
    "    \"\"\"\n",
    "    main_image_tag = soup.find(\"figure\", {\"class\": \"imageMedia leadmedia-story full\"})\n",
    "    \n",
    "    if main_image_tag:\n",
    "        main_image_url = main_image_tag.find(\"img\").attrs[\"src\"]\n",
    "        return main_image_url\n",
    "    else:\n",
    "        #print(\"No main header image found in article!\")\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publish_time(soup):\n",
    "    \"\"\"returns a tuple of publish time string and datetime string if found in article, None if not\n",
    "    \n",
    "    Assume time is contained within time tag (class: timestamp)\n",
    "    \"\"\"\n",
    "    time_tag = soup.find(\"time\", {\"class\": \"timeStamp\"})\n",
    "    if time_tag:\n",
    "        datetime_str = time_tag.attrs[\"datetime\"]\n",
    "        \n",
    "        #NOTE: if we want to return a datetime object, error when writing to JSON\n",
    "        #datetime_obj = parser.isoparse(datetime_str)\n",
    "        #SOLUTION: return as string for now, convert to datetime object later in pipeline\n",
    "        \n",
    "        #format of time_tag.text: \n",
    "        timetext_str = time_tag.text.split(\"|\")[0].replace(\"Posted: \", \"\").strip()\n",
    "        return (timetext_str, datetime_str)\n",
    "    else:\n",
    "        #print(\"No time information found in article!\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(soup, specify_source_type=True):\n",
    "    \"\"\"Returns the source of the article if it exists\n",
    "    if specify_source_type, subdivision of CBC will be returned\n",
    "    if not, \"CBC\" will be returned as the source\n",
    "    \n",
    "    \n",
    "    Assume that source always starts with \"CBC\" (Ex: \"CBC news\", \"CBC radio\")\n",
    "    Assume that source comes before span tag (class: bullet)\n",
    "    \"\"\"\n",
    "    \n",
    "    #source appears before <span class=\"bullet\"> Â· </span>\n",
    "    #if author is attached, there are two bullet tags\n",
    "    #if no author attached, there is one bullet tag\n",
    "    source = None\n",
    "    \n",
    "    if specify_source_type:\n",
    "        bullet_spans = soup.find_all(\"span\", {\"class\": \"bullet\"})\n",
    "        for bullet_span in bullet_spans:\n",
    "            previous_str = str(bullet_span.previous_sibling)\n",
    "            if previous_str.startswith(\"CBC\"):\n",
    "                source = previous_str\n",
    "    else:\n",
    "        \n",
    "        source = \"CBC\"\n",
    "    \n",
    "    if source:\n",
    "        return source\n",
    "    else:\n",
    "        #print(\"no source found in article!\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_content(soup, as_string=True):\n",
    "    \"\"\"Returns the text content from a CBC article (as BeautifulSoup object)\n",
    "    if as_string is True, return content as one string,\n",
    "    if as_string is False, return content as list of paragraph strings\n",
    "    \n",
    "    Input: BeautifulSoup object, boolean\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    story_tag = soup.find(\"div\", {\"class\": \"story\"}) \n",
    "    content_list = []\n",
    "    \n",
    "    if story_tag:\n",
    "        for p_tag in story_tag.find_all(\"p\"):\n",
    "            p_text = p_tag.text + \"\\n\"\n",
    "            content_list.append(p_text)\n",
    "\n",
    "        if as_string:\n",
    "            final_content = \"\".join(content_list)\n",
    "        else:\n",
    "            final_content = content_list #return content as list of paragraph strings\n",
    "\n",
    "        return final_content\n",
    "    else:\n",
    "        #print(\"no content found in article!\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_json_items(url, specify_source_type=True):\n",
    "    \"\"\"Returns a json containing the following items from a CBC article:\n",
    "        url: the url of the article\n",
    "        urlToImage: the url of the header image\n",
    "        title: the title of the article \n",
    "        description: subheader of the article\n",
    "        author: author (note that some articles do not specify author)\n",
    "        source: CBC if specify_source_type == False, subdivision of CBC if True (ex: \"CBC radio\")\n",
    "        publishedAt: tuple of (date_string, datetime object)\n",
    "        \n",
    "        input: url returned from CBC API in \"url\" field (missing \"http:\" as part of URL)\n",
    "    \"\"\"\n",
    "    json_dict = {}\n",
    "#     output_list = [] \n",
    "    article_url = \"http:\" + url\n",
    "    \n",
    "    #get HTML from article URL into BeautifulSoup\n",
    "    try:\n",
    "        html_bytes = urllib.request.urlopen(article_url)\n",
    "  \n",
    "    except HTTPError as e:\n",
    "        print('Error code: ', e.code)\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        print('Reason: ', e.reason)\n",
    "        return None\n",
    "\n",
    "    else:    \n",
    "        mybytes = html_bytes.read()\n",
    "        html = mybytes.decode(\"utf8\")\n",
    "        html_bytes.close()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        author_name = get_author(soup)\n",
    "        title_text = get_title(soup)\n",
    "        desc_text = get_desc(soup)\n",
    "        image_url = get_url_to_image(soup)\n",
    "        publish_time = get_publish_time(soup)\n",
    "        news_source = get_source(soup)\n",
    "        content = get_content(soup, True)\n",
    "        \n",
    "        json_dict[\"author\"] = author_name\n",
    "        json_dict[\"title\"] = title_text \n",
    "        json_dict[\"description\"] = desc_text\n",
    "        json_dict[\"url\"] = article_url\n",
    "        json_dict[\"urlToImage\"] = image_url\n",
    "        json_dict[\"publishedAt\"] = publish_time\n",
    "        json_dict[\"source\"] = news_source\n",
    "        json_dict[\"content\"] = content\n",
    "        \n",
    "        final_json = json.dumps(json_dict)\n",
    "        return json_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN FUNCTION CREATED BY SIRISHA\n",
    "def main(query):\n",
    "    \"\"\"\n",
    "    returns a json list containing all articles found from searching \n",
    "    CBC API using the given query and creates a json file containing \n",
    "    json info for each article\n",
    "    \n",
    "    input: query string\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    first_url = get_initial_url(query)\n",
    "    all_urls = scrape_urls(first_url)\n",
    "    json_list = []\n",
    "    json_count = 0\n",
    "    for each_url in all_urls:\n",
    "        retrieved_json  = extract_json_items(each_url)\n",
    "        if retrieved_json is not None:\n",
    "            json_list.append(retrieved_json)\n",
    "            \n",
    "            json_count += 1\n",
    "            if json_count % 20 == 0:\n",
    "                print(\"JSONS ADDED:\", json_count)\n",
    "    \n",
    "    full_query = query.split(\" \")\n",
    "    file_name_prefix = \"_\".join(full_query)\n",
    "    print(file_name_prefix)\n",
    "    \n",
    "    with open( file_name_prefix + '_' +'CBC_article' + '.json', 'w') as json_file:\n",
    "        json.dump(json_list, json_file)\n",
    "    \n",
    "    return json_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mortgage Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out - Sirisha collected these samples\n",
    "\n",
    "\n",
    "# cbc_mr_article = main(\"mortgage rates\")\n",
    "# print(len(cbc_mr_article))\n",
    "# print(cbc_mr_article[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out - Sirisha collected these samples\n",
    "\n",
    "# cbc_ir_article =  main(\"interest rate\")\n",
    "# print(len(cbc_hp_article))\n",
    "# print(cbc_hp_article[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out - Sirisha collected these samples\n",
    "\n",
    "\n",
    "# cbc_hp_article = main('housing price')\n",
    "# print(len(cbc_hp_article))\n",
    "# print(cbc_hp_article[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API CALLS SCRAPED:  20\n",
      "ARTICLES IN URL LIST:  105\n",
      "API CALLS SCRAPED:  40\n",
      "ARTICLES IN URL LIST:  111\n",
      "API CALLS SCRAPED:  60\n",
      "ARTICLES IN URL LIST:  234\n",
      "API CALLS SCRAPED:  80\n",
      "ARTICLES IN URL LIST:  428\n",
      "API CALLS SCRAPED:  100\n",
      "ARTICLES IN URL LIST:  591\n",
      "API CALLS SCRAPED:  120\n",
      "ARTICLES IN URL LIST:  730\n",
      "API CALLS SCRAPED:  140\n",
      "ARTICLES IN URL LIST:  829\n",
      "API CALLS SCRAPED:  160\n",
      "ARTICLES IN URL LIST:  913\n",
      "API CALLS SCRAPED:  180\n",
      "ARTICLES IN URL LIST:  1007\n",
      "API CALLS SCRAPED:  200\n",
      "ARTICLES IN URL LIST:  1077\n",
      "API CALLS SCRAPED:  220\n",
      "ARTICLES IN URL LIST:  1129\n",
      "API CALLS SCRAPED:  240\n",
      "ARTICLES IN URL LIST:  1185\n",
      "API CALLS SCRAPED:  260\n",
      "ARTICLES IN URL LIST:  1227\n",
      "API CALLS SCRAPED:  280\n",
      "ARTICLES IN URL LIST:  1290\n",
      "API CALLS SCRAPED:  300\n",
      "ARTICLES IN URL LIST:  1327\n",
      "API CALLS SCRAPED:  320\n",
      "ARTICLES IN URL LIST:  1392\n",
      "API CALLS SCRAPED:  340\n",
      "ARTICLES IN URL LIST:  1459\n",
      "API CALLS SCRAPED:  360\n",
      "ARTICLES IN URL LIST:  1502\n",
      "API CALLS SCRAPED:  380\n",
      "ARTICLES IN URL LIST:  1536\n",
      "API CALLS SCRAPED:  400\n",
      "ARTICLES IN URL LIST:  1573\n",
      "API CALLS SCRAPED:  420\n",
      "ARTICLES IN URL LIST:  1629\n",
      "API CALLS SCRAPED:  440\n",
      "ARTICLES IN URL LIST:  1692\n",
      "API CALLS SCRAPED:  460\n",
      "ARTICLES IN URL LIST:  1754\n",
      "API CALLS SCRAPED:  480\n",
      "ARTICLES IN URL LIST:  1796\n",
      "API CALLS SCRAPED:  500\n",
      "ARTICLES IN URL LIST:  1815\n",
      "API CALLS SCRAPED:  520\n",
      "ARTICLES IN URL LIST:  1849\n",
      "API CALLS SCRAPED:  540\n",
      "ARTICLES IN URL LIST:  1881\n",
      "API CALLS SCRAPED:  560\n",
      "ARTICLES IN URL LIST:  1907\n",
      "API CALLS SCRAPED:  580\n",
      "ARTICLES IN URL LIST:  1930\n",
      "API CALLS SCRAPED:  600\n",
      "ARTICLES IN URL LIST:  1954\n",
      "API CALLS SCRAPED:  620\n",
      "ARTICLES IN URL LIST:  2005\n",
      "API CALLS SCRAPED:  640\n",
      "ARTICLES IN URL LIST:  2038\n",
      "API CALLS SCRAPED:  660\n",
      "ARTICLES IN URL LIST:  2078\n",
      "API CALLS SCRAPED:  680\n",
      "ARTICLES IN URL LIST:  2101\n",
      "API CALLS SCRAPED:  700\n",
      "ARTICLES IN URL LIST:  2133\n",
      "API CALLS SCRAPED:  720\n",
      "ARTICLES IN URL LIST:  2163\n",
      "API CALLS SCRAPED:  740\n",
      "ARTICLES IN URL LIST:  2191\n",
      "API CALLS SCRAPED:  760\n",
      "ARTICLES IN URL LIST:  2202\n",
      "API CALLS SCRAPED:  780\n",
      "ARTICLES IN URL LIST:  2225\n",
      "API CALLS SCRAPED:  800\n",
      "ARTICLES IN URL LIST:  2240\n",
      "API CALLS SCRAPED:  820\n",
      "ARTICLES IN URL LIST:  2255\n",
      "API CALLS SCRAPED:  840\n",
      "ARTICLES IN URL LIST:  2274\n",
      "API CALLS SCRAPED:  860\n",
      "ARTICLES IN URL LIST:  2290\n",
      "API CALLS SCRAPED:  880\n",
      "ARTICLES IN URL LIST:  2305\n",
      "API CALLS SCRAPED:  900\n",
      "ARTICLES IN URL LIST:  2328\n",
      "API CALLS SCRAPED:  920\n",
      "ARTICLES IN URL LIST:  2346\n",
      "API CALLS SCRAPED:  940\n",
      "ARTICLES IN URL LIST:  2353\n",
      "API CALLS SCRAPED:  960\n",
      "ARTICLES IN URL LIST:  2359\n",
      "API CALLS SCRAPED:  980\n",
      "ARTICLES IN URL LIST:  2371\n",
      "FINAL URLS FROM THE PAST YEAR:  2379\n",
      "JSONS ADDED: 20\n",
      "JSONS ADDED: 40\n",
      "JSONS ADDED: 60\n",
      "JSONS ADDED: 80\n",
      "JSONS ADDED: 100\n",
      "JSONS ADDED: 120\n",
      "JSONS ADDED: 140\n",
      "JSONS ADDED: 160\n",
      "JSONS ADDED: 180\n",
      "JSONS ADDED: 200\n",
      "JSONS ADDED: 220\n",
      "JSONS ADDED: 240\n",
      "JSONS ADDED: 260\n",
      "JSONS ADDED: 280\n",
      "JSONS ADDED: 300\n",
      "JSONS ADDED: 320\n",
      "JSONS ADDED: 340\n",
      "JSONS ADDED: 360\n",
      "JSONS ADDED: 380\n",
      "JSONS ADDED: 400\n",
      "JSONS ADDED: 420\n",
      "JSONS ADDED: 440\n",
      "JSONS ADDED: 460\n",
      "JSONS ADDED: 480\n",
      "JSONS ADDED: 500\n",
      "JSONS ADDED: 520\n",
      "JSONS ADDED: 540\n",
      "JSONS ADDED: 560\n",
      "JSONS ADDED: 580\n",
      "JSONS ADDED: 600\n",
      "JSONS ADDED: 620\n",
      "JSONS ADDED: 640\n",
      "JSONS ADDED: 660\n",
      "JSONS ADDED: 680\n",
      "JSONS ADDED: 700\n",
      "JSONS ADDED: 720\n",
      "JSONS ADDED: 740\n",
      "JSONS ADDED: 760\n",
      "JSONS ADDED: 780\n",
      "JSONS ADDED: 800\n",
      "JSONS ADDED: 820\n",
      "JSONS ADDED: 840\n",
      "JSONS ADDED: 860\n",
      "Error code:  500\n",
      "JSONS ADDED: 880\n",
      "JSONS ADDED: 900\n",
      "JSONS ADDED: 920\n",
      "JSONS ADDED: 940\n",
      "JSONS ADDED: 960\n",
      "Error code:  500\n",
      "JSONS ADDED: 980\n",
      "JSONS ADDED: 1000\n",
      "JSONS ADDED: 1020\n",
      "JSONS ADDED: 1040\n",
      "JSONS ADDED: 1060\n",
      "Error code:  504\n",
      "JSONS ADDED: 1080\n",
      "JSONS ADDED: 1100\n",
      "JSONS ADDED: 1120\n",
      "JSONS ADDED: 1140\n",
      "JSONS ADDED: 1160\n",
      "JSONS ADDED: 1180\n",
      "JSONS ADDED: 1200\n",
      "JSONS ADDED: 1220\n",
      "JSONS ADDED: 1240\n",
      "JSONS ADDED: 1260\n",
      "JSONS ADDED: 1280\n",
      "JSONS ADDED: 1300\n",
      "JSONS ADDED: 1320\n",
      "JSONS ADDED: 1340\n",
      "JSONS ADDED: 1360\n",
      "JSONS ADDED: 1380\n",
      "JSONS ADDED: 1400\n",
      "JSONS ADDED: 1420\n",
      "JSONS ADDED: 1440\n",
      "JSONS ADDED: 1460\n",
      "JSONS ADDED: 1480\n",
      "JSONS ADDED: 1500\n",
      "JSONS ADDED: 1520\n",
      "JSONS ADDED: 1540\n",
      "JSONS ADDED: 1560\n",
      "JSONS ADDED: 1580\n",
      "JSONS ADDED: 1600\n",
      "JSONS ADDED: 1620\n",
      "JSONS ADDED: 1640\n",
      "JSONS ADDED: 1660\n",
      "JSONS ADDED: 1680\n",
      "JSONS ADDED: 1700\n",
      "JSONS ADDED: 1720\n",
      "JSONS ADDED: 1740\n",
      "JSONS ADDED: 1760\n",
      "JSONS ADDED: 1780\n",
      "JSONS ADDED: 1800\n",
      "JSONS ADDED: 1820\n",
      "JSONS ADDED: 1840\n",
      "JSONS ADDED: 1860\n",
      "JSONS ADDED: 1880\n",
      "JSONS ADDED: 1900\n",
      "JSONS ADDED: 1920\n",
      "JSONS ADDED: 1940\n",
      "JSONS ADDED: 1960\n",
      "JSONS ADDED: 1980\n",
      "JSONS ADDED: 2000\n",
      "JSONS ADDED: 2020\n",
      "JSONS ADDED: 2040\n",
      "JSONS ADDED: 2060\n",
      "JSONS ADDED: 2080\n",
      "JSONS ADDED: 2100\n",
      "JSONS ADDED: 2120\n",
      "JSONS ADDED: 2140\n",
      "JSONS ADDED: 2160\n",
      "Error code:  404\n",
      "JSONS ADDED: 2180\n",
      "JSONS ADDED: 2200\n",
      "JSONS ADDED: 2220\n",
      "JSONS ADDED: 2240\n",
      "Error code:  404\n",
      "Error code:  404\n",
      "JSONS ADDED: 2260\n",
      "JSONS ADDED: 2280\n",
      "JSONS ADDED: 2300\n",
      "JSONS ADDED: 2320\n",
      "JSONS ADDED: 2340\n",
      "JSONS ADDED: 2360\n",
      "employment\n",
      "2373\n",
      "{'author': None, 'title': None, 'description': None, 'url': 'http://www.cbc.ca/player/play/1748573251802', 'urlToImage': None, 'publishedAt': None, 'source': None, 'content': None}\n"
     ]
    }
   ],
   "source": [
    "cbc_e_article = main('employment')\n",
    "print(len(cbc_e_article))\n",
    "print(cbc_e_article[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API CALLS SCRAPED:  20\n",
      "ARTICLES IN URL LIST:  80\n",
      "API CALLS SCRAPED:  40\n",
      "ARTICLES IN URL LIST:  136\n",
      "API CALLS SCRAPED:  60\n",
      "ARTICLES IN URL LIST:  179\n",
      "API CALLS SCRAPED:  80\n",
      "ARTICLES IN URL LIST:  218\n",
      "API CALLS SCRAPED:  100\n",
      "ARTICLES IN URL LIST:  254\n",
      "API CALLS SCRAPED:  120\n",
      "ARTICLES IN URL LIST:  267\n",
      "API CALLS SCRAPED:  140\n",
      "ARTICLES IN URL LIST:  296\n",
      "API CALLS SCRAPED:  160\n",
      "ARTICLES IN URL LIST:  314\n",
      "API CALLS SCRAPED:  180\n",
      "ARTICLES IN URL LIST:  320\n",
      "API CALLS SCRAPED:  200\n",
      "ARTICLES IN URL LIST:  326\n",
      "API CALLS SCRAPED:  220\n",
      "ARTICLES IN URL LIST:  329\n",
      "FINAL URLS FROM THE PAST YEAR:  334\n",
      "JSONS ADDED: 20\n",
      "JSONS ADDED: 40\n",
      "JSONS ADDED: 60\n",
      "JSONS ADDED: 80\n",
      "JSONS ADDED: 100\n",
      "JSONS ADDED: 120\n",
      "JSONS ADDED: 140\n",
      "JSONS ADDED: 160\n",
      "JSONS ADDED: 180\n",
      "JSONS ADDED: 200\n",
      "JSONS ADDED: 220\n",
      "JSONS ADDED: 240\n",
      "JSONS ADDED: 260\n",
      "JSONS ADDED: 280\n",
      "JSONS ADDED: 300\n",
      "JSONS ADDED: 320\n",
      "GDP\n",
      "334\n",
      "{'author': 'Pete Evans', 'title': \"Canada's economy shrank at 8% pace in the first three months of 2020, worst since 2009\", 'description': 'March was biggest one-month plunge in GDP since record-keeping began in 1961', 'url': 'http://www.cbc.ca/news/business/statistics-canada-gdp-1.5589843', 'urlToImage': 'https://i.cbc.ca/1.5589873.1590758145!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/coronavirus-social-distancing.jpg', 'publishedAt': ('May 29, 2020 9:58 AM ET', '2020-05-29T20:00:36.780Z'), 'source': 'CBC News', 'content': 'Canada\\'s economy shrank at an 8.2 per cent annual pace in the first three months of 2020, as an already weak economy in January and February was walloped by COVID-19 in March.\\nStatistics Canada reported Friday that the slowdown was the sharpest quarterly drop since the financial crisis of 2009, as measures to contain the pandemic such as school and business closures, border shutdowns\\xa0and travel restrictions brought economic activity grinding to a halt.\\xa0\\nWhile bleak, the eight per cent decline was better than the ten per cent contraction that economists had been expecting for the period. For comparison purposes, the U.S. economy shrank by five per cent over the same time frame.\\nWhile the vast majority of the contraction came in March when the pandemic hit, January and February\\'s numbers weren\\'t overly strong to begin with due to pre-existing drags such as rail blockades across the country, and a teacher strike in Ontario in February.\\xa0\\nIn absolute terms, Canada\\'s gross domestic product was 2.1 per cent smaller over the three months\\xa0than it was at the end of 2019. But much of that came in March alone, as GDP declined by 7.2 per cent during the month. That makes March 2020 the worst month for Canada\\'s economy since record-keeping began in 1961.\\nJust about everything got walloped, as 19 out of the 20 sectors the data agency monitors got smaller. The one exception was utilities, which eked out a gain of 0.4 per cent.\\nWhile March shattered the previous monthly record for slowdowns, early data suggests April\\'s numbers will be even worse, showing an 11 per cent contraction from March\\'s already depressed level.\\nBy sector, the slowdown in March was striking, including:\\nEconomist Doug Porter at Bank of Montreal found some reasons for optimism amid the gloomy numbers, noting that many parts of the economy did better than initially feared.\\n\"The new news here is that the figures were a little less dire than feared,\" he said. \"Consumer spending\\xa0fell only nine\\xa0per cent in the quarter, while business investment was down a mild 2.7 per cent\\xa0(less bad than Q4 in fact), and housing dipped just 0.4 per cent.\"\\nOverall, Porter said the 8.2 per cent pace of contraction\\xa0puts Canada right in the middle of its G7 peers. Canada\\'s economy did worse than Japan\\'s, which shrank at a 3.4 per cent pace, over the period. But Canada is faring much better than\\xa0Italy and France, which\\xa0saw their economies shrink at paces of 17.7\\xa0 and\\xa0 21.4 per cent in the same period.\\nAlicia Macdonald with the Conference Board of Canada said \"the numbers this morning leave no question that Canada is in the midst of its deepest recession in decades. However, with restrictions easing across the country, the economy should have hit bottom in April and we should see positive growth in the months ahead.\"\\n'}\n"
     ]
    }
   ],
   "source": [
    "cbc_gdp_article = main('GDP')\n",
    "print(len(cbc_gdp_article))\n",
    "print(cbc_gdp_article[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API CALLS SCRAPED:  20\n",
      "ARTICLES IN URL LIST:  67\n",
      "API CALLS SCRAPED:  40\n",
      "ARTICLES IN URL LIST:  226\n",
      "API CALLS SCRAPED:  60\n",
      "ARTICLES IN URL LIST:  341\n",
      "API CALLS SCRAPED:  80\n",
      "ARTICLES IN URL LIST:  403\n",
      "API CALLS SCRAPED:  100\n",
      "ARTICLES IN URL LIST:  464\n",
      "API CALLS SCRAPED:  120\n",
      "ARTICLES IN URL LIST:  519\n",
      "API CALLS SCRAPED:  140\n",
      "ARTICLES IN URL LIST:  562\n",
      "API CALLS SCRAPED:  160\n",
      "ARTICLES IN URL LIST:  590\n",
      "API CALLS SCRAPED:  180\n",
      "ARTICLES IN URL LIST:  619\n",
      "API CALLS SCRAPED:  200\n",
      "ARTICLES IN URL LIST:  638\n",
      "API CALLS SCRAPED:  220\n",
      "ARTICLES IN URL LIST:  645\n",
      "API CALLS SCRAPED:  240\n",
      "ARTICLES IN URL LIST:  656\n",
      "API CALLS SCRAPED:  260\n",
      "ARTICLES IN URL LIST:  677\n",
      "API CALLS SCRAPED:  280\n",
      "ARTICLES IN URL LIST:  694\n",
      "API CALLS SCRAPED:  300\n",
      "ARTICLES IN URL LIST:  716\n",
      "API CALLS SCRAPED:  320\n",
      "ARTICLES IN URL LIST:  730\n",
      "API CALLS SCRAPED:  340\n",
      "ARTICLES IN URL LIST:  746\n",
      "API CALLS SCRAPED:  360\n",
      "ARTICLES IN URL LIST:  759\n",
      "API CALLS SCRAPED:  380\n",
      "ARTICLES IN URL LIST:  765\n",
      "API CALLS SCRAPED:  400\n",
      "ARTICLES IN URL LIST:  770\n",
      "API CALLS SCRAPED:  420\n",
      "ARTICLES IN URL LIST:  776\n",
      "API CALLS SCRAPED:  440\n",
      "ARTICLES IN URL LIST:  786\n",
      "API CALLS SCRAPED:  460\n",
      "ARTICLES IN URL LIST:  796\n",
      "API CALLS SCRAPED:  480\n",
      "ARTICLES IN URL LIST:  798\n",
      "API CALLS SCRAPED:  500\n",
      "ARTICLES IN URL LIST:  824\n",
      "API CALLS SCRAPED:  520\n",
      "ARTICLES IN URL LIST:  831\n",
      "API CALLS SCRAPED:  540\n",
      "ARTICLES IN URL LIST:  839\n",
      "API CALLS SCRAPED:  560\n",
      "ARTICLES IN URL LIST:  842\n",
      "API CALLS SCRAPED:  580\n",
      "ARTICLES IN URL LIST:  853\n",
      "FINAL URLS FROM THE PAST YEAR:  853\n",
      "JSONS ADDED: 20\n",
      "JSONS ADDED: 40\n",
      "JSONS ADDED: 60\n",
      "JSONS ADDED: 80\n",
      "JSONS ADDED: 100\n",
      "JSONS ADDED: 120\n",
      "JSONS ADDED: 140\n",
      "JSONS ADDED: 160\n",
      "JSONS ADDED: 180\n",
      "JSONS ADDED: 200\n",
      "JSONS ADDED: 220\n",
      "JSONS ADDED: 240\n",
      "JSONS ADDED: 260\n",
      "JSONS ADDED: 280\n",
      "Error code:  404\n",
      "JSONS ADDED: 300\n",
      "JSONS ADDED: 320\n",
      "JSONS ADDED: 340\n",
      "JSONS ADDED: 360\n",
      "JSONS ADDED: 380\n",
      "Error code:  404\n",
      "JSONS ADDED: 400\n",
      "JSONS ADDED: 420\n",
      "JSONS ADDED: 440\n",
      "JSONS ADDED: 460\n",
      "JSONS ADDED: 480\n",
      "JSONS ADDED: 500\n",
      "Error code:  404\n",
      "JSONS ADDED: 520\n",
      "JSONS ADDED: 540\n",
      "JSONS ADDED: 560\n",
      "JSONS ADDED: 580\n",
      "JSONS ADDED: 600\n",
      "JSONS ADDED: 620\n",
      "JSONS ADDED: 640\n",
      "JSONS ADDED: 660\n",
      "JSONS ADDED: 680\n",
      "JSONS ADDED: 700\n",
      "JSONS ADDED: 720\n",
      "JSONS ADDED: 740\n",
      "JSONS ADDED: 760\n",
      "JSONS ADDED: 780\n",
      "JSONS ADDED: 800\n",
      "JSONS ADDED: 820\n",
      "Error code:  504\n",
      "JSONS ADDED: 840\n",
      "stock_market\n",
      "849\n",
      "{'author': None, 'title': 'Chesapeake Energy shares halted after 50% plunge on bankruptcy report', 'description': 'Company was a pioneer of fracking but has fallen on tough times lately', 'url': 'http://www.cbc.ca/news/business/chesapeake-energy-1.5604727', 'urlToImage': 'https://i.cbc.ca/1.3438690.1454951739!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/chesapeake-energy-layoffs.jpg', 'publishedAt': ('Jun 09, 2020 3:18 PM ET', '2020-06-09T20:26:10.112Z'), 'source': 'CBC News', 'content': 'Shares in one of the biggest natural gas companies in the U.S. were halted on Tuesday\\xa0after plunging by half on a report the company could be about to go bankrupt.\\nFinancial news agency Bloomberg first reported that Chesapeake Energy is considering an arrangement whereby some of its biggest creditors would take control of the company, potentially wiping out shareholders in the process.\\nThe move would be a shocking turn of events for a company that once rivalled Exxon in terms of its influence in the U.S. energy sector. The Oklahoma-based company was founded in 1989, and became a pioneer in fracking, a controversial process of injecting pressurized water and chemicals into previously unobtainable natural gas reservoirs in order to extract them.\\nAt its peak, the company was one of the most influential energy companies in the U.S., but it has been hit hard recently amid declining energy prices and COVID-19.\\nThe company was trying to pivot from natural gas to a greater emphasis on oil when a Saudi-Russian energy price war earlier this year upended those plans and the oil market as a whole.\\nBut the company\\'s main problem is its debt load, which it accumulated during an aggressive pace of acquisitions.\\nThe company owes almost $9 billion\\xa0â more than ten times the company\\'s current value. The bankruptcy plan is seemingly those lenders taking over the company in order to get as much of their money back as they can.\\nChesapeake\\'s shares nearly tripled\\xa0on Monday under extremely heavy trading in what was likely a short squeeze â a sudden move higher for stocks investors are betting heavily against. About 20 per cent of Chesapeake\\'s shareholders are shorting the stock right now, according to financial data firm Fintel.\\nWatch the video below for an explainer of what short selling is, and how it works:\\nThe stock was halted 22 times due to the volatility.\\nAfter markets closed on Monday, the Bloomberg report of bankruptcy plans sent investors running for the exits.\\nChesapeake shares were changing hands at $32.25 on the NYSE on Tuesday, down 54 per cent from Monday\\'s level. Trading in the shares were halted another 14 times on Wednesday. At current prices, the company is worth about $700 million, a fraction of the almost $40 billion it was worth more than a decade ago.\\nIn April the company\\xa0implemented a 200-for-1 stock consolidation\\xa0in an attempt to stop its shares from being delisted from the stock exchange. In May it warned that bankruptcy was possible, telling investors as it withdrew its financial guidance that it was\\xa0\"working with its financial and legal advisors to best position Chesapeake for the future, including analyzing all available strategic alternatives to address its capital structure and improve its financial position.\"\\nChesapeake had about 2,300 employees at the end of last year, before announcing a 13 per cent cut to its workforce in April.\\n\\xa0\\n\\xa0\\n'}\n"
     ]
    }
   ],
   "source": [
    "cbc_tsx_article = main('stock market')\n",
    "print(len(cbc_tsx_article))\n",
    "print(cbc_tsx_article[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DELETE - tests\n",
    "\n",
    "\n",
    "# #TEST ON DIFFERENT CBC LINKS RETURNED BY CBC API\n",
    "\n",
    "# standard_url = \"//www.cbc.ca/news/politics/federal-deficit-higher-than-252-billion-1.5566768\"\n",
    "# radio_url = \"//www.cbc.ca/radio/costofliving/slashed-interest-rates-getting-a-piece-of-the-electric-car-pie-and-a-happy-jobs-friday-to-all-1.5486253\"\n",
    "# media_url = \"//www.cbc.ca/player/play/1707317315674\"\n",
    "# noauthor_url = \"//www.cbc.ca/news/canada/coronavirus-covid19-world-canada-may12-1.5564261\"\n",
    "\n",
    "\n",
    "\n",
    "# extract_json_items(standard_url)\n",
    "\n",
    "# #note: doesn't work for 'player' URLS (\"//www.cbc.ca/player/play/1707317315674\")\n",
    "# #will run, but will return null for most values - player articles have different setup\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
