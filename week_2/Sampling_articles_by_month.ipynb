{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CBC SCRAPING CODE\n",
    "### Authors: JONATHAN CHAN and PANDRAMISHI NAGA SIRISHA\n",
    "\n",
    "###MOST RECENT UPDATE:  \n",
    "##2020 MAY 19, 9:17PM\n",
    "#wrote function to create the final csvs with truncated dates\n",
    "\n",
    "#TO DO:\n",
    "#confirm docstrings with sirisha - what modifications were done to json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json \n",
    "from bs4 import BeautifulSoup\n",
    "#from datetime import date\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import pytz\n",
    "import dateutil.parser\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import json\n",
<<<<<<< HEAD
    "import csv"
=======
    "import csv\n",
    "import pandas as pd"
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(filename,list_name):\n",
    "    \"\"\"creates a csv containing title and description of articles in a given JSON\"\"\"\n",
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(filename,list_name): #NOTE TO SIRISHA: unsure of what modifications were done to this function?\n",
    "    \"\"\"creates a csv containing title and description of articles in a given JSON\n",
    "    \n",
    "    \"\"\"\n",
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
    "    ind = 0\n",
    "    title_list = []\n",
    "    desc_list = []\n",
    "    date_list =[]\n",
    "\n",
    "    for json_dict in list_name:\n",
    "        #check if valid title exists\n",
    "        if json_dict[\"title\"]:\n",
    "            title_list.append(json_dict[\"title\"])\n",
    "            desc_list.append(json_dict[\"description\"])\n",
<<<<<<< HEAD
    "            date_list.append(dateutil.parser.parse(json_dict['publishedAt'][1]).month)\n",
=======
    "            #date_list.append(dateutil.parser.parse(json_dict['publishedAt'][1]).month)\n",
    "            date_list.append(dateutil.parser.parse(json_dict['publishedAt'][1]))\n",
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
    "            ind += 1\n",
    "            \n",
    "            \n",
    "    prefix = filename.split(\".\")[0]\n",
    "    out_filename = prefix  + \"_\" + str(ind) + \"_to_annotate.csv\"\n",
    "    with open(out_filename, 'w') as myfile:\n",
    "        writer = csv.writer(myfile)\n",
    "        #wr.writerow(mylist)\n",
<<<<<<< HEAD
    "        writer.writerow([\"title\", \"description\"])\n",
    "        for i in range(len(title_list)):\n",
    "            writer.writerow([title_list[i], desc_list[i], date_list[i]])\n",
    "                \n",
    "                \n",
    "# json_to_csv(\"mortgage_rates_CBC_article.json\")"
=======
    "        writer.writerow([\"title\", \"description\",])\n",
    "        for i in range(len(title_list)):\n",
    "            writer.writerow([title_list[i], desc_list[i], date_list[i]])\n",
    "                \n",
    "                \n"
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_subset_in_csv(filename, sample_size):\n",
=======
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'employment_CBC_article.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a84e2c16387e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mjson_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mextract_subset_in_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"employment_CBC_article.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-a84e2c16387e>\u001b[0m in \u001b[0;36mextract_subset_in_csv\u001b[0;34m(filename, sample_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m     11\u001b[0m     \u001b[0marticle_dictionary_by_month\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfull_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'employment_CBC_article.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_subset_in_csv(filename, sample_size):\n",
    "    \"\"\"\n",
    "    returns a csv containing a subset of articles to annotate\n",
    "    w/ sample_size articles from each month\n",
    "    \n",
    "    (columns: title, description, and date)\n",
    "    \n",
    "    input: \n",
    "    filename: json containing article info\n",
    "    sample_size: number of articles to be collected from each month\n",
    "    \"\"\"\n",
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
    "    article_dictionary_by_month = defaultdict(list)\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "        full_list = []\n",
    "        for json_dict in data:\n",
    "            if json_dict['publishedAt'] == None or json_dict['title'] == None or json_dict['description'] == None or json_dict['content'] == None :\n",
    "                pass\n",
    "            else:\n",
    "                article_date = (dateutil.parser.parse(json_dict['publishedAt'][1]))\n",
    "                article_month = article_date.month\n",
    "                article_dictionary_by_month[article_month].append(json_dict)\n",
    "                \n",
    "        for month_number, list_of_articles in sorted(article_dictionary_by_month.items()):\n",
    "            random.shuffle(list_of_articles)\n",
    "            subset_list = list_of_articles[:sample_size]\n",
    "            full_list = full_list + subset_list\n",
    "        json_to_csv(filename,full_list)\n",
    "\n",
<<<<<<< HEAD
    "extract_subset_in_csv(\"mortgage_rates_CBC_article_full.json\", 5)"
=======
    "extract_subset_in_csv(\"employment_CBC_article.json\", 5)"
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 71,
=======
   "execution_count": 4,
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in sorted(article_dictionary_by_month.keys()):\n",
    "#     print(\"For month = \",i,\", number of articles are\", len(article_dictionary_by_month[i]))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "economic_indicators_articles = [\"employment_CBC_article.json\", \"GDP_CBC_article.json\", \"housing_price_CBC_article.json\", \"mortgage_rates_CBC_article.json\",\"stock_market_CBC_article.json\"]"
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# economic_indicators_articles = [\"employment_CBC_article.json\", \"GDP_CBC_article.json\", \"housing_price_CBC_article.json\", \"mortgage_rates_CBC_article.json\",\"stock_market_CBC_article.json\"]"
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "for ec in economic_indicators_articles:\n",
    "    extract_subset_in_csv(ec, 5)"
=======
    "# for ec in economic_indicators_articles:\n",
    "#     extract_subset_in_csv(ec, 5)"
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filename\") as f:\n",
    "    data = json.load(f)"
   ]
=======
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_with_dates(csv_file, json_file):\n",
    "    \"\"\"\n",
    "    USE WHEN ADDING DATES TO A CSV ALREADY MANUALLY ANNOTATED\n",
    "    \n",
    "    Returns a new csv with added date column from the associated json file\n",
    "    \n",
    "    input: \n",
    "    csv_file: csv with title, description, sentiment rows only\n",
    "    json_file: json to search the date for each article title\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    new_csv_name = csv_file.split(\".\")[0] + \"_updated.csv\"\n",
    "\n",
    "    title_list = []\n",
    "    desc_list = []\n",
    "    anno_list =[]\n",
    "    \n",
    "    with open(csv_file, 'r', encoding = \"utf-8\") as myfile:\n",
    "        reader = csv.reader(myfile)\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            title_list.append(row[0])\n",
    "            desc_list.append(row[1])\n",
    "            anno_list.append(row[2])\n",
    "    \n",
    "    date_list = []\n",
    "    \n",
    "    with open(json_file) as myjson:\n",
    "        data = json.load(myjson)\n",
    "        \n",
    "        for title in title_list:\n",
    "            current_date = None\n",
    "            for json_dict in data:\n",
    "                if json_dict[\"title\"] == title:\n",
    "                    current_date = json_dict['publishedAt'][1]\n",
    "            date_list.append(current_date)\n",
    "    \n",
    "    with open(new_csv_name, 'w') as myfile:\n",
    "        writer = csv.writer(myfile)\n",
    "        writer.writerow([\"title\", \"description\",\"date\", \"Sentiment\"])\n",
    "        for i in range(len(title_list)):\n",
    "            writer.writerow([title_list[i], desc_list[i], date_list[i], anno_list[i]])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#csv_with_dates(\"stock_market_CBC_article_60_annotated_once.csv\", \"stock_market_CBC_article.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xls_to_csv(xls_name, sheet_name, iso_delimiter):\n",
    "    \"\"\"returns a csv for the corresponding sheet of an xls \n",
    "    \n",
    "    date column should be converted from ISO datetime format\n",
    "    (yyyy-MM-dd'T'HH:mm:ss.SSSZZ) to YYYY-MM-DD format\n",
    "    all other columns remain the same.\n",
    "    \n",
    "    input:\n",
    "    xls_name: xlsx file with sheet for each of the 6 indicators\n",
    "    sheet_name: name of sheet for financial indicator \n",
    "        (columns: title, description, date (in ISO datetime format), title_desc_sent_1)\n",
    "    iso_delimiter: character that separates date from time in 'date' column (ex: 2020-01-06T22:45:21.316Z, 2020-01-06 19:53:02.511000+00:00)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    xls_full = pd.ExcelFile(xls_name)\n",
    "    df1 = pd.read_excel(xls_full, sheet_name, skiprows=1) #assume first row is title, header on row 2\n",
    "    \n",
    "    date_list = []\n",
    "    for index, value in df1[\"date\"].items():\n",
    "        date_list.append(value.split(iso_delimiter)[0]) #only need date from datetime string\n",
    "    \n",
    "    title_list = df1[\"title\"].tolist()\n",
    "    desc_list = df1[\"description\"].tolist()\n",
    "    anno_list = df1[\"title_desc_sent_1\"].tolist()\n",
    "    \n",
    "    assert(len(title_list) == len(date_list))\n",
    "    \n",
    "    split_xls_name = xls_name.split(\"_\")\n",
    "    out_name = sheet_name + \"_\" + \"_\".join(split_xls_name[:2]) + \"_CBC.csv\"\n",
    "    \n",
    "    with open(out_name, 'w') as myfile:\n",
    "        writer = csv.writer(myfile)\n",
    "        writer.writerow([\"title\", \"description\",\"date\", \"title_desc_sent_1\"])\n",
    "        for i in range(len(title_list)):\n",
    "            writer.writerow([title_list[i], desc_list[i], date_list[i], anno_list[i]])\n",
    "    print(\"FILE WRITTEN: \", out_name)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE WRITTEN:  stock_market_combined_annotations_CBC.csv\n"
     ]
    }
   ],
   "source": [
    "#xls_to_csv(\"combined_annotations_sirisha_jon.xlsx\", \"GDP\", \"T\")\n",
    "#xls_to_csv(\"combined_annotations_sirisha_jon.xlsx\", \"employment\", \"T\")\n",
    "#xls_to_csv(\"combined_annotations_sirisha_jon.xlsx\", \"housing_prices\", \" \")\n",
    "#xls_to_csv(\"combined_annotations_sirisha_jon.xlsx\", \"interest_rate\", \" \")\n",
    "#xls_to_csv(\"combined_annotations_sirisha_jon.xlsx\", \"mortgage_rate\", \" \")\n",
    "#xls_to_csv(\"combined_annotations_sirisha_jon.xlsx\", \"stock_market\", \"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> c36f2cb1224ea8413fcc4263cc71ba1926aeb745
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
