{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ajax Api to scrape Bloomberg Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bloomberg_date(date):\n",
    "    'convert the date of articles to month(abbreviated) day, year'\n",
    "    if date == None:\n",
    "        new_date = None\n",
    "    elif not \"ago\" in date: # if the original date format of bloomberg post is XXX hours ago\n",
    "        new_date = date\n",
    "    else:\n",
    "        hrs = re.search(\"\\d+\", date) #regex extracts the time in hours\n",
    "        new_date = (datetime.now() - timedelta(hours=int(hrs.group()))) #calculates the date when the post was created\n",
    "        new_date = datetime.strftime(new_date, '%b %d, %Y')\n",
    "    return new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bnn_article_scraper(query):\n",
    "    '''\n",
    "    Srape the article news from BNN Bloomberg website with a search query\n",
    "    Return a json file containing the returned articles\n",
    "    \n",
    "    input:\n",
    "    query: (str) search keyword\n",
    "    '''\n",
    "    output_list = []\n",
    "    search_query = 'q=' + '&q='.join(query.split())\n",
    "    url_prefix = 'https://www.bnnbloomberg.ca'\n",
    "    url = f'https://www.bnnbloomberg.ca/search/bnn-search-tab-view-7.360399/articles-7.360400?ot=example.AjaxPageLayout.ot&{search_query}&parentPaginationAllowed=false'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    api_soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    for article in api_soup.find_all('div', {'class': 'article-content'}):\n",
    "        title = article.a.text.strip()\n",
    "        #print(\"article_title:\", title)\n",
    "\n",
    "        article_url = url_prefix + article.a.get('href').strip()\n",
    "        #print(\"article_url:\", article_url)\n",
    "\n",
    "\n",
    "\n",
    "        article_response = requests.get(article_url)\n",
    "        article_soup = BeautifulSoup(article_response.text, 'lxml')\n",
    "        \n",
    "        # get date\n",
    "        date_tag = article_soup.find('div', class_ = \"date\")\n",
    "        if date_tag:\n",
    "            date = date_tag.get_text().strip()\n",
    "        else:\n",
    "            date = None\n",
    "        #print('date:', date)\n",
    "\n",
    "        # get author\n",
    "        author_tag = article_soup.find('span', class_ = \"author\")\n",
    "        if author_tag:\n",
    "            author = author_tag.get_text().strip()\n",
    "        else:\n",
    "            author = None \n",
    "        #print('author:', author)\n",
    "\n",
    "        # get source\n",
    "        source_tag = article_soup.find('span', {'class':'source'})\n",
    "        if source_tag:\n",
    "            source = source_tag.get_text().strip()\n",
    "        else:\n",
    "            source = None\n",
    "        #print('source:', source)\n",
    "\n",
    "        # get content\n",
    "        article_text_tag = article_soup.find('div', {'class':'article-text'})\n",
    "        article_text = ''\n",
    "        \n",
    "        if article_text_tag:\n",
    "    \n",
    "            for children in article_text_tag:\n",
    "                #print(children)\n",
    "                if children.name == 'p':\n",
    "                    article_text += ' '+ children.text\n",
    "            #article_text = article_text_tag.text\n",
    "            # desc = article_text_tag.p.get_text()\n",
    "            desc = article_text_tag.text.strip().split(\"\\n\")[0]\n",
    "        else:\n",
    "            article_text_tag = article_soup.find('div', {'class':'article-text-chart'})\n",
    "            if article_text_tag:\n",
    "                for children in article_text_tag:\n",
    "                    if children.name == 'p':\n",
    "                        article_text += ' '+ children.text\n",
    "                # article_text = article_text_tag.get_text(' ')\n",
    "                # desc = article_text_tag.p.get_text()\n",
    "                desc = article_text_tag.text.strip().split(\"\\n\")[0] # Amy spotted this bug\n",
    "            else:\n",
    "                article_text = None\n",
    "                desc = None\n",
    "        #print('content:', article_text)\n",
    "\n",
    "        # get image url\n",
    "        article_image_tag = article_soup.find('p', {'class':'image-center'})\n",
    "        if article_image_tag:\n",
    "            image_url = url_prefix + article_image_tag.img['src']\n",
    "        else:\n",
    "            image_url = None\n",
    "        #print('image_url:', image_url)\n",
    "        #print('\\n')\n",
    "        \n",
    "        article_dict = {}\n",
    "        \n",
    "        article_dict['source'] = source\n",
    "        article_dict['author'] = author\n",
    "        article_dict['title'] = title\n",
    "        article_dict['description'] = desc\n",
    "        article_dict['url'] = article_url\n",
    "        article_dict['urlToImage'] = image_url\n",
    "        article_dict['publishedAt'] = clean_bloomberg_date(date)\n",
    "        article_dict['content'] = article_text\n",
    "        \n",
    "        output_list.append(article_dict)\n",
    "        \n",
    "    with open('_'.join(query.split()) + '_' + str(len(output_list)) + '_' +'Bloomberg_article' + '.json', 'w') as json_file:\n",
    "        json.dump(output_list, json_file)\n",
    "        \n",
    "    return output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_response = requests.get('https://www.bnnbloomberg.ca/multi-unit-housing-starts-up-in-parts-of-canada-despite-covid-19-1.1433503')\n",
    "# article_soup = BeautifulSoup(article_response.text, 'lxml')\n",
    "\n",
    "# article_text_tag = article_soup.find('div', {'class':'article-text'})\n",
    "# article_text = ''\n",
    "# if article_text_tag:\n",
    "    \n",
    "#     for children in article_text_tag:\n",
    "#         #print(children)\n",
    "#         if children.name == 'p':\n",
    "#             article_text += ' '+ children.text\n",
    "#     #article_text = article_text_tag.text\n",
    "#     # desc = article_text_tag.p.get_text()\n",
    "#     desc = article_text_tag.text.strip().split(\"\\n\")[0]\n",
    "# else:\n",
    "#     article_text_tag = article_soup.find('div', {'class':'article-text-chart'})\n",
    "#     if article_text_tag:\n",
    "#         for children in article_text_tag:\n",
    "#         #print(children)\n",
    "#             if children.name == 'p':\n",
    "#                 article_text += ' '+ children.text\n",
    "\n",
    "#             #desc = article_text_tag.p.get_text()\n",
    "#             desc = article_text_tag.text.strip().split(\"\\n\")[0] # Amy spotted this bug\n",
    "#     else:\n",
    "#         article_text = None\n",
    "#         desc = None\n",
    "# print('content:', article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mortgage Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloomberg_mr_article = bnn_article_scraper('mortgage rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'The Canadian Press',\n",
       " 'author': None,\n",
       " 'title': 'Multi-unit housing starts up in parts of Canada despite COVID-19',\n",
       " 'description': 'OTTAWA -- Canada Mortgage and Housing Corp. says construction of multi-unit housing projects remained strong in some provinces last month despite the fight against the COVID-19 pandemic.',\n",
       " 'url': 'https://www.bnnbloomberg.ca/multi-unit-housing-starts-up-in-parts-of-canada-despite-covid-19-1.1433503',\n",
       " 'urlToImage': None,\n",
       " 'publishedAt': 'May 8, 2020',\n",
       " 'content': \" OTTAWA -- Canada Mortgage and Housing Corp. says construction of multi-unit housing projects remained strong in some provinces last month despite the fight against the COVID-19 pandemic. CMHC estimates a 10.8 per cent month-over-month increase in its national seasonally adjusted annual rate last month compared with March, excluding Quebec. The federal agency says there was growth in multi-family starts in Ontario, Saskatchewan and Manitoba in April but Quebec was left out of the monthly national tally because the province's COVID-19 containment measures were in place until April 20. The April seasonally adjusted annualized rate, excluding Quebec, was 166,415 units, up from 150,224 units in March. Excluding Quebec, multiple dwelling starts in urban areas of Canada were up 35.7 per cent from March, while urban single-family starts fell 27.1 per cent. Rural starts were estimated at 7,285 units. Ontario accounted for the largest number of starts at 93,628, up 42 per cent. British Columbia had the second-largest seasonally adjusted rate, at 27,767, down 10 per cent from March. Alberta's starts were down 28 per cent from March, at a seasonally adjusted rate of 23,262 units.\"}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloomberg_mr_article[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloomberg_ir_article = bnn_article_scraper('interest rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bloomberg_ir_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloomberg_hp_article = bnn_article_scraper('housing price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bloomberg_hp_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloomberg_e_article = bnn_article_scraper('employment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bloomberg_e_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloomberg_gdp_article = bnn_article_scraper('GDP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bloomberg_gdp_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloomberg_tsx_article = bnn_article_scraper('stock market')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bloomberg_tsx_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(url)\n",
    "# api_soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# output_list = []\n",
    "# query = 'mortgage rates'\n",
    "# search_query = 'q=' + '&q='.join(query.split())\n",
    "# url_prefix = 'https://www.bnnbloomberg.ca'\n",
    "# url = f'https://www.bnnbloomberg.ca/search/bnn-search-tab-view-7.360399/articles-7.360400?ot=example.AjaxPageLayout.ot&{search_query}&parentPaginationAllowed=false'\n",
    "\n",
    "# response = requests.get(url)\n",
    "# api_soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "# for article in api_soup.find_all('div', {'class': 'article-content'}):\n",
    "#     title = article.a.text.strip()\n",
    "#     print(\"article_title:\", title)\n",
    "\n",
    "#     article_url = url_prefix + article.a.get('href').strip()\n",
    "#     print(\"article_url:\", article_url)\n",
    "\n",
    "\n",
    "\n",
    "#     article_response = requests.get(article_url)\n",
    "#     article_soup = BeautifulSoup(article_response.text, 'lxml')\n",
    "#     # get date\n",
    "#     date_tag = article_soup.find('div', class_ = \"date\")\n",
    "#     if date_tag:\n",
    "#         date = date_tag.get_text().strip()\n",
    "#     else:\n",
    "#         date = None\n",
    "#     print('date:', date)\n",
    "\n",
    "#     # get author\n",
    "#     author_tag = article_soup.find('span', class_ = \"author\")\n",
    "#     if author_tag:\n",
    "#         author = author_tag.get_text().strip()\n",
    "#     else:\n",
    "#         author = None \n",
    "#     print('author:', author)\n",
    "\n",
    "#     # get source\n",
    "#     source_tag = article_soup.find('span', {'class':'source'})\n",
    "#     if source_tag:\n",
    "#         source = source_tag.get_text().strip()\n",
    "#     else:\n",
    "#         source = None\n",
    "#     print('source:', source)\n",
    "\n",
    "#     # get content\n",
    "#     article_text_tag = article_soup.find('div', {'class':'article-text'})\n",
    "#     if article_text_tag:\n",
    "#         article_text = article_text_tag.get_text(' ')\n",
    "#         desc = article_text_tag.p.get_text()\n",
    "#     else:\n",
    "#         article_text_tag = article_soup.find('div', {'class':'article-text-chart'})\n",
    "#         if article_text_tag:\n",
    "#             article_text = article_text_tag.get_text(' ')\n",
    "#             desc = article_text_tag.p.get_text()\n",
    "#         else:\n",
    "#             article_text = None\n",
    "#             desc = None\n",
    "#     print('content:', article_text)\n",
    "#     print('desc:', desc)\n",
    "\n",
    "#     # get image url\n",
    "#     article_image_tag = article_soup.find('p', {'class':'image-center'})\n",
    "#     if article_image_tag:\n",
    "#         image_url = url_prefix + article_image_tag.img['src']\n",
    "#     else:\n",
    "#         image_url = None\n",
    "#     print('image_url:', image_url)\n",
    "#     print('\\n')\n",
    "\n",
    "#     article_dict = {}\n",
    "\n",
    "#     article_dict['source'] = source\n",
    "#     article_dict['author'] = author\n",
    "#     article_dict['title'] = title\n",
    "#     article_dict['description'] = None\n",
    "#     article_dict['url'] = article_url\n",
    "#     article_dict['urlToImage'] = image_url\n",
    "#     article_dict['PublishedAt'] = datetime.strptime(date, '%b %d, %Y').date()\n",
    "#     article_dict['content'] = article_text\n",
    "\n",
    "#     output_list.append(article_dict)\n",
    "    \n",
    "#     break\n",
    "\n",
    "# # with open('_'.join(query.split()) + '_' + str(len(output_list)) + '_' +'Bloomberg_article' + '.json', 'w') as json_file:\n",
    "# #     json.dump(output_list, json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first = api_soup.find('div', {'class': 'article-content'})\n",
    "# title = first.a.text.strip()\n",
    "# print('title:', title)\n",
    "# url = url_prefix + first.a.get('href')\n",
    "# #print('url:', url)\n",
    "\n",
    "# article_response = requests.get(url)\n",
    "# article_soup = BeautifulSoup(article_response.text, 'lxml')\n",
    "# date = article_soup.find('div', class_ = \"date\").get_text().strip()\n",
    "# print('date:', date)\n",
    "\n",
    "# author = article_soup.find('span', class_ = \"author\").get_text().strip()\n",
    "# print('author:', author)\n",
    "\n",
    "# source = article_soup.find('span', {'class':'source'}).get_text().strip()\n",
    "# print('source:', source)\n",
    "\n",
    "# article_text = article_soup.find('div', {'class':'article-text'}).get_text(' ')\n",
    "# print('content:', article_text)\n",
    "\n",
    "# article_image = article_soup.find('div', {'class':'article-image'})\n",
    "# # image_url = url_prefix + article_image['src']\n",
    "# print(article_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
