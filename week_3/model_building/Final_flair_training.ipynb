{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Two_stage_flair_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "39274c9449ea4aca8f8bfeba530c8364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_128470d5db964aaa8fc9455600e62dd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9bd4c4f06074c119854d840e125a87d",
              "IPY_MODEL_b849e5fac74d431eba60de1b55385da5"
            ]
          }
        },
        "128470d5db964aaa8fc9455600e62dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9bd4c4f06074c119854d840e125a87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac4db8b6338f4b67885c3bf514c46023",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_538a8ac582d04094a71204e2989abf92"
          }
        },
        "b849e5fac74d431eba60de1b55385da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3fa760aeda914fe2abb5a073e7f4a932",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 830kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c551ace341c45f1926c0962c6fcf5c6"
          }
        },
        "ac4db8b6338f4b67885c3bf514c46023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "538a8ac582d04094a71204e2989abf92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fa760aeda914fe2abb5a073e7f4a932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c551ace341c45f1926c0962c6fcf5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb056f13a8fd47dd81bedff7662781c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9bbb2e74e23d45eaad4bca0ef916af88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be75d745928b4eb2abfa98ca561d7576",
              "IPY_MODEL_6eb12223b60445c9b36fc4c671643020"
            ]
          }
        },
        "9bbb2e74e23d45eaad4bca0ef916af88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be75d745928b4eb2abfa98ca561d7576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a76bcda48d694bfbb8e0a1557b1ed9a9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e55f1739c4ea49eaa8a94fdb87ba85a6"
          }
        },
        "6eb12223b60445c9b36fc4c671643020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f83c2ecdebc45fa91fe886c0a2fe1fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:11&lt;00:00, 37.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34cba46fe9fc4a6faa5234ad5bb9e688"
          }
        },
        "a76bcda48d694bfbb8e0a1557b1ed9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e55f1739c4ea49eaa8a94fdb87ba85a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f83c2ecdebc45fa91fe886c0a2fe1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34cba46fe9fc4a6faa5234ad5bb9e688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3e29d2f54d7488e985a47192de809ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c4eabe83ae44c659cf4fc5f008fdd8f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_443f22702d214ea0bd55f9491f9f6056",
              "IPY_MODEL_057d06d532564dea9152bb7b3f8b79d2"
            ]
          }
        },
        "9c4eabe83ae44c659cf4fc5f008fdd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "443f22702d214ea0bd55f9491f9f6056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1654565da2c42e2bc156cd8fe6289d1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13a90443320b413faa1e9fcf3f36286b"
          }
        },
        "057d06d532564dea9152bb7b3f8b79d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32c4afa98cbd4758b4b5250cc5d8ed9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:11&lt;00:00, 39.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89ab14378dfc4574bfaaf99dcc4ea824"
          }
        },
        "a1654565da2c42e2bc156cd8fe6289d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13a90443320b413faa1e9fcf3f36286b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32c4afa98cbd4758b4b5250cc5d8ed9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89ab14378dfc4574bfaaf99dcc4ea824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybjXa4UJ3g7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVY0ZiGk38i_",
        "colab_type": "code",
        "outputId": "2ecfb730-5fec-4d70-d237-98070efe9f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-stlm912b\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-stlm912b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2.8.1)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.22.2.post1)\n",
            "Collecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/f9/9f2b6c672c8f8bb87a4c1bd52c1b57213627b035305aad745d015b2a62ae/pytest-5.4.2-py3-none-any.whl (247kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.8.7)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 14.0MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Collecting transformers>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.5.0+cu101)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 16.6MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair==0.4.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.4.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.4.5) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.4.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.6.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (8.3.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.5) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair==0.4.5) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.7)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.4.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.13.13)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.6.0->flair==0.4.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.16.13)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.4.5-cp36-none-any.whl size=148505 sha256=6c948c0e64a7dd3183fb4a438906803bec39800a9a0d13c51e86ae2e749e9dbf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-56ucurov/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Building wheels for collected packages: sqlitedict, langdetect, mpld3, segtok, sacremoses\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=f52137bc19cb0013d50833a990c79c44fececc55fdd23ad15505df4176c10a91\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=4e74d416433e998969cf3176371c65674b528e2c1622a7db36a183361153a2df\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=212270f3e7c8a598b2b991513d1ca106e0a7605891fcf4b9d6603bebc8f5bdea\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=786265a402fe64c24dc63cb7799f2314772ce7398ae6ab25b94c10af36312280\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=c92423e12abefead05c91c3954ae987e55ee3f52a8c90837c25bb13552ee27aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sqlitedict langdetect mpld3 segtok sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sqlitedict, pluggy, pytest, deprecated, langdetect, sentencepiece, bpemb, sacremoses, tokenizers, transformers, mpld3, segtok, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.4.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.2 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP7gl75D39dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "from flair.data import Corpus\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBdZ1L34XwO",
        "colab_type": "code",
        "outputId": "6588f990-bb36-41d5-e6f8-fdeb3484dbad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm4Y_PUUwePN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U90p69Xd5KIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_folder = \"/content/drive/My Drive/Capstone/new_data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkUisuXz7tuK",
        "colab_type": "text"
      },
      "source": [
        "### First Stage (Train on benchmark dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-_Bmpa6gn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = pd.read_csv(data_folder + \"combined_benchmark.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVaSsyAn72AU",
        "colab_type": "code",
        "outputId": "ad9cab31-16a8-42ca-c9b1-5e404940011a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "benchmark = benchmark[['label', 'text']]\n",
        "benchmark.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Why not subscribe to the magazine ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>Tornio Works employs 2,300 of whom more than 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>The move is aimed at boosting sales , cost-eff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>As a result of the merger , the largest profes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>18 March 2010 A leakage in the gypsum pond was...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0                Why not subscribe to the magazine ?\n",
              "1     -1  Tornio Works employs 2,300 of whom more than 1...\n",
              "2      1  The move is aimed at boosting sales , cost-eff...\n",
              "3      0  As a result of the merger , the largest profes...\n",
              "4     -1  18 March 2010 A leakage in the gypsum pond was..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_MVMXq8pvf",
        "colab_type": "text"
      },
      "source": [
        "#### Create train, dev and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUbbfcSC8ekr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# benchmark = benchmark.sample(frac=1)\n",
        "# benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', sep='\\t', index = False, header = False)\n",
        "# benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', sep='\\t', index = False, header = False)\n",
        "# benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', sep='\\t', index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFvvbnacsxJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WMydYBXszIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle_X_train, kaggle_X_te, kaggle_Y_train, kaggle_Y_te = train_test_split(benchmark['text'],benchmark['label'], test_size = 0.2, random_state = 0, stratify = benchmark['label'])\n",
        "kaggle_X_dev, kaggle_X_test, kaggle_Y_dev, kaggle_Y_test = train_test_split(kaggle_X_te,kaggle_Y_te, test_size = 0.5, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXPW_syOwjgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhMvAKu3s2My",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark_train_df =  pd.DataFrame({ 'label': kaggle_Y_train, 'text': kaggle_X_train   })\n",
        "benchmark_dev_df = pd.DataFrame({ 'label': kaggle_Y_dev , 'text': kaggle_X_dev  })\n",
        "benchmark_test_df = pd.DataFrame({ 'label': kaggle_Y_test, 'text': kaggle_X_test   })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mabSa5mrs4Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark_train_df.to_csv( data_folder + \"train.csv\",  sep='\\t', index = False, header = False)\n",
        "benchmark_dev_df.to_csv( data_folder + \"dev.csv\",sep='\\t', index = False, header = False)\n",
        "benchmark_test_df.to_csv( data_folder + \"test.csv\", sep='\\t',index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D-hQy9HvIzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7QE3IS69txr",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz-2gNy58wDI",
        "colab_type": "code",
        "outputId": "e7221973-699f-452c-ee41-f8069a1cc24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_folder), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
        "column_name_map = {1: \"text\", 0: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                         column_name_map,\n",
        "                                         skip_header=False, #no header in kaggle data\n",
        "                                         delimiter='\\t',    # comma separated rows\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 00:41:15,766 Reading data from /content/drive/My Drive/Capstone/new_data\n",
            "2020-05-22 00:41:15,767 Train: /content/drive/My Drive/Capstone/new_data/train.csv\n",
            "2020-05-22 00:41:15,768 Dev: /content/drive/My Drive/Capstone/new_data/dev.csv\n",
            "2020-05-22 00:41:15,769 Test: /content/drive/My Drive/Capstone/new_data/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb1lynSQ98-z",
        "colab_type": "text"
      },
      "source": [
        "#### Create word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u9PFUze9_5y",
        "colab_type": "code",
        "outputId": "aa25993a-93db-4186-cc59-0c2ba003361b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "39274c9449ea4aca8f8bfeba530c8364",
            "128470d5db964aaa8fc9455600e62dd6",
            "e9bd4c4f06074c119854d840e125a87d",
            "b849e5fac74d431eba60de1b55385da5",
            "ac4db8b6338f4b67885c3bf514c46023",
            "538a8ac582d04094a71204e2989abf92",
            "3fa760aeda914fe2abb5a073e7f4a932",
            "5c551ace341c45f1926c0962c6fcf5c6",
            "cb056f13a8fd47dd81bedff7662781c1",
            "9bbb2e74e23d45eaad4bca0ef916af88",
            "be75d745928b4eb2abfa98ca561d7576",
            "6eb12223b60445c9b36fc4c671643020",
            "a76bcda48d694bfbb8e0a1557b1ed9a9",
            "e55f1739c4ea49eaa8a94fdb87ba85a6",
            "3f83c2ecdebc45fa91fe886c0a2fe1fa",
            "34cba46fe9fc4a6faa5234ad5bb9e688",
            "b3e29d2f54d7488e985a47192de809ec",
            "9c4eabe83ae44c659cf4fc5f008fdd8f",
            "443f22702d214ea0bd55f9491f9f6056",
            "057d06d532564dea9152bb7b3f8b79d2",
            "a1654565da2c42e2bc156cd8fe6289d1",
            "13a90443320b413faa1e9fcf3f36286b",
            "32c4afa98cbd4758b4b5250cc5d8ed9c",
            "89ab14378dfc4574bfaaf99dcc4ea824"
          ]
        }
      },
      "source": [
        "word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39274c9449ea4aca8f8bfeba530c8364",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb056f13a8fd47dd81bedff7662781c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3e29d2f54d7488e985a47192de809ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2020-05-22 00:41:53,809 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpcfliebv5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:02<00:00, 9825041.73B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 00:41:56,565 copying /tmp/tmpcfliebv5 to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2020-05-22 00:41:56,586 removing temp file /tmp/tmpcfliebv5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 00:42:13,684 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpm9k20d0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:02<00:00, 9182361.40B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 00:42:16,524 copying /tmp/tmpm9k20d0s to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2020-05-22 00:42:16,543 removing temp file /tmp/tmpm9k20d0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HovCqFfSMjmJ",
        "colab_type": "text"
      },
      "source": [
        "#### First Stage Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wik8DDxm-DKy",
        "colab_type": "code",
        "outputId": "007cb3dc-1b8b-4e94-9efb-e2051253dd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train(data_folder, max_epochs=10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 00:42:29,759 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "100%|██████████| 1315/1315 [00:01<00:00, 1014.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 00:42:31,312 [b'1', b'0', b'-1']\n",
            "2020-05-22 00:42:31,325 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:42:31,329 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-22 00:42:31,334 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:42:31,336 Corpus: \"Corpus: 1168 train + 146 dev + 147 test sentences\"\n",
            "2020-05-22 00:42:31,338 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:42:31,339 Parameters:\n",
            "2020-05-22 00:42:31,341  - learning_rate: \"0.1\"\n",
            "2020-05-22 00:42:31,342  - mini_batch_size: \"32\"\n",
            "2020-05-22 00:42:31,343  - patience: \"3\"\n",
            "2020-05-22 00:42:31,344  - anneal_factor: \"0.5\"\n",
            "2020-05-22 00:42:31,345  - max_epochs: \"10\"\n",
            "2020-05-22 00:42:31,346  - shuffle: \"True\"\n",
            "2020-05-22 00:42:31,347  - train_with_dev: \"False\"\n",
            "2020-05-22 00:42:31,348  - batch_growth_annealing: \"False\"\n",
            "2020-05-22 00:42:31,349 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:42:31,350 Model training base path: \"/content/drive/My Drive/Capstone/new_data\"\n",
            "2020-05-22 00:42:31,352 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:42:31,353 Device: cuda:0\n",
            "2020-05-22 00:42:31,354 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:42:31,355 Embeddings storage mode: cpu\n",
            "2020-05-22 00:42:31,367 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 00:42:33,340 epoch 1 - iter 3/37 - loss 1.41591505 - samples/sec: 56.25\n",
            "2020-05-22 00:42:45,293 epoch 1 - iter 6/37 - loss 1.45490547 - samples/sec: 67.57\n",
            "2020-05-22 00:42:57,051 epoch 1 - iter 9/37 - loss 1.31488357 - samples/sec: 68.15\n",
            "2020-05-22 00:43:08,577 epoch 1 - iter 12/37 - loss 1.28688369 - samples/sec: 80.23\n",
            "2020-05-22 00:43:20,193 epoch 1 - iter 15/37 - loss 1.23950537 - samples/sec: 82.39\n",
            "2020-05-22 00:43:31,961 epoch 1 - iter 18/37 - loss 1.27530628 - samples/sec: 70.68\n",
            "2020-05-22 00:43:43,390 epoch 1 - iter 21/37 - loss 1.28792808 - samples/sec: 73.44\n",
            "2020-05-22 00:43:55,197 epoch 1 - iter 24/37 - loss 1.26882177 - samples/sec: 75.74\n",
            "2020-05-22 00:44:06,782 epoch 1 - iter 27/37 - loss 1.25488860 - samples/sec: 82.36\n",
            "2020-05-22 00:44:18,182 epoch 1 - iter 30/37 - loss 1.23522135 - samples/sec: 75.24\n",
            "2020-05-22 00:44:29,490 epoch 1 - iter 33/37 - loss 1.22724476 - samples/sec: 87.06\n",
            "2020-05-22 00:44:40,844 epoch 1 - iter 36/37 - loss 1.21286295 - samples/sec: 83.94\n",
            "2020-05-22 00:44:51,579 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:44:51,580 EPOCH 1 done: loss 1.2049 - lr 0.1000000\n",
            "2020-05-22 00:44:53,964 DEV : loss 0.8998611569404602 - score 0.7397\n",
            "2020-05-22 00:44:54,091 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-22 00:44:55,791 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:44:57,493 epoch 2 - iter 3/37 - loss 1.20730607 - samples/sec: 68.40\n",
            "2020-05-22 00:45:09,344 epoch 2 - iter 6/37 - loss 1.07251569 - samples/sec: 72.55\n",
            "2020-05-22 00:45:21,370 epoch 2 - iter 9/37 - loss 0.97260718 - samples/sec: 63.84\n",
            "2020-05-22 00:45:33,061 epoch 2 - iter 12/37 - loss 0.94812411 - samples/sec: 77.77\n",
            "2020-05-22 00:45:43,902 epoch 2 - iter 15/37 - loss 0.97158413 - samples/sec: 78.67\n",
            "2020-05-22 00:45:55,189 epoch 2 - iter 18/37 - loss 0.94860942 - samples/sec: 83.81\n",
            "2020-05-22 00:46:06,828 epoch 2 - iter 21/37 - loss 0.93628871 - samples/sec: 82.53\n",
            "2020-05-22 00:46:17,972 epoch 2 - iter 24/37 - loss 0.92900413 - samples/sec: 86.34\n",
            "2020-05-22 00:46:29,563 epoch 2 - iter 27/37 - loss 0.97095631 - samples/sec: 80.96\n",
            "2020-05-22 00:46:40,672 epoch 2 - iter 30/37 - loss 0.96807605 - samples/sec: 79.85\n",
            "2020-05-22 00:46:52,142 epoch 2 - iter 33/37 - loss 0.96696916 - samples/sec: 83.55\n",
            "2020-05-22 00:47:04,467 epoch 2 - iter 36/37 - loss 0.96560179 - samples/sec: 74.42\n",
            "2020-05-22 00:47:14,640 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:47:14,644 EPOCH 2 done: loss 0.9637 - lr 0.1000000\n",
            "2020-05-22 00:47:16,761 DEV : loss 0.9690008163452148 - score 0.6986\n",
            "2020-05-22 00:47:16,900 BAD EPOCHS (no improvement): 1\n",
            "2020-05-22 00:47:16,905 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:47:18,478 epoch 3 - iter 3/37 - loss 0.84053596 - samples/sec: 73.56\n",
            "2020-05-22 00:47:30,555 epoch 3 - iter 6/37 - loss 0.97097852 - samples/sec: 74.40\n",
            "2020-05-22 00:47:41,784 epoch 3 - iter 9/37 - loss 0.92482010 - samples/sec: 79.45\n",
            "2020-05-22 00:47:54,064 epoch 3 - iter 12/37 - loss 0.91661553 - samples/sec: 78.17\n",
            "2020-05-22 00:48:05,918 epoch 3 - iter 15/37 - loss 0.88392003 - samples/sec: 77.89\n",
            "2020-05-22 00:48:17,631 epoch 3 - iter 18/37 - loss 0.86608591 - samples/sec: 79.20\n",
            "2020-05-22 00:48:29,248 epoch 3 - iter 21/37 - loss 0.86521186 - samples/sec: 79.59\n",
            "2020-05-22 00:48:40,591 epoch 3 - iter 24/37 - loss 0.85861980 - samples/sec: 80.04\n",
            "2020-05-22 00:48:52,242 epoch 3 - iter 27/37 - loss 0.86205239 - samples/sec: 79.72\n",
            "2020-05-22 00:49:03,824 epoch 3 - iter 30/37 - loss 0.85804576 - samples/sec: 76.65\n",
            "2020-05-22 00:49:15,475 epoch 3 - iter 33/37 - loss 0.83975809 - samples/sec: 71.62\n",
            "2020-05-22 00:49:26,950 epoch 3 - iter 36/37 - loss 0.85323644 - samples/sec: 82.44\n",
            "2020-05-22 00:49:37,689 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:49:37,690 EPOCH 3 done: loss 0.8570 - lr 0.1000000\n",
            "2020-05-22 00:49:39,850 DEV : loss 1.2271349430084229 - score 0.5799\n",
            "2020-05-22 00:49:39,979 BAD EPOCHS (no improvement): 2\n",
            "2020-05-22 00:49:39,984 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:49:41,647 epoch 4 - iter 3/37 - loss 0.94055422 - samples/sec: 67.22\n",
            "2020-05-22 00:49:53,206 epoch 4 - iter 6/37 - loss 0.93130690 - samples/sec: 75.10\n",
            "2020-05-22 00:50:04,910 epoch 4 - iter 9/37 - loss 0.92028144 - samples/sec: 81.97\n",
            "2020-05-22 00:50:16,216 epoch 4 - iter 12/37 - loss 0.87532102 - samples/sec: 83.86\n",
            "2020-05-22 00:50:27,840 epoch 4 - iter 15/37 - loss 0.85151905 - samples/sec: 73.07\n",
            "2020-05-22 00:50:39,135 epoch 4 - iter 18/37 - loss 0.83240354 - samples/sec: 75.98\n",
            "2020-05-22 00:50:50,622 epoch 4 - iter 21/37 - loss 0.80714606 - samples/sec: 75.75\n",
            "2020-05-22 00:51:02,164 epoch 4 - iter 24/37 - loss 0.79409362 - samples/sec: 79.78\n",
            "2020-05-22 00:51:13,552 epoch 4 - iter 27/37 - loss 0.77648768 - samples/sec: 81.67\n",
            "2020-05-22 00:51:25,252 epoch 4 - iter 30/37 - loss 0.78448324 - samples/sec: 69.22\n",
            "2020-05-22 00:51:36,471 epoch 4 - iter 33/37 - loss 0.79356803 - samples/sec: 87.42\n",
            "2020-05-22 00:51:47,882 epoch 4 - iter 36/37 - loss 0.78659094 - samples/sec: 83.15\n",
            "2020-05-22 00:51:59,081 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:51:59,083 EPOCH 4 done: loss 0.7830 - lr 0.1000000\n",
            "2020-05-22 00:52:01,592 DEV : loss 1.2768433094024658 - score 0.5753\n",
            "2020-05-22 00:52:01,756 BAD EPOCHS (no improvement): 3\n",
            "2020-05-22 00:52:01,762 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:52:03,655 epoch 5 - iter 3/37 - loss 0.84066087 - samples/sec: 60.36\n",
            "2020-05-22 00:52:15,701 epoch 5 - iter 6/37 - loss 0.82399378 - samples/sec: 78.69\n",
            "2020-05-22 00:52:27,551 epoch 5 - iter 9/37 - loss 0.76723164 - samples/sec: 80.42\n",
            "2020-05-22 00:52:39,280 epoch 5 - iter 12/37 - loss 0.77037014 - samples/sec: 73.49\n",
            "2020-05-22 00:52:50,971 epoch 5 - iter 15/37 - loss 0.76692803 - samples/sec: 75.27\n",
            "2020-05-22 00:53:02,870 epoch 5 - iter 18/37 - loss 0.73557398 - samples/sec: 80.68\n",
            "2020-05-22 00:53:14,395 epoch 5 - iter 21/37 - loss 0.74447789 - samples/sec: 77.68\n",
            "2020-05-22 00:53:26,188 epoch 5 - iter 24/37 - loss 0.74719223 - samples/sec: 77.34\n",
            "2020-05-22 00:53:37,884 epoch 5 - iter 27/37 - loss 0.74860534 - samples/sec: 82.42\n",
            "2020-05-22 00:53:49,123 epoch 5 - iter 30/37 - loss 0.74724279 - samples/sec: 84.69\n",
            "2020-05-22 00:54:00,430 epoch 5 - iter 33/37 - loss 0.76488152 - samples/sec: 80.81\n",
            "2020-05-22 00:54:11,850 epoch 5 - iter 36/37 - loss 0.77095065 - samples/sec: 72.79\n",
            "2020-05-22 00:54:22,584 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:54:22,585 EPOCH 5 done: loss 0.7690 - lr 0.1000000\n",
            "2020-05-22 00:54:24,748 DEV : loss 0.7436613440513611 - score 0.7397\n",
            "2020-05-22 00:54:24,885 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-22 00:54:26,766 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:54:28,572 epoch 6 - iter 3/37 - loss 0.67008372 - samples/sec: 65.05\n",
            "2020-05-22 00:54:40,517 epoch 6 - iter 6/37 - loss 0.61851603 - samples/sec: 58.92\n",
            "2020-05-22 00:54:52,241 epoch 6 - iter 9/37 - loss 0.65401488 - samples/sec: 74.48\n",
            "2020-05-22 00:55:03,897 epoch 6 - iter 12/37 - loss 0.70030040 - samples/sec: 77.15\n",
            "2020-05-22 00:55:15,439 epoch 6 - iter 15/37 - loss 0.67807879 - samples/sec: 79.52\n",
            "2020-05-22 00:55:26,992 epoch 6 - iter 18/37 - loss 0.66999438 - samples/sec: 77.56\n",
            "2020-05-22 00:55:38,594 epoch 6 - iter 21/37 - loss 0.68981812 - samples/sec: 69.84\n",
            "2020-05-22 00:55:49,952 epoch 6 - iter 24/37 - loss 0.70255164 - samples/sec: 78.92\n",
            "2020-05-22 00:56:01,318 epoch 6 - iter 27/37 - loss 0.69599121 - samples/sec: 79.37\n",
            "2020-05-22 00:56:12,627 epoch 6 - iter 30/37 - loss 0.69780677 - samples/sec: 79.80\n",
            "2020-05-22 00:56:24,164 epoch 6 - iter 33/37 - loss 0.72548686 - samples/sec: 79.09\n",
            "2020-05-22 00:56:35,591 epoch 6 - iter 36/37 - loss 0.73963432 - samples/sec: 93.32\n",
            "2020-05-22 00:56:46,397 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:56:46,398 EPOCH 6 done: loss 0.7448 - lr 0.1000000\n",
            "2020-05-22 00:56:48,586 DEV : loss 0.6968156695365906 - score 0.7534\n",
            "2020-05-22 00:56:48,718 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-22 00:56:50,444 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:56:52,457 epoch 7 - iter 3/37 - loss 0.70563819 - samples/sec: 64.65\n",
            "2020-05-22 00:57:04,993 epoch 7 - iter 6/37 - loss 0.63265085 - samples/sec: 68.05\n",
            "2020-05-22 00:57:18,623 epoch 7 - iter 9/37 - loss 0.58033367 - samples/sec: 76.36\n",
            "2020-05-22 00:57:30,278 epoch 7 - iter 12/37 - loss 0.59176361 - samples/sec: 84.52\n",
            "2020-05-22 00:57:41,845 epoch 7 - iter 15/37 - loss 0.60735153 - samples/sec: 71.74\n",
            "2020-05-22 00:57:53,574 epoch 7 - iter 18/37 - loss 0.67985438 - samples/sec: 74.39\n",
            "2020-05-22 00:58:06,267 epoch 7 - iter 21/37 - loss 0.68615040 - samples/sec: 75.09\n",
            "2020-05-22 00:58:17,635 epoch 7 - iter 24/37 - loss 0.67946891 - samples/sec: 82.90\n",
            "2020-05-22 00:58:29,327 epoch 7 - iter 27/37 - loss 0.66154365 - samples/sec: 75.90\n",
            "2020-05-22 00:58:40,983 epoch 7 - iter 30/37 - loss 0.67736530 - samples/sec: 79.53\n",
            "2020-05-22 00:58:52,595 epoch 7 - iter 33/37 - loss 0.67473032 - samples/sec: 86.94\n",
            "2020-05-22 00:59:04,036 epoch 7 - iter 36/37 - loss 0.67710134 - samples/sec: 78.88\n",
            "2020-05-22 00:59:14,753 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:59:14,754 EPOCH 7 done: loss 0.6765 - lr 0.1000000\n",
            "2020-05-22 00:59:16,915 DEV : loss 0.9381842017173767 - score 0.7306\n",
            "2020-05-22 00:59:17,253 BAD EPOCHS (no improvement): 1\n",
            "2020-05-22 00:59:17,257 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 00:59:19,002 epoch 8 - iter 3/37 - loss 0.75932650 - samples/sec: 66.12\n",
            "2020-05-22 00:59:30,190 epoch 8 - iter 6/37 - loss 0.68573088 - samples/sec: 82.14\n",
            "2020-05-22 00:59:41,929 epoch 8 - iter 9/37 - loss 0.62507136 - samples/sec: 78.82\n",
            "2020-05-22 00:59:53,496 epoch 8 - iter 12/37 - loss 0.64899908 - samples/sec: 85.47\n",
            "2020-05-22 01:00:05,268 epoch 8 - iter 15/37 - loss 0.67046439 - samples/sec: 79.59\n",
            "2020-05-22 01:00:16,633 epoch 8 - iter 18/37 - loss 0.72262917 - samples/sec: 77.57\n",
            "2020-05-22 01:00:28,167 epoch 8 - iter 21/37 - loss 0.69039665 - samples/sec: 80.05\n",
            "2020-05-22 01:00:39,595 epoch 8 - iter 24/37 - loss 0.71518594 - samples/sec: 72.41\n",
            "2020-05-22 01:00:51,059 epoch 8 - iter 27/37 - loss 0.71911895 - samples/sec: 77.34\n",
            "2020-05-22 01:01:02,397 epoch 8 - iter 30/37 - loss 0.70081836 - samples/sec: 84.55\n",
            "2020-05-22 01:01:14,246 epoch 8 - iter 33/37 - loss 0.69858052 - samples/sec: 79.05\n",
            "2020-05-22 01:01:25,850 epoch 8 - iter 36/37 - loss 0.70272230 - samples/sec: 83.78\n",
            "2020-05-22 01:01:36,324 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 01:01:36,326 EPOCH 8 done: loss 0.6989 - lr 0.1000000\n",
            "2020-05-22 01:01:38,797 DEV : loss 0.8523504137992859 - score 0.7534\n",
            "2020-05-22 01:01:38,930 BAD EPOCHS (no improvement): 2\n",
            "2020-05-22 01:01:38,933 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 01:01:40,573 epoch 9 - iter 3/37 - loss 0.44089292 - samples/sec: 71.10\n",
            "2020-05-22 01:01:52,014 epoch 9 - iter 6/37 - loss 0.65176911 - samples/sec: 80.36\n",
            "2020-05-22 01:02:03,343 epoch 9 - iter 9/37 - loss 0.62191309 - samples/sec: 79.45\n",
            "2020-05-22 01:02:14,957 epoch 9 - iter 12/37 - loss 0.60838908 - samples/sec: 76.85\n",
            "2020-05-22 01:02:28,063 epoch 9 - iter 15/37 - loss 0.59171602 - samples/sec: 76.30\n",
            "2020-05-22 01:02:39,149 epoch 9 - iter 18/37 - loss 0.58194639 - samples/sec: 75.86\n",
            "2020-05-22 01:02:50,738 epoch 9 - iter 21/37 - loss 0.58805037 - samples/sec: 78.15\n",
            "2020-05-22 01:03:02,631 epoch 9 - iter 24/37 - loss 0.59741177 - samples/sec: 65.02\n",
            "2020-05-22 01:03:14,697 epoch 9 - iter 27/37 - loss 0.61964419 - samples/sec: 79.01\n",
            "2020-05-22 01:03:26,240 epoch 9 - iter 30/37 - loss 0.61039788 - samples/sec: 85.85\n",
            "2020-05-22 01:03:37,435 epoch 9 - iter 33/37 - loss 0.64793207 - samples/sec: 88.15\n",
            "2020-05-22 01:03:48,816 epoch 9 - iter 36/37 - loss 0.65428215 - samples/sec: 82.61\n",
            "2020-05-22 01:03:59,273 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 01:03:59,276 EPOCH 9 done: loss 0.6587 - lr 0.1000000\n",
            "2020-05-22 01:04:01,652 DEV : loss 0.7248088717460632 - score 0.758\n",
            "2020-05-22 01:04:01,781 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-22 01:04:03,604 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 01:04:05,427 epoch 10 - iter 3/37 - loss 0.49353832 - samples/sec: 65.80\n",
            "2020-05-22 01:04:17,708 epoch 10 - iter 6/37 - loss 0.53612233 - samples/sec: 78.18\n",
            "2020-05-22 01:04:29,351 epoch 10 - iter 9/37 - loss 0.54604996 - samples/sec: 73.05\n",
            "2020-05-22 01:04:40,643 epoch 10 - iter 12/37 - loss 0.53145946 - samples/sec: 77.29\n",
            "2020-05-22 01:04:52,093 epoch 10 - iter 15/37 - loss 0.51898531 - samples/sec: 78.33\n",
            "2020-05-22 01:05:03,581 epoch 10 - iter 18/37 - loss 0.55050239 - samples/sec: 80.96\n",
            "2020-05-22 01:05:15,531 epoch 10 - iter 21/37 - loss 0.57944474 - samples/sec: 63.47\n",
            "2020-05-22 01:05:26,890 epoch 10 - iter 24/37 - loss 0.56617150 - samples/sec: 77.84\n",
            "2020-05-22 01:05:38,432 epoch 10 - iter 27/37 - loss 0.57988886 - samples/sec: 80.98\n",
            "2020-05-22 01:05:49,774 epoch 10 - iter 30/37 - loss 0.59309034 - samples/sec: 86.33\n",
            "2020-05-22 01:06:01,300 epoch 10 - iter 33/37 - loss 0.59054984 - samples/sec: 86.81\n",
            "2020-05-22 01:06:12,877 epoch 10 - iter 36/37 - loss 0.58700147 - samples/sec: 76.14\n",
            "2020-05-22 01:06:23,446 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 01:06:23,447 EPOCH 10 done: loss 0.5800 - lr 0.1000000\n",
            "2020-05-22 01:06:25,593 DEV : loss 0.7704737782478333 - score 0.8037\n",
            "2020-05-22 01:06:25,724 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-22 01:06:29,873 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-22 01:06:29,874 Testing using best model ...\n",
            "2020-05-22 01:06:29,877 loading file /content/drive/My Drive/Capstone/new_data/best-model.pt\n",
            "2020-05-22 01:06:32,618 0.6598639455782312\t0.6598639455782312\t0.6598639455782312\n",
            "2020-05-22 01:06:32,623 \n",
            "MICRO_AVG: acc 0.7732426303854876 - f1-score 0.6598639455782312\n",
            "MACRO_AVG: acc 0.7732426303854876 - f1-score 0.6350342152859354\n",
            "-1         tp: 37 - fp: 15 - fn: 12 - tn: 83 - precision: 0.7115 - recall: 0.7551 - accuracy: 0.8163 - f1-score: 0.7327\n",
            "0          tp: 44 - fp: 27 - fn: 3 - tn: 73 - precision: 0.6197 - recall: 0.9362 - accuracy: 0.7959 - f1-score: 0.7458\n",
            "1          tp: 16 - fp: 8 - fn: 35 - tn: 88 - precision: 0.6667 - recall: 0.3137 - accuracy: 0.7075 - f1-score: 0.4267\n",
            "2020-05-22 01:06:32,625 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.8998611569404602,\n",
              "  0.9690008163452148,\n",
              "  1.2271349430084229,\n",
              "  1.2768433094024658,\n",
              "  0.7436613440513611,\n",
              "  0.6968156695365906,\n",
              "  0.9381842017173767,\n",
              "  0.8523504137992859,\n",
              "  0.7248088717460632,\n",
              "  0.7704737782478333],\n",
              " 'dev_score_history': [0.7397260273972602,\n",
              "  0.6986301369863014,\n",
              "  0.5799086757990868,\n",
              "  0.5753424657534246,\n",
              "  0.7397260273972602,\n",
              "  0.7534246575342466,\n",
              "  0.730593607305936,\n",
              "  0.7534246575342466,\n",
              "  0.7579908675799086,\n",
              "  0.8036529680365296],\n",
              " 'test_score': 0.7732426303854876,\n",
              " 'train_loss_history': [1.2048546929617185,\n",
              "  0.9636928213609232,\n",
              "  0.8570267461441659,\n",
              "  0.7829802527620986,\n",
              "  0.7690218107120411,\n",
              "  0.7448374612911327,\n",
              "  0.6764946853792345,\n",
              "  0.6988622038751036,\n",
              "  0.6586972636145514,\n",
              "  0.5799998939037323]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2JikhOEZFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5maM-7gQWqJ",
        "colab_type": "text"
      },
      "source": [
        "### Second Stage (train on hand annotated datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbrXhSRlnCR3",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0E6iEy9UgYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data_folder = '/content/drive/My Drive/Capstone/second_stage_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGDir71nHb6",
        "colab_type": "text"
      },
      "source": [
        "#### Second Stage fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWg4fjqNYMKa",
        "colab_type": "code",
        "outputId": "cadf0c56-5bfd-4350-c481-861b9bc354a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# benchmark_embeddings = FlairEmbeddings(data_folder + 'best-model.pt')\n",
        "benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 22:56:22,462 loading file ./drive/My Drive/capstone/data/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1XWYH6QZGl",
        "colab_type": "code",
        "outputId": "bb3b5a9f-0100-4ab6-b88f-8307cc8c67da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer = ModelTrainer(benchmark_classifier, corpus)\n",
        "trainer.train(new_data_folder, max_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 22:56:25,413 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,418 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-21 22:56:25,421 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,422 Corpus: \"Corpus: 132 train + 33 dev + 33 test sentences\"\n",
            "2020-05-21 22:56:25,424 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,426 Parameters:\n",
            "2020-05-21 22:56:25,428  - learning_rate: \"0.1\"\n",
            "2020-05-21 22:56:25,431  - mini_batch_size: \"32\"\n",
            "2020-05-21 22:56:25,432  - patience: \"3\"\n",
            "2020-05-21 22:56:25,436  - anneal_factor: \"0.5\"\n",
            "2020-05-21 22:56:25,439  - max_epochs: \"10\"\n",
            "2020-05-21 22:56:25,442  - shuffle: \"True\"\n",
            "2020-05-21 22:56:25,444  - train_with_dev: \"False\"\n",
            "2020-05-21 22:56:25,446  - batch_growth_annealing: \"False\"\n",
            "2020-05-21 22:56:25,448 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,451 Model training base path: \"drive/My Drive/capstone/data/second_stage\"\n",
            "2020-05-21 22:56:25,454 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,456 Device: cuda:0\n",
            "2020-05-21 22:56:25,458 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,460 Embeddings storage mode: cpu\n",
            "2020-05-21 22:56:25,473 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:26,567 epoch 1 - iter 1/5 - loss 2.47603059 - samples/sec: 41.77\n",
            "2020-05-21 22:56:40,614 epoch 1 - iter 2/5 - loss 1.98752087 - samples/sec: 43.24\n",
            "2020-05-21 22:56:54,562 epoch 1 - iter 3/5 - loss 1.63302696 - samples/sec: 44.08\n",
            "2020-05-21 22:57:08,428 epoch 1 - iter 4/5 - loss 1.47905332 - samples/sec: 48.81\n",
            "2020-05-21 22:57:21,568 epoch 1 - iter 5/5 - loss 1.22447270 - samples/sec: 219.30\n",
            "2020-05-21 22:57:34,921 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:57:34,927 EPOCH 1 done: loss 1.2245 - lr 0.1000000\n",
            "2020-05-21 22:57:36,068 DEV : loss 0.6211347579956055 - score 0.7778\n",
            "2020-05-21 22:57:36,124 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 22:57:38,107 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:57:39,104 epoch 2 - iter 1/5 - loss 0.94350493 - samples/sec: 47.58\n",
            "2020-05-21 22:57:53,003 epoch 2 - iter 2/5 - loss 1.39652342 - samples/sec: 44.56\n",
            "2020-05-21 22:58:07,013 epoch 2 - iter 3/5 - loss 1.21690861 - samples/sec: 40.58\n",
            "2020-05-21 22:58:20,957 epoch 2 - iter 4/5 - loss 1.09449874 - samples/sec: 43.76\n",
            "2020-05-21 22:58:34,201 epoch 2 - iter 5/5 - loss 1.06485778 - samples/sec: 212.62\n",
            "2020-05-21 22:58:47,441 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:58:47,442 EPOCH 2 done: loss 1.0649 - lr 0.1000000\n",
            "2020-05-21 22:58:48,599 DEV : loss 0.6653227806091309 - score 0.7778\n",
            "2020-05-21 22:58:48,657 BAD EPOCHS (no improvement): 1\n",
            "2020-05-21 22:58:48,662 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:58:49,981 epoch 3 - iter 1/5 - loss 0.68031418 - samples/sec: 48.09\n",
            "2020-05-21 22:59:03,841 epoch 3 - iter 2/5 - loss 0.90626210 - samples/sec: 49.76\n",
            "2020-05-21 22:59:17,670 epoch 3 - iter 3/5 - loss 0.74246905 - samples/sec: 51.44\n",
            "2020-05-21 22:59:31,545 epoch 3 - iter 4/5 - loss 0.74629961 - samples/sec: 52.11\n",
            "2020-05-21 22:59:44,844 epoch 3 - iter 5/5 - loss 0.72768322 - samples/sec: 235.84\n",
            "2020-05-21 22:59:58,181 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:59:58,186 EPOCH 3 done: loss 0.7277 - lr 0.1000000\n",
            "2020-05-21 22:59:59,256 DEV : loss 0.5546189546585083 - score 0.7778\n",
            "2020-05-21 22:59:59,311 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:00:01,374 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:00:02,425 epoch 4 - iter 1/5 - loss 0.36992514 - samples/sec: 46.40\n",
            "2020-05-21 23:00:16,377 epoch 4 - iter 2/5 - loss 0.42011677 - samples/sec: 39.28\n",
            "2020-05-21 23:00:30,188 epoch 4 - iter 3/5 - loss 0.38523609 - samples/sec: 53.84\n",
            "2020-05-21 23:00:43,955 epoch 4 - iter 4/5 - loss 0.43879703 - samples/sec: 48.82\n",
            "2020-05-21 23:00:57,218 epoch 4 - iter 5/5 - loss 0.65687655 - samples/sec: 248.04\n",
            "2020-05-21 23:01:10,457 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:01:10,459 EPOCH 4 done: loss 0.6569 - lr 0.1000000\n",
            "2020-05-21 23:01:11,529 DEV : loss 0.4246145486831665 - score 0.8384\n",
            "2020-05-21 23:01:11,582 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:01:13,656 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:01:14,696 epoch 5 - iter 1/5 - loss 0.49954554 - samples/sec: 44.86\n",
            "2020-05-21 23:01:28,640 epoch 5 - iter 2/5 - loss 0.51323853 - samples/sec: 48.29\n",
            "2020-05-21 23:01:42,772 epoch 5 - iter 3/5 - loss 0.48786973 - samples/sec: 50.17\n",
            "2020-05-21 23:01:56,621 epoch 5 - iter 4/5 - loss 0.44873910 - samples/sec: 49.51\n",
            "2020-05-21 23:02:09,845 epoch 5 - iter 5/5 - loss 0.40970936 - samples/sec: 246.27\n",
            "2020-05-21 23:02:23,186 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:02:23,191 EPOCH 5 done: loss 0.4097 - lr 0.1000000\n",
            "2020-05-21 23:02:24,283 DEV : loss 0.34248945116996765 - score 0.8788\n",
            "2020-05-21 23:02:24,338 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:02:26,310 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:02:27,372 epoch 6 - iter 1/5 - loss 0.21148753 - samples/sec: 45.16\n",
            "2020-05-21 23:02:41,336 epoch 6 - iter 2/5 - loss 0.30649507 - samples/sec: 38.36\n",
            "2020-05-21 23:02:55,214 epoch 6 - iter 3/5 - loss 0.38828582 - samples/sec: 49.23\n",
            "2020-05-21 23:03:09,081 epoch 6 - iter 4/5 - loss 0.35075251 - samples/sec: 49.55\n",
            "2020-05-21 23:03:22,303 epoch 6 - iter 5/5 - loss 0.45927231 - samples/sec: 243.98\n",
            "2020-05-21 23:03:35,543 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:03:35,548 EPOCH 6 done: loss 0.4593 - lr 0.1000000\n",
            "2020-05-21 23:03:36,619 DEV : loss 2.3637852668762207 - score 0.6162\n",
            "2020-05-21 23:03:36,673 BAD EPOCHS (no improvement): 1\n",
            "2020-05-21 23:03:36,680 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:03:37,688 epoch 7 - iter 1/5 - loss 1.47228169 - samples/sec: 45.76\n",
            "2020-05-21 23:03:51,809 epoch 7 - iter 2/5 - loss 1.12373403 - samples/sec: 36.22\n",
            "2020-05-21 23:04:05,555 epoch 7 - iter 3/5 - loss 1.13963407 - samples/sec: 50.46\n",
            "2020-05-21 23:04:19,389 epoch 7 - iter 4/5 - loss 1.00034453 - samples/sec: 51.40\n",
            "2020-05-21 23:04:32,621 epoch 7 - iter 5/5 - loss 0.92683176 - samples/sec: 240.11\n",
            "2020-05-21 23:04:45,966 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:04:45,968 EPOCH 7 done: loss 0.9268 - lr 0.1000000\n",
            "2020-05-21 23:04:47,044 DEV : loss 0.3363116681575775 - score 0.8788\n",
            "2020-05-21 23:04:47,099 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:04:49,291 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:04:50,327 epoch 8 - iter 1/5 - loss 0.29025859 - samples/sec: 46.26\n",
            "2020-05-21 23:05:04,211 epoch 8 - iter 2/5 - loss 0.31462778 - samples/sec: 43.51\n",
            "2020-05-21 23:05:18,044 epoch 8 - iter 3/5 - loss 0.28279692 - samples/sec: 52.11\n",
            "2020-05-21 23:05:31,875 epoch 8 - iter 4/5 - loss 0.26356334 - samples/sec: 51.25\n",
            "2020-05-21 23:05:45,115 epoch 8 - iter 5/5 - loss 0.26085380 - samples/sec: 214.85\n",
            "2020-05-21 23:05:58,464 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:05:58,466 EPOCH 8 done: loss 0.2609 - lr 0.1000000\n",
            "2020-05-21 23:05:59,555 DEV : loss 1.2868273258209229 - score 0.7172\n",
            "2020-05-21 23:05:59,615 BAD EPOCHS (no improvement): 1\n",
            "2020-05-21 23:05:59,622 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:06:00,615 epoch 9 - iter 1/5 - loss 0.25317389 - samples/sec: 47.12\n",
            "2020-05-21 23:06:14,740 epoch 9 - iter 2/5 - loss 0.24439692 - samples/sec: 35.10\n",
            "2020-05-21 23:06:28,445 epoch 9 - iter 3/5 - loss 0.25073752 - samples/sec: 54.20\n",
            "2020-05-21 23:06:42,311 epoch 9 - iter 4/5 - loss 0.28024385 - samples/sec: 48.16\n",
            "2020-05-21 23:06:55,561 epoch 9 - iter 5/5 - loss 0.33514250 - samples/sec: 221.16\n",
            "2020-05-21 23:07:08,910 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:07:08,916 EPOCH 9 done: loss 0.3351 - lr 0.1000000\n",
            "2020-05-21 23:07:10,014 DEV : loss 0.8674789667129517 - score 0.8182\n",
            "2020-05-21 23:07:10,069 BAD EPOCHS (no improvement): 2\n",
            "2020-05-21 23:07:10,075 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:07:11,100 epoch 10 - iter 1/5 - loss 0.55110812 - samples/sec: 44.46\n",
            "2020-05-21 23:07:24,961 epoch 10 - iter 2/5 - loss 0.66377437 - samples/sec: 50.07\n",
            "2020-05-21 23:07:38,841 epoch 10 - iter 3/5 - loss 0.53912481 - samples/sec: 48.59\n",
            "2020-05-21 23:07:52,670 epoch 10 - iter 4/5 - loss 0.44988540 - samples/sec: 52.08\n",
            "2020-05-21 23:08:05,863 epoch 10 - iter 5/5 - loss 0.37118482 - samples/sec: 217.09\n",
            "2020-05-21 23:08:19,211 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:08:19,216 EPOCH 10 done: loss 0.3712 - lr 0.1000000\n",
            "2020-05-21 23:08:20,305 DEV : loss 0.4017622470855713 - score 0.899\n",
            "2020-05-21 23:08:20,362 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:08:24,581 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:08:24,585 Testing using best model ...\n",
            "2020-05-21 23:08:24,591 loading file drive/My Drive/capstone/data/second_stage/best-model.pt\n",
            "2020-05-21 23:08:26,632 0.8484848484848485\t0.8484848484848485\t0.8484848484848486\n",
            "2020-05-21 23:08:26,638 \n",
            "MICRO_AVG: acc 0.898989898989899 - f1-score 0.8484848484848486\n",
            "MACRO_AVG: acc 0.8989898989898991 - f1-score 0.8523809523809525\n",
            "-1         tp: 9 - fp: 1 - fn: 2 - tn: 21 - precision: 0.9000 - recall: 0.8182 - accuracy: 0.9091 - f1-score: 0.8571\n",
            "0          tp: 10 - fp: 4 - fn: 1 - tn: 18 - precision: 0.7143 - recall: 0.9091 - accuracy: 0.8485 - f1-score: 0.8000\n",
            "1          tp: 9 - fp: 0 - fn: 2 - tn: 22 - precision: 1.0000 - recall: 0.8182 - accuracy: 0.9394 - f1-score: 0.9000\n",
            "2020-05-21 23:08:26,642 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.6211347579956055,\n",
              "  0.6653227806091309,\n",
              "  0.5546189546585083,\n",
              "  0.4246145486831665,\n",
              "  0.34248945116996765,\n",
              "  2.3637852668762207,\n",
              "  0.3363116681575775,\n",
              "  1.2868273258209229,\n",
              "  0.8674789667129517,\n",
              "  0.4017622470855713],\n",
              " 'dev_score_history': [0.7777777777777778,\n",
              "  0.7777777777777778,\n",
              "  0.7777777777777778,\n",
              "  0.8383838383838383,\n",
              "  0.8787878787878788,\n",
              "  0.6161616161616161,\n",
              "  0.8787878787878788,\n",
              "  0.7171717171717171,\n",
              "  0.8181818181818182,\n",
              "  0.898989898989899],\n",
              " 'test_score': 0.898989898989899,\n",
              " 'train_loss_history': [1.22447270154953,\n",
              "  1.0648577809333801,\n",
              "  0.7276832222938537,\n",
              "  0.6568765461444854,\n",
              "  0.4097093641757965,\n",
              "  0.4592723071575165,\n",
              "  0.9268317580223083,\n",
              "  0.26085380017757415,\n",
              "  0.3351425021886826,\n",
              "  0.37118481993675234]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKyyw1CSZFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbf02034-eb5d-495b-fc3f-1676ecece4ba"
      },
      "source": [
        "final_classifier = TextClassifier.load(new_data_folder + 'final-model.pt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 02:10:33,883 loading file /content/drive/My Drive/Capstone/second_stage_data/final-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Klf6tFJSKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "86a3925a-f51c-4092-df23-a1befee506e8"
      },
      "source": [
        "final_classifier.predict(\"Canada's economy shrinks in October from auto strike spillover. Canada’s economy contracted in October for the first time in eight months, as the United Auto Workers strike in the U.S. weighed on plant production\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence: \"Canada's economy shrinks in October from auto strike spillover. Canada’s economy contracted in October for the first time in eight months, as the United Auto Workers strike in the U.S. weighed on plant production\"   [− Tokens: 34  − Sentence-Labels: {'class': [-1 (0.9992)]}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0PdX89UJf9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}