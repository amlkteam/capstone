{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Two stage flair training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c77f1ef62e4b4eb096c479d3e32115fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_841075c3d81d45be8dbd463b49f4b616",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d9aa008f1914208bc0fe13a47d61d57",
              "IPY_MODEL_c6fefd65bcff4f21bde5a7ccff636080"
            ]
          }
        },
        "841075c3d81d45be8dbd463b49f4b616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d9aa008f1914208bc0fe13a47d61d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d740f077937b423584eeb7b338411fab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b539d242fcf148dba6384f206950fec2"
          }
        },
        "c6fefd65bcff4f21bde5a7ccff636080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_149fbbfca875490eacfedf3dee2d3bab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 827kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c4be3c21c8848b3b668007be4c5c4ba"
          }
        },
        "d740f077937b423584eeb7b338411fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b539d242fcf148dba6384f206950fec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "149fbbfca875490eacfedf3dee2d3bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c4be3c21c8848b3b668007be4c5c4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b8e6eaa6f55457ca311a0a5e9f82cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_133f98493e654f4a98a80c59e26324a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f7a1ec90af14d919f8f2b6075483a93",
              "IPY_MODEL_0a9bf515ae1c43858bd9dfa018099c76"
            ]
          }
        },
        "133f98493e654f4a98a80c59e26324a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f7a1ec90af14d919f8f2b6075483a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c93f08209dea4de9a7e6503519e24a43",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1506181aa044402d94d73420b9e8314e"
          }
        },
        "0a9bf515ae1c43858bd9dfa018099c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c968cebc32074dadb00536adabe5f4b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:09&lt;00:00, 43.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9352560607e64304a280dd3b659c1401"
          }
        },
        "c93f08209dea4de9a7e6503519e24a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1506181aa044402d94d73420b9e8314e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c968cebc32074dadb00536adabe5f4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9352560607e64304a280dd3b659c1401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa5cd174d4d349e39f24121162d339ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_010cce0aea28493395142cbe902d1c96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80b256e0b95848ea8159cefb51c40f2a",
              "IPY_MODEL_1745a2ab7cf1455ab9970f53544091b0"
            ]
          }
        },
        "010cce0aea28493395142cbe902d1c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80b256e0b95848ea8159cefb51c40f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_111034d875a042b181ec27ab95493eda",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd2e1fe5770a489ea24fd889f4dcd85c"
          }
        },
        "1745a2ab7cf1455ab9970f53544091b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e93801303b349f3b4b4c24bf655ace6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_940f0d92faa34d69a70cc87bebe2f4ec"
          }
        },
        "111034d875a042b181ec27ab95493eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd2e1fe5770a489ea24fd889f4dcd85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e93801303b349f3b4b4c24bf655ace6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "940f0d92faa34d69a70cc87bebe2f4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybjXa4UJ3g7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVY0ZiGk38i_",
        "colab_type": "code",
        "outputId": "332e2955-e7e4-4cbb-b39d-8e4be1fbee1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-2uq1kiol\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-2uq1kiol\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.1.2)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 6.5MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting transformers>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.5.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2.8.1)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 39.0MB/s \n",
            "\u001b[?25hCollecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/f9/9f2b6c672c8f8bb87a4c1bd52c1b57213627b035305aad745d015b2a62ae/pytest-5.4.2-py3-none-any.whl (247kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 36.7MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.2.1)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.5) (1.12.1)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 19.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.4.5) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (8.3.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.6.0->flair==0.4.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.13.13)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.4.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.16.13)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.4.5-cp36-none-any.whl size=148505 sha256=0e830f8bcfe065dc0e53bb3c8e6ff68448d9dd279dd29ca510a10f7f781abba7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i8wc5kpo/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Building wheels for collected packages: mpld3, sqlitedict, langdetect, segtok, sacremoses\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=8b5210abad3b201518b68c0b6f451ad22e95b967b3672a82b406911218ff51a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=11d7cdaee699bcab452ab3fb84e717cc32f47e0620aefc0842cb744bfd7da3e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=2a4e19721ab302eba15310902dad12f1a6d2bcd9dbce6e15c9193c67289d10b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=59b02677c14403c8b8562556ed287472b9cc2690f984bdb4689512b9e65b4c91\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b2134c3f306fd6cdbb171cf9acc166a3fa4c8c185d99fff5b3548dd2c0e9ac0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built mpld3 sqlitedict langdetect segtok sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: mpld3, sqlitedict, deprecated, tokenizers, sentencepiece, sacremoses, transformers, langdetect, pluggy, pytest, bpemb, segtok, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.4.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.2 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP7gl75D39dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "from flair.data import Corpus\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfpsjw8I4Si-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBdZ1L34XwO",
        "colab_type": "code",
        "outputId": "ea3bde99-955f-4c1a-d0a6-c6cd437825b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U90p69Xd5KIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_folder = \"./drive/My Drive/capstone/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkUisuXz7tuK",
        "colab_type": "text"
      },
      "source": [
        "### First Stage (Train on benchmark dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-_Bmpa6gn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = pd.read_csv(data_folder + \"combined_benchmark.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVaSsyAn72AU",
        "colab_type": "code",
        "outputId": "90d3d87c-722b-41c1-fd1f-100d3989b196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "benchmark = benchmark[['label', 'text']]\n",
        "benchmark.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Why not subscribe to the magazine ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>Tornio Works employs 2,300 of whom more than 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>The move is aimed at boosting sales , cost-eff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>As a result of the merger , the largest profes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>18 March 2010 A leakage in the gypsum pond was...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0                Why not subscribe to the magazine ?\n",
              "1     -1  Tornio Works employs 2,300 of whom more than 1...\n",
              "2      1  The move is aimed at boosting sales , cost-eff...\n",
              "3      0  As a result of the merger , the largest profes...\n",
              "4     -1  18 March 2010 A leakage in the gypsum pond was..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_MVMXq8pvf",
        "colab_type": "text"
      },
      "source": [
        "#### Create train, dev and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUbbfcSC8ekr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark = benchmark.sample(frac=1)\n",
        "benchmark.iloc[0:int(len(benchmark)*0.8)].to_csv(data_folder + 'train.csv', sep='\\t', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.8):int(len(benchmark)*0.9)].to_csv(data_folder + 'test.csv', sep='\\t', index = False, header = False)\n",
        "benchmark.iloc[int(len(benchmark)*0.9):].to_csv(data_folder + 'dev.csv', sep='\\t', index = False, header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7QE3IS69txr",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz-2gNy58wDI",
        "colab_type": "code",
        "outputId": "1bc31adc-dc66-4e97-a4b5-ca7ce66fc2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_folder), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
        "column_name_map = {1: \"text\", 0: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                         column_name_map,\n",
        "                                         skip_header=False, #no header in kaggle data\n",
        "                                         delimiter='\\t',    # comma separated rows\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 21:33:57,559 Reading data from drive/My Drive/capstone/data\n",
            "2020-05-21 21:33:57,560 Train: drive/My Drive/capstone/data/train.csv\n",
            "2020-05-21 21:33:57,561 Dev: drive/My Drive/capstone/data/dev.csv\n",
            "2020-05-21 21:33:57,563 Test: drive/My Drive/capstone/data/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb1lynSQ98-z",
        "colab_type": "text"
      },
      "source": [
        "#### Create word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u9PFUze9_5y",
        "colab_type": "code",
        "outputId": "f20a2afc-8be1-4511-cb1f-d908d4f5a53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "c77f1ef62e4b4eb096c479d3e32115fd",
            "841075c3d81d45be8dbd463b49f4b616",
            "6d9aa008f1914208bc0fe13a47d61d57",
            "c6fefd65bcff4f21bde5a7ccff636080",
            "d740f077937b423584eeb7b338411fab",
            "b539d242fcf148dba6384f206950fec2",
            "149fbbfca875490eacfedf3dee2d3bab",
            "4c4be3c21c8848b3b668007be4c5c4ba",
            "9b8e6eaa6f55457ca311a0a5e9f82cee",
            "133f98493e654f4a98a80c59e26324a8",
            "3f7a1ec90af14d919f8f2b6075483a93",
            "0a9bf515ae1c43858bd9dfa018099c76",
            "c93f08209dea4de9a7e6503519e24a43",
            "1506181aa044402d94d73420b9e8314e",
            "c968cebc32074dadb00536adabe5f4b0",
            "9352560607e64304a280dd3b659c1401",
            "aa5cd174d4d349e39f24121162d339ba",
            "010cce0aea28493395142cbe902d1c96",
            "80b256e0b95848ea8159cefb51c40f2a",
            "1745a2ab7cf1455ab9970f53544091b0",
            "111034d875a042b181ec27ab95493eda",
            "dd2e1fe5770a489ea24fd889f4dcd85c",
            "1e93801303b349f3b4b4c24bf655ace6",
            "940f0d92faa34d69a70cc87bebe2f4ec"
          ]
        }
      },
      "source": [
        "word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c77f1ef62e4b4eb096c479d3e32115fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b8e6eaa6f55457ca311a0a5e9f82cee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa5cd174d4d349e39f24121162d339ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2020-05-21 21:34:20,508 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpx661a1f1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:00<00:00, 49444260.47B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 21:34:21,096 copying /tmp/tmpx661a1f1 to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 21:34:21,125 removing temp file /tmp/tmpx661a1f1\n",
            "2020-05-21 21:34:37,776 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp119mrbt1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:00<00:00, 51132721.58B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 21:34:38,322 copying /tmp/tmp119mrbt1 to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 21:34:38,354 removing temp file /tmp/tmp119mrbt1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HovCqFfSMjmJ",
        "colab_type": "text"
      },
      "source": [
        "#### First Stage Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wik8DDxm-DKy",
        "colab_type": "code",
        "outputId": "a95b394e-05f7-45f5-e630-5491ae7e0cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train(data_folder, max_epochs=10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 21:34:44,497 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "100%|██████████| 1314/1314 [00:02<00:00, 642.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 21:34:46,855 [b'0', b'-1', b'1']\n",
            "2020-05-21 21:34:46,874 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:34:46,877 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-21 21:34:46,881 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:34:46,882 Corpus: \"Corpus: 1168 train + 147 dev + 146 test sentences\"\n",
            "2020-05-21 21:34:46,883 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:34:46,889 Parameters:\n",
            "2020-05-21 21:34:46,890  - learning_rate: \"0.1\"\n",
            "2020-05-21 21:34:46,904  - mini_batch_size: \"32\"\n",
            "2020-05-21 21:34:46,907  - patience: \"3\"\n",
            "2020-05-21 21:34:46,908  - anneal_factor: \"0.5\"\n",
            "2020-05-21 21:34:46,909  - max_epochs: \"10\"\n",
            "2020-05-21 21:34:46,910  - shuffle: \"True\"\n",
            "2020-05-21 21:34:46,912  - train_with_dev: \"False\"\n",
            "2020-05-21 21:34:46,913  - batch_growth_annealing: \"False\"\n",
            "2020-05-21 21:34:46,915 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:34:46,916 Model training base path: \"drive/My Drive/capstone/data\"\n",
            "2020-05-21 21:34:46,920 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:34:46,921 Device: cuda:0\n",
            "2020-05-21 21:34:46,930 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:34:46,932 Embeddings storage mode: cpu\n",
            "2020-05-21 21:34:46,946 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 21:34:49,614 epoch 1 - iter 3/37 - loss 1.37792166 - samples/sec: 41.88\n",
            "2020-05-21 21:35:04,758 epoch 1 - iter 6/37 - loss 1.38339380 - samples/sec: 50.24\n",
            "2020-05-21 21:35:20,032 epoch 1 - iter 9/37 - loss 1.25956689 - samples/sec: 47.84\n",
            "2020-05-21 21:35:35,205 epoch 1 - iter 12/37 - loss 1.27234081 - samples/sec: 44.19\n",
            "2020-05-21 21:35:50,097 epoch 1 - iter 15/37 - loss 1.23371030 - samples/sec: 56.95\n",
            "2020-05-21 21:36:05,057 epoch 1 - iter 18/37 - loss 1.22769420 - samples/sec: 57.27\n",
            "2020-05-21 21:36:19,920 epoch 1 - iter 21/37 - loss 1.21607478 - samples/sec: 57.71\n",
            "2020-05-21 21:36:35,063 epoch 1 - iter 24/37 - loss 1.20891273 - samples/sec: 52.59\n",
            "2020-05-21 21:36:50,015 epoch 1 - iter 27/37 - loss 1.19474173 - samples/sec: 55.33\n",
            "2020-05-21 21:37:04,955 epoch 1 - iter 30/37 - loss 1.17071977 - samples/sec: 52.95\n",
            "2020-05-21 21:37:19,909 epoch 1 - iter 33/37 - loss 1.14583929 - samples/sec: 54.74\n",
            "2020-05-21 21:37:34,727 epoch 1 - iter 36/37 - loss 1.15452903 - samples/sec: 52.71\n",
            "2020-05-21 21:37:48,457 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:37:48,458 EPOCH 1 done: loss 1.1595 - lr 0.1000000\n",
            "2020-05-21 21:37:51,776 DEV : loss 0.9445202946662903 - score 0.7007\n",
            "2020-05-21 21:37:51,933 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 21:37:54,046 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:37:56,358 epoch 2 - iter 3/37 - loss 0.85524519 - samples/sec: 50.25\n",
            "2020-05-21 21:38:11,253 epoch 2 - iter 6/37 - loss 1.09922825 - samples/sec: 54.97\n",
            "2020-05-21 21:38:26,507 epoch 2 - iter 9/37 - loss 1.00522574 - samples/sec: 54.98\n",
            "2020-05-21 21:38:41,368 epoch 2 - iter 12/37 - loss 0.98037452 - samples/sec: 54.78\n",
            "2020-05-21 21:38:56,222 epoch 2 - iter 15/37 - loss 0.97838963 - samples/sec: 55.68\n",
            "2020-05-21 21:39:11,054 epoch 2 - iter 18/37 - loss 0.98308966 - samples/sec: 59.10\n",
            "2020-05-21 21:39:26,334 epoch 2 - iter 21/37 - loss 0.95657368 - samples/sec: 51.80\n",
            "2020-05-21 21:39:41,357 epoch 2 - iter 24/37 - loss 0.95138034 - samples/sec: 52.98\n",
            "2020-05-21 21:39:56,173 epoch 2 - iter 27/37 - loss 0.95253751 - samples/sec: 57.74\n",
            "2020-05-21 21:40:10,860 epoch 2 - iter 30/37 - loss 0.98773212 - samples/sec: 61.09\n",
            "2020-05-21 21:40:26,100 epoch 2 - iter 33/37 - loss 0.97131553 - samples/sec: 52.78\n",
            "2020-05-21 21:40:41,006 epoch 2 - iter 36/37 - loss 0.96665085 - samples/sec: 56.53\n",
            "2020-05-21 21:40:54,593 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:40:54,597 EPOCH 2 done: loss 0.9739 - lr 0.1000000\n",
            "2020-05-21 21:40:57,735 DEV : loss 0.931380569934845 - score 0.6871\n",
            "2020-05-21 21:40:57,920 BAD EPOCHS (no improvement): 1\n",
            "2020-05-21 21:40:57,930 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:41:00,220 epoch 3 - iter 3/37 - loss 0.78594307 - samples/sec: 53.17\n",
            "2020-05-21 21:41:15,319 epoch 3 - iter 6/37 - loss 0.87059626 - samples/sec: 57.18\n",
            "2020-05-21 21:41:30,252 epoch 3 - iter 9/37 - loss 0.83778094 - samples/sec: 56.83\n",
            "2020-05-21 21:41:45,306 epoch 3 - iter 12/37 - loss 0.82532736 - samples/sec: 53.17\n",
            "2020-05-21 21:42:00,170 epoch 3 - iter 15/37 - loss 0.82298377 - samples/sec: 58.05\n",
            "2020-05-21 21:42:15,125 epoch 3 - iter 18/37 - loss 0.83990110 - samples/sec: 55.10\n",
            "2020-05-21 21:42:29,999 epoch 3 - iter 21/37 - loss 0.86151212 - samples/sec: 57.33\n",
            "2020-05-21 21:42:44,930 epoch 3 - iter 24/37 - loss 0.84199478 - samples/sec: 54.04\n",
            "2020-05-21 21:42:59,845 epoch 3 - iter 27/37 - loss 0.85924654 - samples/sec: 55.98\n",
            "2020-05-21 21:43:14,781 epoch 3 - iter 30/37 - loss 0.84688073 - samples/sec: 55.50\n",
            "2020-05-21 21:43:29,649 epoch 3 - iter 33/37 - loss 0.84553108 - samples/sec: 57.70\n",
            "2020-05-21 21:43:44,517 epoch 3 - iter 36/37 - loss 0.82642869 - samples/sec: 54.67\n",
            "2020-05-21 21:43:58,244 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:43:58,249 EPOCH 3 done: loss 0.8259 - lr 0.1000000\n",
            "2020-05-21 21:44:01,262 DEV : loss 1.0202172994613647 - score 0.6961\n",
            "2020-05-21 21:44:01,422 BAD EPOCHS (no improvement): 2\n",
            "2020-05-21 21:44:01,427 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:44:04,053 epoch 4 - iter 3/37 - loss 0.69517150 - samples/sec: 42.90\n",
            "2020-05-21 21:44:19,829 epoch 4 - iter 6/37 - loss 0.72263813 - samples/sec: 53.00\n",
            "2020-05-21 21:44:35,580 epoch 4 - iter 9/37 - loss 0.75209264 - samples/sec: 56.52\n",
            "2020-05-21 21:44:51,337 epoch 4 - iter 12/37 - loss 0.72499405 - samples/sec: 56.21\n",
            "2020-05-21 21:45:07,397 epoch 4 - iter 15/37 - loss 0.72337782 - samples/sec: 56.74\n",
            "2020-05-21 21:45:23,166 epoch 4 - iter 18/37 - loss 0.73976502 - samples/sec: 56.25\n",
            "2020-05-21 21:45:38,982 epoch 4 - iter 21/37 - loss 0.72228904 - samples/sec: 55.21\n",
            "2020-05-21 21:45:54,710 epoch 4 - iter 24/37 - loss 0.75199094 - samples/sec: 57.58\n",
            "2020-05-21 21:46:10,811 epoch 4 - iter 27/37 - loss 0.75499927 - samples/sec: 49.97\n",
            "2020-05-21 21:46:26,421 epoch 4 - iter 30/37 - loss 0.74420565 - samples/sec: 58.69\n",
            "2020-05-21 21:46:42,230 epoch 4 - iter 33/37 - loss 0.75718331 - samples/sec: 54.88\n",
            "2020-05-21 21:46:57,865 epoch 4 - iter 36/37 - loss 0.78696104 - samples/sec: 61.53\n",
            "2020-05-21 21:47:12,503 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:47:12,508 EPOCH 4 done: loss 0.7832 - lr 0.1000000\n",
            "2020-05-21 21:47:15,796 DEV : loss 0.8029612898826599 - score 0.7415\n",
            "2020-05-21 21:47:15,951 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 21:47:18,187 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:47:20,541 epoch 5 - iter 3/37 - loss 0.64034499 - samples/sec: 49.05\n",
            "2020-05-21 21:47:36,013 epoch 5 - iter 6/37 - loss 0.79552535 - samples/sec: 55.93\n",
            "2020-05-21 21:47:51,916 epoch 5 - iter 9/37 - loss 0.76471422 - samples/sec: 53.36\n",
            "2020-05-21 21:48:07,934 epoch 5 - iter 12/37 - loss 0.76398595 - samples/sec: 48.46\n",
            "2020-05-21 21:48:23,588 epoch 5 - iter 15/37 - loss 0.74059561 - samples/sec: 58.19\n",
            "2020-05-21 21:48:39,467 epoch 5 - iter 18/37 - loss 0.73144527 - samples/sec: 55.84\n",
            "2020-05-21 21:48:55,232 epoch 5 - iter 21/37 - loss 0.71586683 - samples/sec: 56.07\n",
            "2020-05-21 21:49:11,306 epoch 5 - iter 24/37 - loss 0.72395818 - samples/sec: 52.77\n",
            "2020-05-21 21:49:27,162 epoch 5 - iter 27/37 - loss 0.72656212 - samples/sec: 57.58\n",
            "2020-05-21 21:49:42,920 epoch 5 - iter 30/37 - loss 0.72081359 - samples/sec: 56.03\n",
            "2020-05-21 21:49:58,665 epoch 5 - iter 33/37 - loss 0.71714353 - samples/sec: 56.90\n",
            "2020-05-21 21:50:14,470 epoch 5 - iter 36/37 - loss 0.73095743 - samples/sec: 58.60\n",
            "2020-05-21 21:50:29,039 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:50:29,041 EPOCH 5 done: loss 0.7250 - lr 0.1000000\n",
            "2020-05-21 21:50:33,455 DEV : loss 0.8560692667961121 - score 0.7596\n",
            "2020-05-21 21:50:33,627 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 21:50:35,752 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:50:38,190 epoch 6 - iter 3/37 - loss 0.63888168 - samples/sec: 51.43\n",
            "2020-05-21 21:50:53,821 epoch 6 - iter 6/37 - loss 0.78605540 - samples/sec: 55.68\n",
            "2020-05-21 21:51:09,795 epoch 6 - iter 9/37 - loss 0.70923318 - samples/sec: 58.92\n",
            "2020-05-21 21:51:25,526 epoch 6 - iter 12/37 - loss 0.72843050 - samples/sec: 57.41\n",
            "2020-05-21 21:51:41,177 epoch 6 - iter 15/37 - loss 0.73410404 - samples/sec: 56.53\n",
            "2020-05-21 21:51:57,278 epoch 6 - iter 18/37 - loss 0.74840003 - samples/sec: 56.32\n",
            "2020-05-21 21:52:13,020 epoch 6 - iter 21/37 - loss 0.72714724 - samples/sec: 56.50\n",
            "2020-05-21 21:52:28,843 epoch 6 - iter 24/37 - loss 0.71306286 - samples/sec: 55.04\n",
            "2020-05-21 21:52:44,545 epoch 6 - iter 27/37 - loss 0.69998651 - samples/sec: 57.90\n",
            "2020-05-21 21:53:00,385 epoch 6 - iter 30/37 - loss 0.68654988 - samples/sec: 58.09\n",
            "2020-05-21 21:53:16,322 epoch 6 - iter 33/37 - loss 0.69359179 - samples/sec: 50.98\n",
            "2020-05-21 21:53:32,036 epoch 6 - iter 36/37 - loss 0.71336695 - samples/sec: 57.81\n",
            "2020-05-21 21:53:46,625 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:53:46,627 EPOCH 6 done: loss 0.7038 - lr 0.1000000\n",
            "2020-05-21 21:53:49,593 DEV : loss 0.8320075869560242 - score 0.7324\n",
            "2020-05-21 21:53:49,742 BAD EPOCHS (no improvement): 1\n",
            "2020-05-21 21:53:49,747 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:53:52,381 epoch 7 - iter 3/37 - loss 0.67194335 - samples/sec: 49.78\n",
            "2020-05-21 21:54:08,092 epoch 7 - iter 6/37 - loss 0.59081362 - samples/sec: 58.02\n",
            "2020-05-21 21:54:23,855 epoch 7 - iter 9/37 - loss 0.54072740 - samples/sec: 56.66\n",
            "2020-05-21 21:54:39,668 epoch 7 - iter 12/37 - loss 0.60737691 - samples/sec: 58.63\n",
            "2020-05-21 21:54:55,538 epoch 7 - iter 15/37 - loss 0.65824075 - samples/sec: 56.61\n",
            "2020-05-21 21:55:11,237 epoch 7 - iter 18/37 - loss 0.64680442 - samples/sec: 57.85\n",
            "2020-05-21 21:55:27,133 epoch 7 - iter 21/37 - loss 0.64072014 - samples/sec: 56.84\n",
            "2020-05-21 21:55:42,843 epoch 7 - iter 24/37 - loss 0.65696819 - samples/sec: 57.42\n",
            "2020-05-21 21:55:58,755 epoch 7 - iter 27/37 - loss 0.69582895 - samples/sec: 57.95\n",
            "2020-05-21 21:56:14,659 epoch 7 - iter 30/37 - loss 0.67759945 - samples/sec: 55.81\n",
            "2020-05-21 21:56:30,356 epoch 7 - iter 33/37 - loss 0.68227184 - samples/sec: 58.23\n",
            "2020-05-21 21:56:46,079 epoch 7 - iter 36/37 - loss 0.67792013 - samples/sec: 57.87\n",
            "2020-05-21 21:57:00,535 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:57:00,537 EPOCH 7 done: loss 0.6765 - lr 0.1000000\n",
            "2020-05-21 21:57:03,744 DEV : loss 1.0983926057815552 - score 0.7052\n",
            "2020-05-21 21:57:03,899 BAD EPOCHS (no improvement): 2\n",
            "2020-05-21 21:57:03,904 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 21:57:06,144 epoch 8 - iter 3/37 - loss 0.59439997 - samples/sec: 52.96\n",
            "2020-05-21 21:57:21,873 epoch 8 - iter 6/37 - loss 0.56928804 - samples/sec: 55.20\n",
            "2020-05-21 21:57:37,489 epoch 8 - iter 9/37 - loss 0.64330026 - samples/sec: 58.25\n",
            "2020-05-21 21:57:53,477 epoch 8 - iter 12/37 - loss 0.72071398 - samples/sec: 49.90\n",
            "2020-05-21 21:58:09,250 epoch 8 - iter 15/37 - loss 0.67545224 - samples/sec: 56.58\n",
            "2020-05-21 21:58:24,957 epoch 8 - iter 18/37 - loss 0.63852616 - samples/sec: 58.47\n",
            "2020-05-21 21:58:40,845 epoch 8 - iter 21/37 - loss 0.61622297 - samples/sec: 49.90\n",
            "2020-05-21 21:58:56,901 epoch 8 - iter 24/37 - loss 0.59554440 - samples/sec: 51.58\n",
            "2020-05-21 21:59:12,591 epoch 8 - iter 27/37 - loss 0.60221954 - samples/sec: 58.72\n",
            "2020-05-21 21:59:28,320 epoch 8 - iter 30/37 - loss 0.59528004 - samples/sec: 57.45\n",
            "2020-05-21 21:59:44,075 epoch 8 - iter 33/37 - loss 0.59690305 - samples/sec: 56.90\n",
            "2020-05-21 21:59:59,799 epoch 8 - iter 36/37 - loss 0.59973333 - samples/sec: 57.15\n",
            "2020-05-21 22:00:14,199 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:00:14,201 EPOCH 8 done: loss 0.5982 - lr 0.1000000\n",
            "2020-05-21 22:00:17,464 DEV : loss 0.8370154500007629 - score 0.746\n",
            "2020-05-21 22:00:17,618 BAD EPOCHS (no improvement): 3\n",
            "2020-05-21 22:00:17,625 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:00:19,915 epoch 9 - iter 3/37 - loss 0.79148982 - samples/sec: 52.88\n",
            "2020-05-21 22:00:35,852 epoch 9 - iter 6/37 - loss 0.79131648 - samples/sec: 55.46\n",
            "2020-05-21 22:00:51,719 epoch 9 - iter 9/37 - loss 0.82306821 - samples/sec: 62.23\n",
            "2020-05-21 22:01:07,550 epoch 9 - iter 12/37 - loss 0.78826874 - samples/sec: 54.18\n",
            "2020-05-21 22:01:23,387 epoch 9 - iter 15/37 - loss 0.73234124 - samples/sec: 54.12\n",
            "2020-05-21 22:01:39,065 epoch 9 - iter 18/37 - loss 0.69298738 - samples/sec: 57.99\n",
            "2020-05-21 22:01:55,083 epoch 9 - iter 21/37 - loss 0.65552629 - samples/sec: 48.30\n",
            "2020-05-21 22:02:10,903 epoch 9 - iter 24/37 - loss 0.64999323 - samples/sec: 54.43\n",
            "2020-05-21 22:02:26,840 epoch 9 - iter 27/37 - loss 0.65730035 - samples/sec: 54.08\n",
            "2020-05-21 22:02:42,617 epoch 9 - iter 30/37 - loss 0.65020915 - samples/sec: 57.19\n",
            "2020-05-21 22:02:58,296 epoch 9 - iter 33/37 - loss 0.65261606 - samples/sec: 58.95\n",
            "2020-05-21 22:03:14,367 epoch 9 - iter 36/37 - loss 0.63152339 - samples/sec: 50.67\n",
            "2020-05-21 22:03:28,810 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:03:28,816 EPOCH 9 done: loss 0.6327 - lr 0.1000000\n",
            "2020-05-21 22:03:31,784 DEV : loss 1.3560564517974854 - score 0.6871\n",
            "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-05-21 22:03:31,944 BAD EPOCHS (no improvement): 4\n",
            "2020-05-21 22:03:31,949 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:03:34,111 epoch 10 - iter 3/37 - loss 0.63264841 - samples/sec: 52.16\n",
            "2020-05-21 22:03:50,282 epoch 10 - iter 6/37 - loss 0.48688252 - samples/sec: 53.38\n",
            "2020-05-21 22:04:06,139 epoch 10 - iter 9/37 - loss 0.46484144 - samples/sec: 53.50\n",
            "2020-05-21 22:04:21,886 epoch 10 - iter 12/37 - loss 0.43838393 - samples/sec: 56.74\n",
            "2020-05-21 22:04:37,556 epoch 10 - iter 15/37 - loss 0.43753751 - samples/sec: 55.45\n",
            "2020-05-21 22:04:53,430 epoch 10 - iter 18/37 - loss 0.43621853 - samples/sec: 56.95\n",
            "2020-05-21 22:05:09,227 epoch 10 - iter 21/37 - loss 0.45240130 - samples/sec: 58.66\n",
            "2020-05-21 22:05:24,972 epoch 10 - iter 24/37 - loss 0.45714683 - samples/sec: 56.72\n",
            "2020-05-21 22:05:40,659 epoch 10 - iter 27/37 - loss 0.46108902 - samples/sec: 56.48\n",
            "2020-05-21 22:05:56,370 epoch 10 - iter 30/37 - loss 0.45459591 - samples/sec: 55.10\n",
            "2020-05-21 22:06:12,242 epoch 10 - iter 33/37 - loss 0.45016072 - samples/sec: 59.58\n",
            "2020-05-21 22:06:27,952 epoch 10 - iter 36/37 - loss 0.45976658 - samples/sec: 57.95\n",
            "2020-05-21 22:06:42,622 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:06:42,628 EPOCH 10 done: loss 0.4617 - lr 0.0500000\n",
            "2020-05-21 22:06:45,675 DEV : loss 0.8271321654319763 - score 0.7732\n",
            "2020-05-21 22:06:45,837 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 22:06:50,595 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:06:50,604 Testing using best model ...\n",
            "2020-05-21 22:06:50,613 loading file drive/My Drive/capstone/data/best-model.pt\n",
            "2020-05-21 22:06:54,653 0.6643835616438356\t0.6643835616438356\t0.6643835616438356\n",
            "2020-05-21 22:06:54,660 \n",
            "MICRO_AVG: acc 0.776255707762557 - f1-score 0.6643835616438356\n",
            "MACRO_AVG: acc 0.776255707762557 - f1-score 0.6142857142857143\n",
            "-1         tp: 35 - fp: 20 - fn: 10 - tn: 81 - precision: 0.6364 - recall: 0.7778 - accuracy: 0.7945 - f1-score: 0.7000\n",
            "0          tp: 51 - fp: 22 - fn: 2 - tn: 71 - precision: 0.6986 - recall: 0.9623 - accuracy: 0.8356 - f1-score: 0.8095\n",
            "1          tp: 11 - fp: 7 - fn: 37 - tn: 91 - precision: 0.6111 - recall: 0.2292 - accuracy: 0.6986 - f1-score: 0.3333\n",
            "2020-05-21 22:06:54,664 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.9445202946662903,\n",
              "  0.931380569934845,\n",
              "  1.0202172994613647,\n",
              "  0.8029612898826599,\n",
              "  0.8560692667961121,\n",
              "  0.8320075869560242,\n",
              "  1.0983926057815552,\n",
              "  0.8370154500007629,\n",
              "  1.3560564517974854,\n",
              "  0.8271321654319763],\n",
              " 'dev_score_history': [0.7006802721088435,\n",
              "  0.6870748299319728,\n",
              "  0.6961451247165533,\n",
              "  0.7414965986394558,\n",
              "  0.7596371882086168,\n",
              "  0.7324263038548753,\n",
              "  0.7052154195011338,\n",
              "  0.746031746031746,\n",
              "  0.6870748299319728,\n",
              "  0.7732426303854876],\n",
              " 'test_score': 0.776255707762557,\n",
              " 'train_loss_history': [1.1594745307355314,\n",
              "  0.9738980918317228,\n",
              "  0.8259133777102908,\n",
              "  0.7832235951681394,\n",
              "  0.7250221081682153,\n",
              "  0.703832321070336,\n",
              "  0.6765379398255735,\n",
              "  0.5982233124810297,\n",
              "  0.632674384761501,\n",
              "  0.4617382706822576]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2JikhOEZFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5maM-7gQWqJ",
        "colab_type": "text"
      },
      "source": [
        "### Second Stage (train on hand annotated datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbrXhSRlnCR3",
        "colab_type": "text"
      },
      "source": [
        "#### Build corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0E6iEy9UgYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ce1a6515-dfa2-4c3d-b264-08116d6e7966"
      },
      "source": [
        "new_data_folder = './drive/My Drive/capstone/data/second_stage/'\n",
        "new_column_name_map = {5: \"text\", 4: \"label_topic\"}\n",
        "\n",
        "corpus: Corpus = CSVClassificationCorpus(new_data_folder,\n",
        "                                         new_column_name_map,\n",
        "                                         skip_header=True, #no header in kaggle data\n",
        "                                         delimiter=',',    # comma separated rows\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 22:56:20,848 Reading data from drive/My Drive/capstone/data/second_stage\n",
            "2020-05-21 22:56:20,850 Train: drive/My Drive/capstone/data/second_stage/train.csv\n",
            "2020-05-21 22:56:20,852 Dev: drive/My Drive/capstone/data/second_stage/dev.csv\n",
            "2020-05-21 22:56:20,858 Test: drive/My Drive/capstone/data/second_stage/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGDir71nHb6",
        "colab_type": "text"
      },
      "source": [
        "#### Second Stage fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWg4fjqNYMKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cadf0c56-5bfd-4350-c481-861b9bc354a1"
      },
      "source": [
        "# benchmark_embeddings = FlairEmbeddings(data_folder + 'best-model.pt')\n",
        "benchmark_classifier = TextClassifier.load(data_folder + 'best-model.pt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 22:56:22,462 loading file ./drive/My Drive/capstone/data/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1XWYH6QZGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb3b5a9f-0100-4ab6-b88f-8307cc8c67da"
      },
      "source": [
        "trainer = ModelTrainer(benchmark_classifier, corpus)\n",
        "trainer.train(new_data_folder, max_epochs=10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 22:56:25,413 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,418 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-21 22:56:25,421 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,422 Corpus: \"Corpus: 132 train + 33 dev + 33 test sentences\"\n",
            "2020-05-21 22:56:25,424 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,426 Parameters:\n",
            "2020-05-21 22:56:25,428  - learning_rate: \"0.1\"\n",
            "2020-05-21 22:56:25,431  - mini_batch_size: \"32\"\n",
            "2020-05-21 22:56:25,432  - patience: \"3\"\n",
            "2020-05-21 22:56:25,436  - anneal_factor: \"0.5\"\n",
            "2020-05-21 22:56:25,439  - max_epochs: \"10\"\n",
            "2020-05-21 22:56:25,442  - shuffle: \"True\"\n",
            "2020-05-21 22:56:25,444  - train_with_dev: \"False\"\n",
            "2020-05-21 22:56:25,446  - batch_growth_annealing: \"False\"\n",
            "2020-05-21 22:56:25,448 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,451 Model training base path: \"drive/My Drive/capstone/data/second_stage\"\n",
            "2020-05-21 22:56:25,454 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,456 Device: cuda:0\n",
            "2020-05-21 22:56:25,458 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:25,460 Embeddings storage mode: cpu\n",
            "2020-05-21 22:56:25,473 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:56:26,567 epoch 1 - iter 1/5 - loss 2.47603059 - samples/sec: 41.77\n",
            "2020-05-21 22:56:40,614 epoch 1 - iter 2/5 - loss 1.98752087 - samples/sec: 43.24\n",
            "2020-05-21 22:56:54,562 epoch 1 - iter 3/5 - loss 1.63302696 - samples/sec: 44.08\n",
            "2020-05-21 22:57:08,428 epoch 1 - iter 4/5 - loss 1.47905332 - samples/sec: 48.81\n",
            "2020-05-21 22:57:21,568 epoch 1 - iter 5/5 - loss 1.22447270 - samples/sec: 219.30\n",
            "2020-05-21 22:57:34,921 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:57:34,927 EPOCH 1 done: loss 1.2245 - lr 0.1000000\n",
            "2020-05-21 22:57:36,068 DEV : loss 0.6211347579956055 - score 0.7778\n",
            "2020-05-21 22:57:36,124 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 22:57:38,107 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:57:39,104 epoch 2 - iter 1/5 - loss 0.94350493 - samples/sec: 47.58\n",
            "2020-05-21 22:57:53,003 epoch 2 - iter 2/5 - loss 1.39652342 - samples/sec: 44.56\n",
            "2020-05-21 22:58:07,013 epoch 2 - iter 3/5 - loss 1.21690861 - samples/sec: 40.58\n",
            "2020-05-21 22:58:20,957 epoch 2 - iter 4/5 - loss 1.09449874 - samples/sec: 43.76\n",
            "2020-05-21 22:58:34,201 epoch 2 - iter 5/5 - loss 1.06485778 - samples/sec: 212.62\n",
            "2020-05-21 22:58:47,441 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:58:47,442 EPOCH 2 done: loss 1.0649 - lr 0.1000000\n",
            "2020-05-21 22:58:48,599 DEV : loss 0.6653227806091309 - score 0.7778\n",
            "2020-05-21 22:58:48,657 BAD EPOCHS (no improvement): 1\n",
            "2020-05-21 22:58:48,662 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:58:49,981 epoch 3 - iter 1/5 - loss 0.68031418 - samples/sec: 48.09\n",
            "2020-05-21 22:59:03,841 epoch 3 - iter 2/5 - loss 0.90626210 - samples/sec: 49.76\n",
            "2020-05-21 22:59:17,670 epoch 3 - iter 3/5 - loss 0.74246905 - samples/sec: 51.44\n",
            "2020-05-21 22:59:31,545 epoch 3 - iter 4/5 - loss 0.74629961 - samples/sec: 52.11\n",
            "2020-05-21 22:59:44,844 epoch 3 - iter 5/5 - loss 0.72768322 - samples/sec: 235.84\n",
            "2020-05-21 22:59:58,181 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 22:59:58,186 EPOCH 3 done: loss 0.7277 - lr 0.1000000\n",
            "2020-05-21 22:59:59,256 DEV : loss 0.5546189546585083 - score 0.7778\n",
            "2020-05-21 22:59:59,311 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:00:01,374 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:00:02,425 epoch 4 - iter 1/5 - loss 0.36992514 - samples/sec: 46.40\n",
            "2020-05-21 23:00:16,377 epoch 4 - iter 2/5 - loss 0.42011677 - samples/sec: 39.28\n",
            "2020-05-21 23:00:30,188 epoch 4 - iter 3/5 - loss 0.38523609 - samples/sec: 53.84\n",
            "2020-05-21 23:00:43,955 epoch 4 - iter 4/5 - loss 0.43879703 - samples/sec: 48.82\n",
            "2020-05-21 23:00:57,218 epoch 4 - iter 5/5 - loss 0.65687655 - samples/sec: 248.04\n",
            "2020-05-21 23:01:10,457 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:01:10,459 EPOCH 4 done: loss 0.6569 - lr 0.1000000\n",
            "2020-05-21 23:01:11,529 DEV : loss 0.4246145486831665 - score 0.8384\n",
            "2020-05-21 23:01:11,582 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:01:13,656 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:01:14,696 epoch 5 - iter 1/5 - loss 0.49954554 - samples/sec: 44.86\n",
            "2020-05-21 23:01:28,640 epoch 5 - iter 2/5 - loss 0.51323853 - samples/sec: 48.29\n",
            "2020-05-21 23:01:42,772 epoch 5 - iter 3/5 - loss 0.48786973 - samples/sec: 50.17\n",
            "2020-05-21 23:01:56,621 epoch 5 - iter 4/5 - loss 0.44873910 - samples/sec: 49.51\n",
            "2020-05-21 23:02:09,845 epoch 5 - iter 5/5 - loss 0.40970936 - samples/sec: 246.27\n",
            "2020-05-21 23:02:23,186 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:02:23,191 EPOCH 5 done: loss 0.4097 - lr 0.1000000\n",
            "2020-05-21 23:02:24,283 DEV : loss 0.34248945116996765 - score 0.8788\n",
            "2020-05-21 23:02:24,338 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:02:26,310 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:02:27,372 epoch 6 - iter 1/5 - loss 0.21148753 - samples/sec: 45.16\n",
            "2020-05-21 23:02:41,336 epoch 6 - iter 2/5 - loss 0.30649507 - samples/sec: 38.36\n",
            "2020-05-21 23:02:55,214 epoch 6 - iter 3/5 - loss 0.38828582 - samples/sec: 49.23\n",
            "2020-05-21 23:03:09,081 epoch 6 - iter 4/5 - loss 0.35075251 - samples/sec: 49.55\n",
            "2020-05-21 23:03:22,303 epoch 6 - iter 5/5 - loss 0.45927231 - samples/sec: 243.98\n",
            "2020-05-21 23:03:35,543 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:03:35,548 EPOCH 6 done: loss 0.4593 - lr 0.1000000\n",
            "2020-05-21 23:03:36,619 DEV : loss 2.3637852668762207 - score 0.6162\n",
            "2020-05-21 23:03:36,673 BAD EPOCHS (no improvement): 1\n",
            "2020-05-21 23:03:36,680 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:03:37,688 epoch 7 - iter 1/5 - loss 1.47228169 - samples/sec: 45.76\n",
            "2020-05-21 23:03:51,809 epoch 7 - iter 2/5 - loss 1.12373403 - samples/sec: 36.22\n",
            "2020-05-21 23:04:05,555 epoch 7 - iter 3/5 - loss 1.13963407 - samples/sec: 50.46\n",
            "2020-05-21 23:04:19,389 epoch 7 - iter 4/5 - loss 1.00034453 - samples/sec: 51.40\n",
            "2020-05-21 23:04:32,621 epoch 7 - iter 5/5 - loss 0.92683176 - samples/sec: 240.11\n",
            "2020-05-21 23:04:45,966 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:04:45,968 EPOCH 7 done: loss 0.9268 - lr 0.1000000\n",
            "2020-05-21 23:04:47,044 DEV : loss 0.3363116681575775 - score 0.8788\n",
            "2020-05-21 23:04:47,099 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:04:49,291 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:04:50,327 epoch 8 - iter 1/5 - loss 0.29025859 - samples/sec: 46.26\n",
            "2020-05-21 23:05:04,211 epoch 8 - iter 2/5 - loss 0.31462778 - samples/sec: 43.51\n",
            "2020-05-21 23:05:18,044 epoch 8 - iter 3/5 - loss 0.28279692 - samples/sec: 52.11\n",
            "2020-05-21 23:05:31,875 epoch 8 - iter 4/5 - loss 0.26356334 - samples/sec: 51.25\n",
            "2020-05-21 23:05:45,115 epoch 8 - iter 5/5 - loss 0.26085380 - samples/sec: 214.85\n",
            "2020-05-21 23:05:58,464 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:05:58,466 EPOCH 8 done: loss 0.2609 - lr 0.1000000\n",
            "2020-05-21 23:05:59,555 DEV : loss 1.2868273258209229 - score 0.7172\n",
            "2020-05-21 23:05:59,615 BAD EPOCHS (no improvement): 1\n",
            "2020-05-21 23:05:59,622 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:06:00,615 epoch 9 - iter 1/5 - loss 0.25317389 - samples/sec: 47.12\n",
            "2020-05-21 23:06:14,740 epoch 9 - iter 2/5 - loss 0.24439692 - samples/sec: 35.10\n",
            "2020-05-21 23:06:28,445 epoch 9 - iter 3/5 - loss 0.25073752 - samples/sec: 54.20\n",
            "2020-05-21 23:06:42,311 epoch 9 - iter 4/5 - loss 0.28024385 - samples/sec: 48.16\n",
            "2020-05-21 23:06:55,561 epoch 9 - iter 5/5 - loss 0.33514250 - samples/sec: 221.16\n",
            "2020-05-21 23:07:08,910 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:07:08,916 EPOCH 9 done: loss 0.3351 - lr 0.1000000\n",
            "2020-05-21 23:07:10,014 DEV : loss 0.8674789667129517 - score 0.8182\n",
            "2020-05-21 23:07:10,069 BAD EPOCHS (no improvement): 2\n",
            "2020-05-21 23:07:10,075 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:07:11,100 epoch 10 - iter 1/5 - loss 0.55110812 - samples/sec: 44.46\n",
            "2020-05-21 23:07:24,961 epoch 10 - iter 2/5 - loss 0.66377437 - samples/sec: 50.07\n",
            "2020-05-21 23:07:38,841 epoch 10 - iter 3/5 - loss 0.53912481 - samples/sec: 48.59\n",
            "2020-05-21 23:07:52,670 epoch 10 - iter 4/5 - loss 0.44988540 - samples/sec: 52.08\n",
            "2020-05-21 23:08:05,863 epoch 10 - iter 5/5 - loss 0.37118482 - samples/sec: 217.09\n",
            "2020-05-21 23:08:19,211 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:08:19,216 EPOCH 10 done: loss 0.3712 - lr 0.1000000\n",
            "2020-05-21 23:08:20,305 DEV : loss 0.4017622470855713 - score 0.899\n",
            "2020-05-21 23:08:20,362 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-21 23:08:24,581 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-21 23:08:24,585 Testing using best model ...\n",
            "2020-05-21 23:08:24,591 loading file drive/My Drive/capstone/data/second_stage/best-model.pt\n",
            "2020-05-21 23:08:26,632 0.8484848484848485\t0.8484848484848485\t0.8484848484848486\n",
            "2020-05-21 23:08:26,638 \n",
            "MICRO_AVG: acc 0.898989898989899 - f1-score 0.8484848484848486\n",
            "MACRO_AVG: acc 0.8989898989898991 - f1-score 0.8523809523809525\n",
            "-1         tp: 9 - fp: 1 - fn: 2 - tn: 21 - precision: 0.9000 - recall: 0.8182 - accuracy: 0.9091 - f1-score: 0.8571\n",
            "0          tp: 10 - fp: 4 - fn: 1 - tn: 18 - precision: 0.7143 - recall: 0.9091 - accuracy: 0.8485 - f1-score: 0.8000\n",
            "1          tp: 9 - fp: 0 - fn: 2 - tn: 22 - precision: 1.0000 - recall: 0.8182 - accuracy: 0.9394 - f1-score: 0.9000\n",
            "2020-05-21 23:08:26,642 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.6211347579956055,\n",
              "  0.6653227806091309,\n",
              "  0.5546189546585083,\n",
              "  0.4246145486831665,\n",
              "  0.34248945116996765,\n",
              "  2.3637852668762207,\n",
              "  0.3363116681575775,\n",
              "  1.2868273258209229,\n",
              "  0.8674789667129517,\n",
              "  0.4017622470855713],\n",
              " 'dev_score_history': [0.7777777777777778,\n",
              "  0.7777777777777778,\n",
              "  0.7777777777777778,\n",
              "  0.8383838383838383,\n",
              "  0.8787878787878788,\n",
              "  0.6161616161616161,\n",
              "  0.8787878787878788,\n",
              "  0.7171717171717171,\n",
              "  0.8181818181818182,\n",
              "  0.898989898989899],\n",
              " 'test_score': 0.898989898989899,\n",
              " 'train_loss_history': [1.22447270154953,\n",
              "  1.0648577809333801,\n",
              "  0.7276832222938537,\n",
              "  0.6568765461444854,\n",
              "  0.4097093641757965,\n",
              "  0.4592723071575165,\n",
              "  0.9268317580223083,\n",
              "  0.26085380017757415,\n",
              "  0.3351425021886826,\n",
              "  0.37118481993675234]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKyyw1CSZFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}